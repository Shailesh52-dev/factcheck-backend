{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.5590200445434297,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0022271714922048997,
      "grad_norm": 3.431209087371826,
      "learning_rate": 9e-07,
      "loss": 0.6988,
      "step": 10
    },
    {
      "epoch": 0.004454342984409799,
      "grad_norm": 1.5945241451263428,
      "learning_rate": 1.9e-06,
      "loss": 0.6943,
      "step": 20
    },
    {
      "epoch": 0.0066815144766146995,
      "grad_norm": 1.3031045198440552,
      "learning_rate": 2.9e-06,
      "loss": 0.6927,
      "step": 30
    },
    {
      "epoch": 0.008908685968819599,
      "grad_norm": 2.643918514251709,
      "learning_rate": 3.9e-06,
      "loss": 0.6881,
      "step": 40
    },
    {
      "epoch": 0.011135857461024499,
      "grad_norm": 1.3544669151306152,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.6639,
      "step": 50
    },
    {
      "epoch": 0.013363028953229399,
      "grad_norm": 2.9651875495910645,
      "learning_rate": 5.9e-06,
      "loss": 0.651,
      "step": 60
    },
    {
      "epoch": 0.015590200445434299,
      "grad_norm": 3.1865758895874023,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.5755,
      "step": 70
    },
    {
      "epoch": 0.017817371937639197,
      "grad_norm": 3.4834768772125244,
      "learning_rate": 7.9e-06,
      "loss": 0.4199,
      "step": 80
    },
    {
      "epoch": 0.0200445434298441,
      "grad_norm": 1.7848082780838013,
      "learning_rate": 8.9e-06,
      "loss": 0.2412,
      "step": 90
    },
    {
      "epoch": 0.022271714922048998,
      "grad_norm": 0.9703733325004578,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.1429,
      "step": 100
    },
    {
      "epoch": 0.024498886414253896,
      "grad_norm": 0.5473387241363525,
      "learning_rate": 1.09e-05,
      "loss": 0.0967,
      "step": 110
    },
    {
      "epoch": 0.026726057906458798,
      "grad_norm": 0.40797603130340576,
      "learning_rate": 1.19e-05,
      "loss": 0.0464,
      "step": 120
    },
    {
      "epoch": 0.028953229398663696,
      "grad_norm": 0.29466378688812256,
      "learning_rate": 1.29e-05,
      "loss": 0.0263,
      "step": 130
    },
    {
      "epoch": 0.031180400890868598,
      "grad_norm": 0.7490040063858032,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0188,
      "step": 140
    },
    {
      "epoch": 0.0334075723830735,
      "grad_norm": 0.1550196409225464,
      "learning_rate": 1.49e-05,
      "loss": 0.0102,
      "step": 150
    },
    {
      "epoch": 0.035634743875278395,
      "grad_norm": 8.649392127990723,
      "learning_rate": 1.59e-05,
      "loss": 0.0133,
      "step": 160
    },
    {
      "epoch": 0.0378619153674833,
      "grad_norm": 0.08959051966667175,
      "learning_rate": 1.69e-05,
      "loss": 0.0069,
      "step": 170
    },
    {
      "epoch": 0.0400890868596882,
      "grad_norm": 0.08933669328689575,
      "learning_rate": 1.79e-05,
      "loss": 0.0079,
      "step": 180
    },
    {
      "epoch": 0.042316258351893093,
      "grad_norm": 0.07168997079133987,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0057,
      "step": 190
    },
    {
      "epoch": 0.044543429844097995,
      "grad_norm": 0.06148263067007065,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0434,
      "step": 200
    },
    {
      "epoch": 0.0467706013363029,
      "grad_norm": 0.05540284141898155,
      "learning_rate": 2.09e-05,
      "loss": 0.0702,
      "step": 210
    },
    {
      "epoch": 0.04899777282850779,
      "grad_norm": 0.0727599635720253,
      "learning_rate": 2.19e-05,
      "loss": 0.0036,
      "step": 220
    },
    {
      "epoch": 0.051224944320712694,
      "grad_norm": 0.051876556128263474,
      "learning_rate": 2.29e-05,
      "loss": 0.003,
      "step": 230
    },
    {
      "epoch": 0.053452115812917596,
      "grad_norm": 0.0467323362827301,
      "learning_rate": 2.39e-05,
      "loss": 0.0028,
      "step": 240
    },
    {
      "epoch": 0.0556792873051225,
      "grad_norm": 0.036060597747564316,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.0025,
      "step": 250
    },
    {
      "epoch": 0.05790645879732739,
      "grad_norm": 0.04070688411593437,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.002,
      "step": 260
    },
    {
      "epoch": 0.060133630289532294,
      "grad_norm": 0.02991284243762493,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0019,
      "step": 270
    },
    {
      "epoch": 0.062360801781737196,
      "grad_norm": 0.02594655565917492,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0018,
      "step": 280
    },
    {
      "epoch": 0.0645879732739421,
      "grad_norm": 0.03034917078912258,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0015,
      "step": 290
    },
    {
      "epoch": 0.066815144766147,
      "grad_norm": 0.040472112596035004,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0013,
      "step": 300
    },
    {
      "epoch": 0.06904231625835189,
      "grad_norm": 0.036792658269405365,
      "learning_rate": 3.09e-05,
      "loss": 0.0013,
      "step": 310
    },
    {
      "epoch": 0.07126948775055679,
      "grad_norm": 0.01685582846403122,
      "learning_rate": 3.19e-05,
      "loss": 0.001,
      "step": 320
    },
    {
      "epoch": 0.07349665924276169,
      "grad_norm": 0.014991199597716331,
      "learning_rate": 3.29e-05,
      "loss": 0.001,
      "step": 330
    },
    {
      "epoch": 0.0757238307349666,
      "grad_norm": 0.015452426858246326,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0009,
      "step": 340
    },
    {
      "epoch": 0.0779510022271715,
      "grad_norm": 0.015531397424638271,
      "learning_rate": 3.49e-05,
      "loss": 0.0007,
      "step": 350
    },
    {
      "epoch": 0.0801781737193764,
      "grad_norm": 0.06109783425927162,
      "learning_rate": 3.59e-05,
      "loss": 0.0009,
      "step": 360
    },
    {
      "epoch": 0.08240534521158129,
      "grad_norm": 0.01355788018554449,
      "learning_rate": 3.69e-05,
      "loss": 0.0558,
      "step": 370
    },
    {
      "epoch": 0.08463251670378619,
      "grad_norm": 0.009466464631259441,
      "learning_rate": 3.79e-05,
      "loss": 0.0006,
      "step": 380
    },
    {
      "epoch": 0.08685968819599109,
      "grad_norm": 0.010187627747654915,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0007,
      "step": 390
    },
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 0.012195323593914509,
      "learning_rate": 3.99e-05,
      "loss": 0.0007,
      "step": 400
    },
    {
      "epoch": 0.09131403118040089,
      "grad_norm": 0.02273370325565338,
      "learning_rate": 4.09e-05,
      "loss": 0.0027,
      "step": 410
    },
    {
      "epoch": 0.0935412026726058,
      "grad_norm": 0.010213186033070087,
      "learning_rate": 4.19e-05,
      "loss": 0.0004,
      "step": 420
    },
    {
      "epoch": 0.0957683741648107,
      "grad_norm": 0.008116074837744236,
      "learning_rate": 4.29e-05,
      "loss": 0.0206,
      "step": 430
    },
    {
      "epoch": 0.09799554565701558,
      "grad_norm": 0.009267566725611687,
      "learning_rate": 4.39e-05,
      "loss": 0.001,
      "step": 440
    },
    {
      "epoch": 0.10022271714922049,
      "grad_norm": 0.007021318655461073,
      "learning_rate": 4.49e-05,
      "loss": 0.0005,
      "step": 450
    },
    {
      "epoch": 0.10244988864142539,
      "grad_norm": 35.92754364013672,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.0291,
      "step": 460
    },
    {
      "epoch": 0.10467706013363029,
      "grad_norm": 0.007265315391123295,
      "learning_rate": 4.69e-05,
      "loss": 0.0128,
      "step": 470
    },
    {
      "epoch": 0.10690423162583519,
      "grad_norm": 0.012291595339775085,
      "learning_rate": 4.79e-05,
      "loss": 0.0013,
      "step": 480
    },
    {
      "epoch": 0.1091314031180401,
      "grad_norm": 0.005603676196187735,
      "learning_rate": 4.89e-05,
      "loss": 0.0003,
      "step": 490
    },
    {
      "epoch": 0.111358574610245,
      "grad_norm": 0.009176917374134064,
      "learning_rate": 4.99e-05,
      "loss": 0.0729,
      "step": 500
    },
    {
      "epoch": 0.11358574610244988,
      "grad_norm": 0.01008897926658392,
      "learning_rate": 4.996530454895914e-05,
      "loss": 0.0005,
      "step": 510
    },
    {
      "epoch": 0.11581291759465479,
      "grad_norm": 0.008612244389951229,
      "learning_rate": 4.992675404780263e-05,
      "loss": 0.0004,
      "step": 520
    },
    {
      "epoch": 0.11804008908685969,
      "grad_norm": 0.03885987773537636,
      "learning_rate": 4.9888203546646105e-05,
      "loss": 0.1178,
      "step": 530
    },
    {
      "epoch": 0.12026726057906459,
      "grad_norm": 0.025776294991374016,
      "learning_rate": 4.984965304548959e-05,
      "loss": 0.0006,
      "step": 540
    },
    {
      "epoch": 0.12249443207126949,
      "grad_norm": 0.08023320883512497,
      "learning_rate": 4.981110254433308e-05,
      "loss": 0.0006,
      "step": 550
    },
    {
      "epoch": 0.12472160356347439,
      "grad_norm": 0.004364595282822847,
      "learning_rate": 4.977255204317656e-05,
      "loss": 0.0004,
      "step": 560
    },
    {
      "epoch": 0.12694877505567928,
      "grad_norm": 0.005635369103401899,
      "learning_rate": 4.973400154202005e-05,
      "loss": 0.0002,
      "step": 570
    },
    {
      "epoch": 0.1291759465478842,
      "grad_norm": 0.004209843464195728,
      "learning_rate": 4.969545104086353e-05,
      "loss": 0.0002,
      "step": 580
    },
    {
      "epoch": 0.13140311804008908,
      "grad_norm": 0.0034029444213956594,
      "learning_rate": 4.965690053970702e-05,
      "loss": 0.0002,
      "step": 590
    },
    {
      "epoch": 0.133630289532294,
      "grad_norm": 0.00575220724567771,
      "learning_rate": 4.9618350038550505e-05,
      "loss": 0.0002,
      "step": 600
    },
    {
      "epoch": 0.1358574610244989,
      "grad_norm": 0.004919408820569515,
      "learning_rate": 4.957979953739399e-05,
      "loss": 0.0002,
      "step": 610
    },
    {
      "epoch": 0.13808463251670378,
      "grad_norm": 0.0033537691924721003,
      "learning_rate": 4.954124903623747e-05,
      "loss": 0.0002,
      "step": 620
    },
    {
      "epoch": 0.1403118040089087,
      "grad_norm": 0.0032662146259099245,
      "learning_rate": 4.950269853508096e-05,
      "loss": 0.0001,
      "step": 630
    },
    {
      "epoch": 0.14253897550111358,
      "grad_norm": 0.0025406882632523775,
      "learning_rate": 4.9464148033924446e-05,
      "loss": 0.0001,
      "step": 640
    },
    {
      "epoch": 0.1447661469933185,
      "grad_norm": 0.02041727863252163,
      "learning_rate": 4.942559753276793e-05,
      "loss": 0.1093,
      "step": 650
    },
    {
      "epoch": 0.14699331848552338,
      "grad_norm": 0.03743819519877434,
      "learning_rate": 4.9387047031611414e-05,
      "loss": 0.0059,
      "step": 660
    },
    {
      "epoch": 0.1492204899777283,
      "grad_norm": 0.007928205654025078,
      "learning_rate": 4.93484965304549e-05,
      "loss": 0.0009,
      "step": 670
    },
    {
      "epoch": 0.1514476614699332,
      "grad_norm": 0.004348834045231342,
      "learning_rate": 4.930994602929838e-05,
      "loss": 0.0011,
      "step": 680
    },
    {
      "epoch": 0.15367483296213807,
      "grad_norm": 0.006778515409678221,
      "learning_rate": 4.9271395528141865e-05,
      "loss": 0.0002,
      "step": 690
    },
    {
      "epoch": 0.155902004454343,
      "grad_norm": 0.00542496656998992,
      "learning_rate": 4.9232845026985355e-05,
      "loss": 0.0002,
      "step": 700
    },
    {
      "epoch": 0.15812917594654788,
      "grad_norm": 0.004850401543080807,
      "learning_rate": 4.919429452582884e-05,
      "loss": 0.0002,
      "step": 710
    },
    {
      "epoch": 0.1603563474387528,
      "grad_norm": 0.004906316753476858,
      "learning_rate": 4.915574402467232e-05,
      "loss": 0.0002,
      "step": 720
    },
    {
      "epoch": 0.16258351893095768,
      "grad_norm": 0.0031026357319206,
      "learning_rate": 4.9117193523515807e-05,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 0.16481069042316257,
      "grad_norm": 0.0030167296063154936,
      "learning_rate": 4.90786430223593e-05,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 0.16703786191536749,
      "grad_norm": 0.003254351206123829,
      "learning_rate": 4.904009252120278e-05,
      "loss": 0.0001,
      "step": 750
    },
    {
      "epoch": 0.16926503340757237,
      "grad_norm": 0.0023794753942638636,
      "learning_rate": 4.9001542020046264e-05,
      "loss": 0.0001,
      "step": 760
    },
    {
      "epoch": 0.1714922048997773,
      "grad_norm": 0.0018970713717862964,
      "learning_rate": 4.896299151888975e-05,
      "loss": 0.0001,
      "step": 770
    },
    {
      "epoch": 0.17371937639198218,
      "grad_norm": 0.0077140796929597855,
      "learning_rate": 4.892444101773323e-05,
      "loss": 0.0494,
      "step": 780
    },
    {
      "epoch": 0.1759465478841871,
      "grad_norm": 0.005012082867324352,
      "learning_rate": 4.8885890516576716e-05,
      "loss": 0.0004,
      "step": 790
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.0030972680542618036,
      "learning_rate": 4.88473400154202e-05,
      "loss": 0.0002,
      "step": 800
    },
    {
      "epoch": 0.18040089086859687,
      "grad_norm": 0.008881570771336555,
      "learning_rate": 4.880878951426368e-05,
      "loss": 0.072,
      "step": 810
    },
    {
      "epoch": 0.18262806236080179,
      "grad_norm": 0.004121475387364626,
      "learning_rate": 4.8770239013107174e-05,
      "loss": 0.0006,
      "step": 820
    },
    {
      "epoch": 0.18485523385300667,
      "grad_norm": 0.003665172727778554,
      "learning_rate": 4.873168851195066e-05,
      "loss": 0.0002,
      "step": 830
    },
    {
      "epoch": 0.1870824053452116,
      "grad_norm": 0.0022593180183321238,
      "learning_rate": 4.869313801079414e-05,
      "loss": 0.0002,
      "step": 840
    },
    {
      "epoch": 0.18930957683741648,
      "grad_norm": 0.0030925734899938107,
      "learning_rate": 4.8654587509637625e-05,
      "loss": 0.0001,
      "step": 850
    },
    {
      "epoch": 0.1915367483296214,
      "grad_norm": 0.005627123173326254,
      "learning_rate": 4.8616037008481115e-05,
      "loss": 0.0866,
      "step": 860
    },
    {
      "epoch": 0.19376391982182628,
      "grad_norm": 0.017698820680379868,
      "learning_rate": 4.85774865073246e-05,
      "loss": 0.0003,
      "step": 870
    },
    {
      "epoch": 0.19599109131403117,
      "grad_norm": 0.0037356670945882797,
      "learning_rate": 4.853893600616808e-05,
      "loss": 0.0008,
      "step": 880
    },
    {
      "epoch": 0.19821826280623608,
      "grad_norm": 0.0017527706222608685,
      "learning_rate": 4.8500385505011566e-05,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 0.20044543429844097,
      "grad_norm": 0.00198148051276803,
      "learning_rate": 4.846183500385506e-05,
      "loss": 0.0001,
      "step": 900
    },
    {
      "epoch": 0.2026726057906459,
      "grad_norm": 0.0033013392239809036,
      "learning_rate": 4.8423284502698534e-05,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 0.20489977728285078,
      "grad_norm": 0.0024627968668937683,
      "learning_rate": 4.838473400154202e-05,
      "loss": 0.0001,
      "step": 920
    },
    {
      "epoch": 0.2071269487750557,
      "grad_norm": 0.002736808033660054,
      "learning_rate": 4.834618350038551e-05,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 0.20935412026726058,
      "grad_norm": 0.0016122461529448628,
      "learning_rate": 4.830763299922899e-05,
      "loss": 0.0001,
      "step": 940
    },
    {
      "epoch": 0.21158129175946547,
      "grad_norm": 0.00158878939691931,
      "learning_rate": 4.8269082498072475e-05,
      "loss": 0.0001,
      "step": 950
    },
    {
      "epoch": 0.21380846325167038,
      "grad_norm": 0.0011894447961822152,
      "learning_rate": 4.823053199691596e-05,
      "loss": 0.0001,
      "step": 960
    },
    {
      "epoch": 0.21603563474387527,
      "grad_norm": 0.0020984618458896875,
      "learning_rate": 4.819198149575945e-05,
      "loss": 0.0001,
      "step": 970
    },
    {
      "epoch": 0.2182628062360802,
      "grad_norm": 0.0013036364689469337,
      "learning_rate": 4.815343099460293e-05,
      "loss": 0.0001,
      "step": 980
    },
    {
      "epoch": 0.22048997772828507,
      "grad_norm": 0.0015882375882938504,
      "learning_rate": 4.811488049344642e-05,
      "loss": 0.0001,
      "step": 990
    },
    {
      "epoch": 0.22271714922049,
      "grad_norm": 0.0015365431318059564,
      "learning_rate": 4.80763299922899e-05,
      "loss": 0.0001,
      "step": 1000
    },
    {
      "epoch": 0.22494432071269488,
      "grad_norm": 0.0016050381818786263,
      "learning_rate": 4.803777949113339e-05,
      "loss": 0.0001,
      "step": 1010
    },
    {
      "epoch": 0.22717149220489977,
      "grad_norm": 0.001162832835689187,
      "learning_rate": 4.7999228989976875e-05,
      "loss": 0.0001,
      "step": 1020
    },
    {
      "epoch": 0.22939866369710468,
      "grad_norm": 0.0017633364768698812,
      "learning_rate": 4.796067848882035e-05,
      "loss": 0.0001,
      "step": 1030
    },
    {
      "epoch": 0.23162583518930957,
      "grad_norm": 0.0014406056143343449,
      "learning_rate": 4.792212798766384e-05,
      "loss": 0.0001,
      "step": 1040
    },
    {
      "epoch": 0.23385300668151449,
      "grad_norm": 0.0009505327907390893,
      "learning_rate": 4.7883577486507326e-05,
      "loss": 0.0,
      "step": 1050
    },
    {
      "epoch": 0.23608017817371937,
      "grad_norm": 0.0009892246453091502,
      "learning_rate": 4.784502698535081e-05,
      "loss": 0.0001,
      "step": 1060
    },
    {
      "epoch": 0.2383073496659243,
      "grad_norm": 0.001066096592694521,
      "learning_rate": 4.7806476484194294e-05,
      "loss": 0.0,
      "step": 1070
    },
    {
      "epoch": 0.24053452115812918,
      "grad_norm": 0.001613892731256783,
      "learning_rate": 4.7767925983037784e-05,
      "loss": 0.0,
      "step": 1080
    },
    {
      "epoch": 0.24276169265033407,
      "grad_norm": 0.0017776720924302936,
      "learning_rate": 4.772937548188127e-05,
      "loss": 0.0001,
      "step": 1090
    },
    {
      "epoch": 0.24498886414253898,
      "grad_norm": 0.002030929084867239,
      "learning_rate": 4.769082498072475e-05,
      "loss": 0.0001,
      "step": 1100
    },
    {
      "epoch": 0.24721603563474387,
      "grad_norm": 0.0009249323047697544,
      "learning_rate": 4.7652274479568235e-05,
      "loss": 0.0,
      "step": 1110
    },
    {
      "epoch": 0.24944320712694878,
      "grad_norm": 0.0008249652455560863,
      "learning_rate": 4.7613723978411726e-05,
      "loss": 0.0,
      "step": 1120
    },
    {
      "epoch": 0.2516703786191537,
      "grad_norm": 0.0012628004187718034,
      "learning_rate": 4.757517347725521e-05,
      "loss": 0.0,
      "step": 1130
    },
    {
      "epoch": 0.25389755011135856,
      "grad_norm": 0.0010191318579018116,
      "learning_rate": 4.753662297609869e-05,
      "loss": 0.0,
      "step": 1140
    },
    {
      "epoch": 0.2561247216035635,
      "grad_norm": 0.0010273990919813514,
      "learning_rate": 4.749807247494218e-05,
      "loss": 0.0,
      "step": 1150
    },
    {
      "epoch": 0.2583518930957684,
      "grad_norm": 0.0009914592374116182,
      "learning_rate": 4.745952197378566e-05,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 0.26057906458797325,
      "grad_norm": 0.0009320122771896422,
      "learning_rate": 4.7420971472629144e-05,
      "loss": 0.0,
      "step": 1170
    },
    {
      "epoch": 0.26280623608017817,
      "grad_norm": 0.0010169537272304296,
      "learning_rate": 4.738242097147263e-05,
      "loss": 0.0,
      "step": 1180
    },
    {
      "epoch": 0.2650334075723831,
      "grad_norm": 0.0006987357628531754,
      "learning_rate": 4.734387047031612e-05,
      "loss": 0.0,
      "step": 1190
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.000799989269580692,
      "learning_rate": 4.73053199691596e-05,
      "loss": 0.0001,
      "step": 1200
    },
    {
      "epoch": 0.26948775055679286,
      "grad_norm": 0.0006347693270072341,
      "learning_rate": 4.7266769468003086e-05,
      "loss": 0.0,
      "step": 1210
    },
    {
      "epoch": 0.2717149220489978,
      "grad_norm": 0.0010448938701301813,
      "learning_rate": 4.722821896684657e-05,
      "loss": 0.0,
      "step": 1220
    },
    {
      "epoch": 0.2739420935412027,
      "grad_norm": 0.0006951876566745341,
      "learning_rate": 4.718966846569006e-05,
      "loss": 0.0,
      "step": 1230
    },
    {
      "epoch": 0.27616926503340755,
      "grad_norm": 0.0009757720399647951,
      "learning_rate": 4.7151117964533544e-05,
      "loss": 0.0,
      "step": 1240
    },
    {
      "epoch": 0.27839643652561247,
      "grad_norm": 0.0008078649989329278,
      "learning_rate": 4.711256746337703e-05,
      "loss": 0.0,
      "step": 1250
    },
    {
      "epoch": 0.2806236080178174,
      "grad_norm": 0.0008198667201213539,
      "learning_rate": 4.707401696222051e-05,
      "loss": 0.0,
      "step": 1260
    },
    {
      "epoch": 0.2828507795100223,
      "grad_norm": 0.0012516301358118653,
      "learning_rate": 4.7035466461064e-05,
      "loss": 0.0,
      "step": 1270
    },
    {
      "epoch": 0.28507795100222716,
      "grad_norm": 0.0006594061851501465,
      "learning_rate": 4.6996915959907485e-05,
      "loss": 0.0024,
      "step": 1280
    },
    {
      "epoch": 0.2873051224944321,
      "grad_norm": 0.0013818058650940657,
      "learning_rate": 4.695836545875096e-05,
      "loss": 0.0,
      "step": 1290
    },
    {
      "epoch": 0.289532293986637,
      "grad_norm": 0.0010867497185245156,
      "learning_rate": 4.6919814957594446e-05,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 0.29175946547884185,
      "grad_norm": 0.0008936910890042782,
      "learning_rate": 4.6881264456437937e-05,
      "loss": 0.0,
      "step": 1310
    },
    {
      "epoch": 0.29398663697104677,
      "grad_norm": 0.0027311043813824654,
      "learning_rate": 4.684271395528142e-05,
      "loss": 0.0,
      "step": 1320
    },
    {
      "epoch": 0.2962138084632517,
      "grad_norm": 0.0008754460723139346,
      "learning_rate": 4.6804163454124904e-05,
      "loss": 0.0,
      "step": 1330
    },
    {
      "epoch": 0.2984409799554566,
      "grad_norm": 0.0005403757095336914,
      "learning_rate": 4.676561295296839e-05,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 0.30066815144766146,
      "grad_norm": 0.0006410368368960917,
      "learning_rate": 4.672706245181188e-05,
      "loss": 0.0,
      "step": 1350
    },
    {
      "epoch": 0.3028953229398664,
      "grad_norm": 0.0010693053482100368,
      "learning_rate": 4.668851195065536e-05,
      "loss": 0.0,
      "step": 1360
    },
    {
      "epoch": 0.3051224944320713,
      "grad_norm": 0.0007671352941542864,
      "learning_rate": 4.6649961449498846e-05,
      "loss": 0.0,
      "step": 1370
    },
    {
      "epoch": 0.30734966592427615,
      "grad_norm": 0.0010526691330596805,
      "learning_rate": 4.661141094834233e-05,
      "loss": 0.0003,
      "step": 1380
    },
    {
      "epoch": 0.30957683741648107,
      "grad_norm": 0.0008738858159631491,
      "learning_rate": 4.657286044718582e-05,
      "loss": 0.0,
      "step": 1390
    },
    {
      "epoch": 0.311804008908686,
      "grad_norm": 0.000733574153855443,
      "learning_rate": 4.6534309946029304e-05,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 0.31403118040089084,
      "grad_norm": 0.0015889606438577175,
      "learning_rate": 4.649575944487278e-05,
      "loss": 0.0,
      "step": 1410
    },
    {
      "epoch": 0.31625835189309576,
      "grad_norm": 0.0008665199275128543,
      "learning_rate": 4.645720894371627e-05,
      "loss": 0.0,
      "step": 1420
    },
    {
      "epoch": 0.3184855233853007,
      "grad_norm": 0.0010845508659258485,
      "learning_rate": 4.6418658442559755e-05,
      "loss": 0.0,
      "step": 1430
    },
    {
      "epoch": 0.3207126948775056,
      "grad_norm": 0.0009218277409672737,
      "learning_rate": 4.638010794140324e-05,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 0.32293986636971045,
      "grad_norm": 0.0013361776946112514,
      "learning_rate": 4.634155744024672e-05,
      "loss": 0.0,
      "step": 1450
    },
    {
      "epoch": 0.32516703786191536,
      "grad_norm": 0.0021335347555577755,
      "learning_rate": 4.630300693909021e-05,
      "loss": 0.1099,
      "step": 1460
    },
    {
      "epoch": 0.3273942093541203,
      "grad_norm": 0.0021354560740292072,
      "learning_rate": 4.6264456437933696e-05,
      "loss": 0.0027,
      "step": 1470
    },
    {
      "epoch": 0.32962138084632514,
      "grad_norm": 0.001235857722349465,
      "learning_rate": 4.622590593677718e-05,
      "loss": 0.0001,
      "step": 1480
    },
    {
      "epoch": 0.33184855233853006,
      "grad_norm": 0.0018102267058566213,
      "learning_rate": 4.6187355435620664e-05,
      "loss": 0.0114,
      "step": 1490
    },
    {
      "epoch": 0.33407572383073497,
      "grad_norm": 0.03878825530409813,
      "learning_rate": 4.6148804934464154e-05,
      "loss": 0.1055,
      "step": 1500
    },
    {
      "epoch": 0.3363028953229399,
      "grad_norm": 0.0012812159257009625,
      "learning_rate": 4.611025443330764e-05,
      "loss": 0.0001,
      "step": 1510
    },
    {
      "epoch": 0.33853006681514475,
      "grad_norm": 0.0018881550058722496,
      "learning_rate": 4.607170393215112e-05,
      "loss": 0.0,
      "step": 1520
    },
    {
      "epoch": 0.34075723830734966,
      "grad_norm": 0.0009954406414180994,
      "learning_rate": 4.6033153430994605e-05,
      "loss": 0.0,
      "step": 1530
    },
    {
      "epoch": 0.3429844097995546,
      "grad_norm": 0.0010783427860587835,
      "learning_rate": 4.599460292983809e-05,
      "loss": 0.0,
      "step": 1540
    },
    {
      "epoch": 0.34521158129175944,
      "grad_norm": 0.000995759037323296,
      "learning_rate": 4.595605242868157e-05,
      "loss": 0.0,
      "step": 1550
    },
    {
      "epoch": 0.34743875278396436,
      "grad_norm": 0.0009018325945362449,
      "learning_rate": 4.5917501927525057e-05,
      "loss": 0.0,
      "step": 1560
    },
    {
      "epoch": 0.34966592427616927,
      "grad_norm": 0.004622419364750385,
      "learning_rate": 4.587895142636855e-05,
      "loss": 0.111,
      "step": 1570
    },
    {
      "epoch": 0.3518930957683742,
      "grad_norm": 0.005895143840461969,
      "learning_rate": 4.584040092521203e-05,
      "loss": 0.0003,
      "step": 1580
    },
    {
      "epoch": 0.35412026726057905,
      "grad_norm": 0.002627168083563447,
      "learning_rate": 4.5801850424055514e-05,
      "loss": 0.0001,
      "step": 1590
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.0021668588742613792,
      "learning_rate": 4.5763299922899e-05,
      "loss": 0.0001,
      "step": 1600
    },
    {
      "epoch": 0.3585746102449889,
      "grad_norm": 0.0018249565036967397,
      "learning_rate": 4.572474942174249e-05,
      "loss": 0.0,
      "step": 1610
    },
    {
      "epoch": 0.36080178173719374,
      "grad_norm": 0.000831479555927217,
      "learning_rate": 4.568619892058597e-05,
      "loss": 0.0001,
      "step": 1620
    },
    {
      "epoch": 0.36302895322939865,
      "grad_norm": 0.0013563591055572033,
      "learning_rate": 4.5647648419429456e-05,
      "loss": 0.0,
      "step": 1630
    },
    {
      "epoch": 0.36525612472160357,
      "grad_norm": 0.0012283700052648783,
      "learning_rate": 4.560909791827294e-05,
      "loss": 0.0,
      "step": 1640
    },
    {
      "epoch": 0.3674832962138085,
      "grad_norm": 0.0006783531862311065,
      "learning_rate": 4.557054741711643e-05,
      "loss": 0.0,
      "step": 1650
    },
    {
      "epoch": 0.36971046770601335,
      "grad_norm": 0.0012505725026130676,
      "learning_rate": 4.553199691595991e-05,
      "loss": 0.0,
      "step": 1660
    },
    {
      "epoch": 0.37193763919821826,
      "grad_norm": 0.0005117461550980806,
      "learning_rate": 4.549344641480339e-05,
      "loss": 0.0,
      "step": 1670
    },
    {
      "epoch": 0.3741648106904232,
      "grad_norm": 0.0013493510195985436,
      "learning_rate": 4.5454895913646875e-05,
      "loss": 0.0,
      "step": 1680
    },
    {
      "epoch": 0.37639198218262804,
      "grad_norm": 0.0008173023234121501,
      "learning_rate": 4.5416345412490365e-05,
      "loss": 0.0,
      "step": 1690
    },
    {
      "epoch": 0.37861915367483295,
      "grad_norm": 0.0003803448344115168,
      "learning_rate": 4.537779491133385e-05,
      "loss": 0.0,
      "step": 1700
    },
    {
      "epoch": 0.38084632516703787,
      "grad_norm": 0.0007326370687223971,
      "learning_rate": 4.533924441017733e-05,
      "loss": 0.0,
      "step": 1710
    },
    {
      "epoch": 0.3830734966592428,
      "grad_norm": 0.000820969115011394,
      "learning_rate": 4.5300693909020816e-05,
      "loss": 0.0,
      "step": 1720
    },
    {
      "epoch": 0.38530066815144765,
      "grad_norm": 0.0007523024687543511,
      "learning_rate": 4.526214340786431e-05,
      "loss": 0.0,
      "step": 1730
    },
    {
      "epoch": 0.38752783964365256,
      "grad_norm": 0.0006807052413932979,
      "learning_rate": 4.522359290670779e-05,
      "loss": 0.0001,
      "step": 1740
    },
    {
      "epoch": 0.3897550111358575,
      "grad_norm": 0.0008182713645510375,
      "learning_rate": 4.5185042405551274e-05,
      "loss": 0.0,
      "step": 1750
    },
    {
      "epoch": 0.39198218262806234,
      "grad_norm": 6.073887825012207,
      "learning_rate": 4.514649190439476e-05,
      "loss": 0.0154,
      "step": 1760
    },
    {
      "epoch": 0.39420935412026725,
      "grad_norm": 0.0010553799802437425,
      "learning_rate": 4.510794140323825e-05,
      "loss": 0.0,
      "step": 1770
    },
    {
      "epoch": 0.39643652561247217,
      "grad_norm": 0.0011755876475945115,
      "learning_rate": 4.506939090208173e-05,
      "loss": 0.0652,
      "step": 1780
    },
    {
      "epoch": 0.3986636971046771,
      "grad_norm": 0.0011125204619020224,
      "learning_rate": 4.503084040092521e-05,
      "loss": 0.0699,
      "step": 1790
    },
    {
      "epoch": 0.40089086859688194,
      "grad_norm": 0.0008977939723990858,
      "learning_rate": 4.49922898997687e-05,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 0.40311804008908686,
      "grad_norm": 0.0008301349589601159,
      "learning_rate": 4.495373939861218e-05,
      "loss": 0.0,
      "step": 1810
    },
    {
      "epoch": 0.4053452115812918,
      "grad_norm": 0.001015080721117556,
      "learning_rate": 4.491518889745567e-05,
      "loss": 0.0,
      "step": 1820
    },
    {
      "epoch": 0.40757238307349664,
      "grad_norm": 0.0006330236210487783,
      "learning_rate": 4.487663839629915e-05,
      "loss": 0.0,
      "step": 1830
    },
    {
      "epoch": 0.40979955456570155,
      "grad_norm": 0.0006975868600420654,
      "learning_rate": 4.483808789514264e-05,
      "loss": 0.0,
      "step": 1840
    },
    {
      "epoch": 0.41202672605790647,
      "grad_norm": 0.0004977515200152993,
      "learning_rate": 4.4799537393986125e-05,
      "loss": 0.0,
      "step": 1850
    },
    {
      "epoch": 0.4142538975501114,
      "grad_norm": 0.0007092118612490594,
      "learning_rate": 4.476098689282961e-05,
      "loss": 0.0,
      "step": 1860
    },
    {
      "epoch": 0.41648106904231624,
      "grad_norm": 0.0006570556433871388,
      "learning_rate": 4.472243639167309e-05,
      "loss": 0.0,
      "step": 1870
    },
    {
      "epoch": 0.41870824053452116,
      "grad_norm": 0.0005447635776363313,
      "learning_rate": 4.468388589051658e-05,
      "loss": 0.0,
      "step": 1880
    },
    {
      "epoch": 0.4209354120267261,
      "grad_norm": 0.0005734127480536699,
      "learning_rate": 4.4645335389360067e-05,
      "loss": 0.0,
      "step": 1890
    },
    {
      "epoch": 0.42316258351893093,
      "grad_norm": 0.00027139150188304484,
      "learning_rate": 4.460678488820355e-05,
      "loss": 0.0,
      "step": 1900
    },
    {
      "epoch": 0.42538975501113585,
      "grad_norm": 0.0003526418295223266,
      "learning_rate": 4.4568234387047034e-05,
      "loss": 0.0,
      "step": 1910
    },
    {
      "epoch": 0.42761692650334077,
      "grad_norm": 0.0004612547636497766,
      "learning_rate": 4.452968388589052e-05,
      "loss": 0.0,
      "step": 1920
    },
    {
      "epoch": 0.4298440979955457,
      "grad_norm": 0.00020060790120624006,
      "learning_rate": 4.4491133384734e-05,
      "loss": 0.0,
      "step": 1930
    },
    {
      "epoch": 0.43207126948775054,
      "grad_norm": 0.00025065711815841496,
      "learning_rate": 4.4452582883577485e-05,
      "loss": 0.0,
      "step": 1940
    },
    {
      "epoch": 0.43429844097995546,
      "grad_norm": 0.000687809195369482,
      "learning_rate": 4.4414032382420976e-05,
      "loss": 0.0,
      "step": 1950
    },
    {
      "epoch": 0.4365256124721604,
      "grad_norm": 0.0002696731826290488,
      "learning_rate": 4.437548188126446e-05,
      "loss": 0.0,
      "step": 1960
    },
    {
      "epoch": 0.43875278396436523,
      "grad_norm": 0.00027800185489468277,
      "learning_rate": 4.433693138010794e-05,
      "loss": 0.0,
      "step": 1970
    },
    {
      "epoch": 0.44097995545657015,
      "grad_norm": 0.0003358863468747586,
      "learning_rate": 4.429838087895143e-05,
      "loss": 0.0,
      "step": 1980
    },
    {
      "epoch": 0.44320712694877507,
      "grad_norm": 0.00025063971406780183,
      "learning_rate": 4.425983037779492e-05,
      "loss": 0.0,
      "step": 1990
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.0002283905923832208,
      "learning_rate": 4.42212798766384e-05,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 0.44766146993318484,
      "grad_norm": 0.00028414212283678353,
      "learning_rate": 4.4182729375481885e-05,
      "loss": 0.0,
      "step": 2010
    },
    {
      "epoch": 0.44988864142538976,
      "grad_norm": 0.0002541285357438028,
      "learning_rate": 4.414417887432537e-05,
      "loss": 0.0,
      "step": 2020
    },
    {
      "epoch": 0.4521158129175947,
      "grad_norm": 0.0003097271837759763,
      "learning_rate": 4.410562837316886e-05,
      "loss": 0.0,
      "step": 2030
    },
    {
      "epoch": 0.45434298440979953,
      "grad_norm": 0.00019927140965592116,
      "learning_rate": 4.4067077872012336e-05,
      "loss": 0.0,
      "step": 2040
    },
    {
      "epoch": 0.45657015590200445,
      "grad_norm": 0.0003926644567400217,
      "learning_rate": 4.402852737085582e-05,
      "loss": 0.0,
      "step": 2050
    },
    {
      "epoch": 0.45879732739420936,
      "grad_norm": 0.00026364834047853947,
      "learning_rate": 4.39899768696993e-05,
      "loss": 0.0,
      "step": 2060
    },
    {
      "epoch": 0.4610244988864143,
      "grad_norm": 0.0003544599749147892,
      "learning_rate": 4.3951426368542794e-05,
      "loss": 0.0,
      "step": 2070
    },
    {
      "epoch": 0.46325167037861914,
      "grad_norm": 0.00031236401991918683,
      "learning_rate": 4.391287586738628e-05,
      "loss": 0.0,
      "step": 2080
    },
    {
      "epoch": 0.46547884187082406,
      "grad_norm": 0.00881137978285551,
      "learning_rate": 4.387432536622976e-05,
      "loss": 0.0,
      "step": 2090
    },
    {
      "epoch": 0.46770601336302897,
      "grad_norm": 0.0001897539768833667,
      "learning_rate": 4.3835774865073245e-05,
      "loss": 0.0,
      "step": 2100
    },
    {
      "epoch": 0.46993318485523383,
      "grad_norm": 0.00021031378128100187,
      "learning_rate": 4.3797224363916735e-05,
      "loss": 0.0,
      "step": 2110
    },
    {
      "epoch": 0.47216035634743875,
      "grad_norm": 0.00033220002660527825,
      "learning_rate": 4.375867386276022e-05,
      "loss": 0.0,
      "step": 2120
    },
    {
      "epoch": 0.47438752783964366,
      "grad_norm": 0.00026820923085324466,
      "learning_rate": 4.37201233616037e-05,
      "loss": 0.0,
      "step": 2130
    },
    {
      "epoch": 0.4766146993318486,
      "grad_norm": 0.0003019977011717856,
      "learning_rate": 4.3681572860447187e-05,
      "loss": 0.0,
      "step": 2140
    },
    {
      "epoch": 0.47884187082405344,
      "grad_norm": 0.00016682011482771486,
      "learning_rate": 4.364302235929068e-05,
      "loss": 0.0,
      "step": 2150
    },
    {
      "epoch": 0.48106904231625836,
      "grad_norm": 0.0001762968604452908,
      "learning_rate": 4.360447185813416e-05,
      "loss": 0.0,
      "step": 2160
    },
    {
      "epoch": 0.48329621380846327,
      "grad_norm": 0.0002879390958696604,
      "learning_rate": 4.356592135697764e-05,
      "loss": 0.0,
      "step": 2170
    },
    {
      "epoch": 0.48552338530066813,
      "grad_norm": 0.00030516277183778584,
      "learning_rate": 4.352737085582113e-05,
      "loss": 0.0,
      "step": 2180
    },
    {
      "epoch": 0.48775055679287305,
      "grad_norm": 0.0002903284039348364,
      "learning_rate": 4.348882035466461e-05,
      "loss": 0.0,
      "step": 2190
    },
    {
      "epoch": 0.48997772828507796,
      "grad_norm": 0.00015976096619851887,
      "learning_rate": 4.3450269853508096e-05,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 0.4922048997772829,
      "grad_norm": 0.0001243038714164868,
      "learning_rate": 4.341171935235158e-05,
      "loss": 0.0,
      "step": 2210
    },
    {
      "epoch": 0.49443207126948774,
      "grad_norm": 0.00015202203940134495,
      "learning_rate": 4.337316885119507e-05,
      "loss": 0.0,
      "step": 2220
    },
    {
      "epoch": 0.49665924276169265,
      "grad_norm": 0.00021134661801625043,
      "learning_rate": 4.3334618350038554e-05,
      "loss": 0.0,
      "step": 2230
    },
    {
      "epoch": 0.49888641425389757,
      "grad_norm": 0.0002100022102240473,
      "learning_rate": 4.329606784888204e-05,
      "loss": 0.0,
      "step": 2240
    },
    {
      "epoch": 0.5011135857461024,
      "grad_norm": 0.00020145188318565488,
      "learning_rate": 4.325751734772552e-05,
      "loss": 0.0048,
      "step": 2250
    },
    {
      "epoch": 0.5033407572383074,
      "grad_norm": 0.00019276955572422594,
      "learning_rate": 4.321896684656901e-05,
      "loss": 0.1059,
      "step": 2260
    },
    {
      "epoch": 0.5055679287305123,
      "grad_norm": 0.0002645141794346273,
      "learning_rate": 4.3180416345412495e-05,
      "loss": 0.0,
      "step": 2270
    },
    {
      "epoch": 0.5077951002227171,
      "grad_norm": 0.00018088033539243042,
      "learning_rate": 4.314186584425598e-05,
      "loss": 0.0707,
      "step": 2280
    },
    {
      "epoch": 0.5100222717149221,
      "grad_norm": 0.0005815575714223087,
      "learning_rate": 4.310331534309946e-05,
      "loss": 0.0,
      "step": 2290
    },
    {
      "epoch": 0.512249443207127,
      "grad_norm": 0.0002722882782109082,
      "learning_rate": 4.3064764841942946e-05,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 0.5144766146993318,
      "grad_norm": 0.0003896223206538707,
      "learning_rate": 4.302621434078643e-05,
      "loss": 0.0,
      "step": 2310
    },
    {
      "epoch": 0.5167037861915368,
      "grad_norm": 0.0002769269049167633,
      "learning_rate": 4.2987663839629914e-05,
      "loss": 0.0,
      "step": 2320
    },
    {
      "epoch": 0.5189309576837416,
      "grad_norm": 0.0003637747431639582,
      "learning_rate": 4.2949113338473404e-05,
      "loss": 0.0,
      "step": 2330
    },
    {
      "epoch": 0.5211581291759465,
      "grad_norm": 0.000259217107668519,
      "learning_rate": 4.291056283731689e-05,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 0.5233853006681515,
      "grad_norm": 0.00026838446501642466,
      "learning_rate": 4.287201233616037e-05,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 0.5256124721603563,
      "grad_norm": 0.00020945107098668814,
      "learning_rate": 4.2833461835003855e-05,
      "loss": 0.0,
      "step": 2360
    },
    {
      "epoch": 0.5278396436525612,
      "grad_norm": 0.00010726645268732682,
      "learning_rate": 4.2794911333847346e-05,
      "loss": 0.0,
      "step": 2370
    },
    {
      "epoch": 0.5300668151447662,
      "grad_norm": 0.00023083029373083264,
      "learning_rate": 4.275636083269083e-05,
      "loss": 0.0,
      "step": 2380
    },
    {
      "epoch": 0.532293986636971,
      "grad_norm": 0.0002932041243184358,
      "learning_rate": 4.271781033153431e-05,
      "loss": 0.0,
      "step": 2390
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.00024158954329323024,
      "learning_rate": 4.26792598303778e-05,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 0.5367483296213809,
      "grad_norm": 0.00017432335880585015,
      "learning_rate": 4.264070932922129e-05,
      "loss": 0.0,
      "step": 2410
    },
    {
      "epoch": 0.5389755011135857,
      "grad_norm": 0.00025588905555196106,
      "learning_rate": 4.2602158828064764e-05,
      "loss": 0.0,
      "step": 2420
    },
    {
      "epoch": 0.5412026726057907,
      "grad_norm": 0.00020005925034638494,
      "learning_rate": 4.256360832690825e-05,
      "loss": 0.0,
      "step": 2430
    },
    {
      "epoch": 0.5434298440979956,
      "grad_norm": 1.326442837715149,
      "learning_rate": 4.252505782575173e-05,
      "loss": 0.0002,
      "step": 2440
    },
    {
      "epoch": 0.5456570155902004,
      "grad_norm": 0.000160490395501256,
      "learning_rate": 4.248650732459522e-05,
      "loss": 0.0,
      "step": 2450
    },
    {
      "epoch": 0.5478841870824054,
      "grad_norm": 0.00026525784051045775,
      "learning_rate": 4.2447956823438706e-05,
      "loss": 0.0,
      "step": 2460
    },
    {
      "epoch": 0.5501113585746102,
      "grad_norm": 0.00028466308140195906,
      "learning_rate": 4.240940632228219e-05,
      "loss": 0.0,
      "step": 2470
    },
    {
      "epoch": 0.5523385300668151,
      "grad_norm": 0.0003406311443541199,
      "learning_rate": 4.2370855821125673e-05,
      "loss": 0.0,
      "step": 2480
    },
    {
      "epoch": 0.5545657015590201,
      "grad_norm": 0.0014456204371526837,
      "learning_rate": 4.2332305319969164e-05,
      "loss": 0.1394,
      "step": 2490
    },
    {
      "epoch": 0.5567928730512249,
      "grad_norm": 0.018602000549435616,
      "learning_rate": 4.229375481881265e-05,
      "loss": 0.0006,
      "step": 2500
    },
    {
      "epoch": 0.5590200445434298,
      "grad_norm": 0.004737880080938339,
      "learning_rate": 4.225520431765613e-05,
      "loss": 0.0002,
      "step": 2510
    },
    {
      "epoch": 0.5612472160356348,
      "grad_norm": 0.0007649053004570305,
      "learning_rate": 4.2216653816499615e-05,
      "loss": 0.0001,
      "step": 2520
    },
    {
      "epoch": 0.5634743875278396,
      "grad_norm": 0.00045079676783643663,
      "learning_rate": 4.2178103315343106e-05,
      "loss": 0.0,
      "step": 2530
    },
    {
      "epoch": 0.5657015590200446,
      "grad_norm": 0.002734321402385831,
      "learning_rate": 4.213955281418659e-05,
      "loss": 0.0001,
      "step": 2540
    },
    {
      "epoch": 0.5679287305122495,
      "grad_norm": 0.0004303815949242562,
      "learning_rate": 4.2101002313030066e-05,
      "loss": 0.0001,
      "step": 2550
    },
    {
      "epoch": 0.5701559020044543,
      "grad_norm": 0.0009247238049283624,
      "learning_rate": 4.206245181187356e-05,
      "loss": 0.0001,
      "step": 2560
    },
    {
      "epoch": 0.5723830734966593,
      "grad_norm": 0.0008175800903700292,
      "learning_rate": 4.202390131071704e-05,
      "loss": 0.0,
      "step": 2570
    },
    {
      "epoch": 0.5746102449888641,
      "grad_norm": 0.0006684832042083144,
      "learning_rate": 4.1985350809560524e-05,
      "loss": 0.0,
      "step": 2580
    },
    {
      "epoch": 0.576837416481069,
      "grad_norm": 0.0016378102591261268,
      "learning_rate": 4.194680030840401e-05,
      "loss": 0.0,
      "step": 2590
    },
    {
      "epoch": 0.579064587973274,
      "grad_norm": 0.001343109761364758,
      "learning_rate": 4.19082498072475e-05,
      "loss": 0.0007,
      "step": 2600
    },
    {
      "epoch": 0.5812917594654788,
      "grad_norm": 0.0011126409517601132,
      "learning_rate": 4.186969930609098e-05,
      "loss": 0.0,
      "step": 2610
    },
    {
      "epoch": 0.5835189309576837,
      "grad_norm": 0.0002313750155735761,
      "learning_rate": 4.1831148804934466e-05,
      "loss": 0.0001,
      "step": 2620
    },
    {
      "epoch": 0.5857461024498887,
      "grad_norm": 0.0008886293508112431,
      "learning_rate": 4.179259830377795e-05,
      "loss": 0.0,
      "step": 2630
    },
    {
      "epoch": 0.5879732739420935,
      "grad_norm": 0.00032957884832285345,
      "learning_rate": 4.175404780262144e-05,
      "loss": 0.0869,
      "step": 2640
    },
    {
      "epoch": 0.5902004454342984,
      "grad_norm": 0.0008201717282645404,
      "learning_rate": 4.1715497301464924e-05,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 0.5924276169265034,
      "grad_norm": 0.00025711231864988804,
      "learning_rate": 4.167694680030841e-05,
      "loss": 0.0,
      "step": 2660
    },
    {
      "epoch": 0.5946547884187082,
      "grad_norm": 0.0008011129684746265,
      "learning_rate": 4.163839629915189e-05,
      "loss": 0.0,
      "step": 2670
    },
    {
      "epoch": 0.5968819599109132,
      "grad_norm": 0.0010779767762869596,
      "learning_rate": 4.1599845797995375e-05,
      "loss": 0.0,
      "step": 2680
    },
    {
      "epoch": 0.5991091314031181,
      "grad_norm": 0.0010311354417353868,
      "learning_rate": 4.156129529683886e-05,
      "loss": 0.0,
      "step": 2690
    },
    {
      "epoch": 0.6013363028953229,
      "grad_norm": 0.00023698681616224349,
      "learning_rate": 4.152274479568234e-05,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 0.6035634743875279,
      "grad_norm": 0.00045445479918271303,
      "learning_rate": 4.148419429452583e-05,
      "loss": 0.0,
      "step": 2710
    },
    {
      "epoch": 0.6057906458797327,
      "grad_norm": 0.00023948757734615356,
      "learning_rate": 4.1445643793369317e-05,
      "loss": 0.0,
      "step": 2720
    },
    {
      "epoch": 0.6080178173719376,
      "grad_norm": 0.0005660987226292491,
      "learning_rate": 4.14070932922128e-05,
      "loss": 0.0,
      "step": 2730
    },
    {
      "epoch": 0.6102449888641426,
      "grad_norm": 0.00026418882771395147,
      "learning_rate": 4.1368542791056284e-05,
      "loss": 0.0,
      "step": 2740
    },
    {
      "epoch": 0.6124721603563474,
      "grad_norm": 0.0010307327611371875,
      "learning_rate": 4.1329992289899774e-05,
      "loss": 0.0,
      "step": 2750
    },
    {
      "epoch": 0.6146993318485523,
      "grad_norm": 0.0007111537852324545,
      "learning_rate": 4.129144178874326e-05,
      "loss": 0.0,
      "step": 2760
    },
    {
      "epoch": 0.6169265033407573,
      "grad_norm": 0.00017744976503308862,
      "learning_rate": 4.125289128758674e-05,
      "loss": 0.0,
      "step": 2770
    },
    {
      "epoch": 0.6191536748329621,
      "grad_norm": 0.00018538543372415006,
      "learning_rate": 4.1214340786430226e-05,
      "loss": 0.0,
      "step": 2780
    },
    {
      "epoch": 0.621380846325167,
      "grad_norm": 0.00015498687571380287,
      "learning_rate": 4.1175790285273716e-05,
      "loss": 0.0,
      "step": 2790
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.00032607323373667896,
      "learning_rate": 4.113723978411719e-05,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 0.6258351893095768,
      "grad_norm": 0.00030000731931068003,
      "learning_rate": 4.109868928296068e-05,
      "loss": 0.0,
      "step": 2810
    },
    {
      "epoch": 0.6280623608017817,
      "grad_norm": 0.000638816796708852,
      "learning_rate": 4.106013878180416e-05,
      "loss": 0.0,
      "step": 2820
    },
    {
      "epoch": 0.6302895322939867,
      "grad_norm": 0.0001565155980642885,
      "learning_rate": 4.102158828064765e-05,
      "loss": 0.0,
      "step": 2830
    },
    {
      "epoch": 0.6325167037861915,
      "grad_norm": 0.0030806143768131733,
      "learning_rate": 4.0983037779491135e-05,
      "loss": 0.1463,
      "step": 2840
    },
    {
      "epoch": 0.6347438752783965,
      "grad_norm": 0.007997855544090271,
      "learning_rate": 4.094448727833462e-05,
      "loss": 0.0002,
      "step": 2850
    },
    {
      "epoch": 0.6369710467706013,
      "grad_norm": 0.004887103568762541,
      "learning_rate": 4.09059367771781e-05,
      "loss": 0.0002,
      "step": 2860
    },
    {
      "epoch": 0.6391982182628062,
      "grad_norm": 0.006579360458999872,
      "learning_rate": 4.086738627602159e-05,
      "loss": 0.0002,
      "step": 2870
    },
    {
      "epoch": 0.6414253897550112,
      "grad_norm": 0.0008752902504056692,
      "learning_rate": 4.0828835774865076e-05,
      "loss": 0.0001,
      "step": 2880
    },
    {
      "epoch": 0.643652561247216,
      "grad_norm": 0.005229898728430271,
      "learning_rate": 4.079028527370856e-05,
      "loss": 0.0001,
      "step": 2890
    },
    {
      "epoch": 0.6458797327394209,
      "grad_norm": 0.0022277552634477615,
      "learning_rate": 4.0751734772552044e-05,
      "loss": 0.0001,
      "step": 2900
    },
    {
      "epoch": 0.6481069042316259,
      "grad_norm": 0.0018573213601484895,
      "learning_rate": 4.0713184271395534e-05,
      "loss": 0.0001,
      "step": 2910
    },
    {
      "epoch": 0.6503340757238307,
      "grad_norm": 0.0020243863109499216,
      "learning_rate": 4.067463377023901e-05,
      "loss": 0.0001,
      "step": 2920
    },
    {
      "epoch": 0.6525612472160356,
      "grad_norm": 0.0007021389901638031,
      "learning_rate": 4.0636083269082495e-05,
      "loss": 0.0,
      "step": 2930
    },
    {
      "epoch": 0.6547884187082406,
      "grad_norm": 0.0017332455608993769,
      "learning_rate": 4.0597532767925985e-05,
      "loss": 0.0001,
      "step": 2940
    },
    {
      "epoch": 0.6570155902004454,
      "grad_norm": 0.0018174854340031743,
      "learning_rate": 4.055898226676947e-05,
      "loss": 0.0001,
      "step": 2950
    },
    {
      "epoch": 0.6592427616926503,
      "grad_norm": 0.0015441302675753832,
      "learning_rate": 4.052043176561295e-05,
      "loss": 0.0,
      "step": 2960
    },
    {
      "epoch": 0.6614699331848553,
      "grad_norm": 0.001032699947245419,
      "learning_rate": 4.0481881264456437e-05,
      "loss": 0.0,
      "step": 2970
    },
    {
      "epoch": 0.6636971046770601,
      "grad_norm": 0.00044125542626716197,
      "learning_rate": 4.044333076329993e-05,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 0.6659242761692651,
      "grad_norm": 0.0009667433332651854,
      "learning_rate": 4.040478026214341e-05,
      "loss": 0.0,
      "step": 2990
    },
    {
      "epoch": 0.6681514476614699,
      "grad_norm": 0.0003516009310260415,
      "learning_rate": 4.0366229760986894e-05,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 0.6703786191536748,
      "grad_norm": 0.0015322661492973566,
      "learning_rate": 4.032767925983038e-05,
      "loss": 0.0,
      "step": 3010
    },
    {
      "epoch": 0.6726057906458798,
      "grad_norm": 0.000876994919963181,
      "learning_rate": 4.028912875867387e-05,
      "loss": 0.0,
      "step": 3020
    },
    {
      "epoch": 0.6748329621380846,
      "grad_norm": 0.00034614064497873187,
      "learning_rate": 4.025057825751735e-05,
      "loss": 0.0,
      "step": 3030
    },
    {
      "epoch": 0.6770601336302895,
      "grad_norm": 0.000813994905911386,
      "learning_rate": 4.0212027756360836e-05,
      "loss": 0.0,
      "step": 3040
    },
    {
      "epoch": 0.6792873051224945,
      "grad_norm": 0.00023068086011335254,
      "learning_rate": 4.017347725520432e-05,
      "loss": 0.0,
      "step": 3050
    },
    {
      "epoch": 0.6815144766146993,
      "grad_norm": 0.001094404375180602,
      "learning_rate": 4.0134926754047803e-05,
      "loss": 0.0,
      "step": 3060
    },
    {
      "epoch": 0.6837416481069042,
      "grad_norm": 0.000730548519641161,
      "learning_rate": 4.009637625289129e-05,
      "loss": 0.0,
      "step": 3070
    },
    {
      "epoch": 0.6859688195991092,
      "grad_norm": 0.00039700401248410344,
      "learning_rate": 4.005782575173477e-05,
      "loss": 0.0,
      "step": 3080
    },
    {
      "epoch": 0.688195991091314,
      "grad_norm": 0.0009495611884631217,
      "learning_rate": 4.001927525057826e-05,
      "loss": 0.0,
      "step": 3090
    },
    {
      "epoch": 0.6904231625835189,
      "grad_norm": 0.0005000840174034238,
      "learning_rate": 3.9980724749421745e-05,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 0.6926503340757239,
      "grad_norm": 0.000807891832664609,
      "learning_rate": 3.994217424826523e-05,
      "loss": 0.0,
      "step": 3110
    },
    {
      "epoch": 0.6948775055679287,
      "grad_norm": 0.0007179659442044795,
      "learning_rate": 3.990362374710871e-05,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 0.6971046770601337,
      "grad_norm": 0.00021862825087737292,
      "learning_rate": 3.98650732459522e-05,
      "loss": 0.0,
      "step": 3130
    },
    {
      "epoch": 0.6993318485523385,
      "grad_norm": 0.0007914184825494885,
      "learning_rate": 3.982652274479569e-05,
      "loss": 0.0,
      "step": 3140
    },
    {
      "epoch": 0.7015590200445434,
      "grad_norm": 0.0004448989639058709,
      "learning_rate": 3.978797224363917e-05,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 0.7037861915367484,
      "grad_norm": 0.0005098663386888802,
      "learning_rate": 3.9749421742482654e-05,
      "loss": 0.0,
      "step": 3160
    },
    {
      "epoch": 0.7060133630289532,
      "grad_norm": 0.0004451029235497117,
      "learning_rate": 3.9710871241326145e-05,
      "loss": 0.0,
      "step": 3170
    },
    {
      "epoch": 0.7082405345211581,
      "grad_norm": 0.0002661039470694959,
      "learning_rate": 3.967232074016962e-05,
      "loss": 0.0,
      "step": 3180
    },
    {
      "epoch": 0.7104677060133631,
      "grad_norm": 0.000525188515894115,
      "learning_rate": 3.9633770239013105e-05,
      "loss": 0.0,
      "step": 3190
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.000537294487003237,
      "learning_rate": 3.9595219737856596e-05,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 0.7149220489977728,
      "grad_norm": 0.00024381428374908864,
      "learning_rate": 3.955666923670008e-05,
      "loss": 0.0,
      "step": 3210
    },
    {
      "epoch": 0.7171492204899778,
      "grad_norm": 0.00045926414895802736,
      "learning_rate": 3.951811873554356e-05,
      "loss": 0.0,
      "step": 3220
    },
    {
      "epoch": 0.7193763919821826,
      "grad_norm": 0.00015859499399084598,
      "learning_rate": 3.947956823438705e-05,
      "loss": 0.0,
      "step": 3230
    },
    {
      "epoch": 0.7216035634743875,
      "grad_norm": 0.0007333502871915698,
      "learning_rate": 3.944101773323054e-05,
      "loss": 0.0,
      "step": 3240
    },
    {
      "epoch": 0.7238307349665924,
      "grad_norm": 0.00042863021371886134,
      "learning_rate": 3.940246723207402e-05,
      "loss": 0.0,
      "step": 3250
    },
    {
      "epoch": 0.7260579064587973,
      "grad_norm": 0.00032288357033394277,
      "learning_rate": 3.9363916730917505e-05,
      "loss": 0.0,
      "step": 3260
    },
    {
      "epoch": 0.7282850779510023,
      "grad_norm": 0.0015761787071824074,
      "learning_rate": 3.932536622976099e-05,
      "loss": 0.0,
      "step": 3270
    },
    {
      "epoch": 0.7305122494432071,
      "grad_norm": 0.0004929349524900317,
      "learning_rate": 3.928681572860448e-05,
      "loss": 0.0,
      "step": 3280
    },
    {
      "epoch": 0.732739420935412,
      "grad_norm": 0.0007659941329620779,
      "learning_rate": 3.924826522744796e-05,
      "loss": 0.0,
      "step": 3290
    },
    {
      "epoch": 0.734966592427617,
      "grad_norm": 0.0001819997123675421,
      "learning_rate": 3.920971472629144e-05,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 0.7371937639198218,
      "grad_norm": 0.0018726077396422625,
      "learning_rate": 3.9171164225134923e-05,
      "loss": 0.0,
      "step": 3310
    },
    {
      "epoch": 0.7394209354120267,
      "grad_norm": 0.0013080404605716467,
      "learning_rate": 3.9132613723978414e-05,
      "loss": 0.0,
      "step": 3320
    },
    {
      "epoch": 0.7416481069042317,
      "grad_norm": 0.000130145184812136,
      "learning_rate": 3.90940632228219e-05,
      "loss": 0.0,
      "step": 3330
    },
    {
      "epoch": 0.7438752783964365,
      "grad_norm": 0.00016184076957870275,
      "learning_rate": 3.905551272166538e-05,
      "loss": 0.0,
      "step": 3340
    },
    {
      "epoch": 0.7461024498886414,
      "grad_norm": 0.0008521195850335062,
      "learning_rate": 3.9016962220508865e-05,
      "loss": 0.0,
      "step": 3350
    },
    {
      "epoch": 0.7483296213808464,
      "grad_norm": 0.0007329609361477196,
      "learning_rate": 3.8978411719352356e-05,
      "loss": 0.0,
      "step": 3360
    },
    {
      "epoch": 0.7505567928730512,
      "grad_norm": 0.0005094830994494259,
      "learning_rate": 3.893986121819584e-05,
      "loss": 0.0,
      "step": 3370
    },
    {
      "epoch": 0.7527839643652561,
      "grad_norm": 0.00043443645699881017,
      "learning_rate": 3.890131071703932e-05,
      "loss": 0.0,
      "step": 3380
    },
    {
      "epoch": 0.755011135857461,
      "grad_norm": 0.0002736199530772865,
      "learning_rate": 3.886276021588281e-05,
      "loss": 0.0,
      "step": 3390
    },
    {
      "epoch": 0.7572383073496659,
      "grad_norm": 0.0006232046289369464,
      "learning_rate": 3.88242097147263e-05,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 0.7594654788418709,
      "grad_norm": 0.0004833474522456527,
      "learning_rate": 3.878565921356978e-05,
      "loss": 0.0,
      "step": 3410
    },
    {
      "epoch": 0.7616926503340757,
      "grad_norm": 0.0003467232745606452,
      "learning_rate": 3.8747108712413265e-05,
      "loss": 0.0,
      "step": 3420
    },
    {
      "epoch": 0.7639198218262806,
      "grad_norm": 0.00019307642651256174,
      "learning_rate": 3.870855821125675e-05,
      "loss": 0.0,
      "step": 3430
    },
    {
      "epoch": 0.7661469933184856,
      "grad_norm": 0.00024653508444316685,
      "learning_rate": 3.867000771010023e-05,
      "loss": 0.0,
      "step": 3440
    },
    {
      "epoch": 0.7683741648106904,
      "grad_norm": 0.0002766924735624343,
      "learning_rate": 3.8631457208943716e-05,
      "loss": 0.0,
      "step": 3450
    },
    {
      "epoch": 0.7706013363028953,
      "grad_norm": 0.00018661456124391407,
      "learning_rate": 3.85929067077872e-05,
      "loss": 0.0,
      "step": 3460
    },
    {
      "epoch": 0.7728285077951003,
      "grad_norm": 0.0002908989554271102,
      "learning_rate": 3.855435620663069e-05,
      "loss": 0.0,
      "step": 3470
    },
    {
      "epoch": 0.7750556792873051,
      "grad_norm": 0.00019832549151033163,
      "learning_rate": 3.8515805705474174e-05,
      "loss": 0.0,
      "step": 3480
    },
    {
      "epoch": 0.77728285077951,
      "grad_norm": 7.54355060053058e-05,
      "learning_rate": 3.847725520431766e-05,
      "loss": 0.0,
      "step": 3490
    },
    {
      "epoch": 0.779510022271715,
      "grad_norm": 0.0001069350546458736,
      "learning_rate": 3.843870470316114e-05,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 0.7817371937639198,
      "grad_norm": 0.00010479502816451713,
      "learning_rate": 3.840015420200463e-05,
      "loss": 0.0,
      "step": 3510
    },
    {
      "epoch": 0.7839643652561247,
      "grad_norm": 0.0004789900267496705,
      "learning_rate": 3.8361603700848115e-05,
      "loss": 0.0,
      "step": 3520
    },
    {
      "epoch": 0.7861915367483296,
      "grad_norm": 0.0005450777243822813,
      "learning_rate": 3.83230531996916e-05,
      "loss": 0.0,
      "step": 3530
    },
    {
      "epoch": 0.7884187082405345,
      "grad_norm": 0.0004193396889604628,
      "learning_rate": 3.828450269853508e-05,
      "loss": 0.0,
      "step": 3540
    },
    {
      "epoch": 0.7906458797327395,
      "grad_norm": 0.00011036631622118875,
      "learning_rate": 3.8245952197378567e-05,
      "loss": 0.0,
      "step": 3550
    },
    {
      "epoch": 0.7928730512249443,
      "grad_norm": 0.00018060173897538334,
      "learning_rate": 3.820740169622205e-05,
      "loss": 0.0,
      "step": 3560
    },
    {
      "epoch": 0.7951002227171492,
      "grad_norm": 8.397765486733988e-05,
      "learning_rate": 3.8168851195065534e-05,
      "loss": 0.0,
      "step": 3570
    },
    {
      "epoch": 0.7973273942093542,
      "grad_norm": 0.0003090219688601792,
      "learning_rate": 3.8130300693909024e-05,
      "loss": 0.0,
      "step": 3580
    },
    {
      "epoch": 0.799554565701559,
      "grad_norm": 0.0001417226594639942,
      "learning_rate": 3.809175019275251e-05,
      "loss": 0.0,
      "step": 3590
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 0.00015111034736037254,
      "learning_rate": 3.805319969159599e-05,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 0.8040089086859689,
      "grad_norm": 0.00034429505467414856,
      "learning_rate": 3.8014649190439476e-05,
      "loss": 0.0,
      "step": 3610
    },
    {
      "epoch": 0.8062360801781737,
      "grad_norm": 0.0006685025873593986,
      "learning_rate": 3.7976098689282966e-05,
      "loss": 0.0,
      "step": 3620
    },
    {
      "epoch": 0.8084632516703786,
      "grad_norm": 0.00031737162498757243,
      "learning_rate": 3.793754818812645e-05,
      "loss": 0.0,
      "step": 3630
    },
    {
      "epoch": 0.8106904231625836,
      "grad_norm": 0.00010926082177320495,
      "learning_rate": 3.7898997686969933e-05,
      "loss": 0.0,
      "step": 3640
    },
    {
      "epoch": 0.8129175946547884,
      "grad_norm": 0.0002477818343322724,
      "learning_rate": 3.786044718581342e-05,
      "loss": 0.0,
      "step": 3650
    },
    {
      "epoch": 0.8151447661469933,
      "grad_norm": 0.00034079686156474054,
      "learning_rate": 3.782189668465691e-05,
      "loss": 0.0,
      "step": 3660
    },
    {
      "epoch": 0.8173719376391982,
      "grad_norm": 0.000335868913680315,
      "learning_rate": 3.778334618350039e-05,
      "loss": 0.0,
      "step": 3670
    },
    {
      "epoch": 0.8195991091314031,
      "grad_norm": 0.00026741702458821237,
      "learning_rate": 3.774479568234387e-05,
      "loss": 0.0,
      "step": 3680
    },
    {
      "epoch": 0.821826280623608,
      "grad_norm": 0.00011169997742399573,
      "learning_rate": 3.770624518118735e-05,
      "loss": 0.0,
      "step": 3690
    },
    {
      "epoch": 0.8240534521158129,
      "grad_norm": 0.000188017962500453,
      "learning_rate": 3.766769468003084e-05,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 0.8262806236080178,
      "grad_norm": 0.0009018090204335749,
      "learning_rate": 3.7629144178874326e-05,
      "loss": 0.0,
      "step": 3710
    },
    {
      "epoch": 0.8285077951002228,
      "grad_norm": 0.00038853008300065994,
      "learning_rate": 3.759059367771781e-05,
      "loss": 0.0,
      "step": 3720
    },
    {
      "epoch": 0.8307349665924276,
      "grad_norm": 0.0002484810829628259,
      "learning_rate": 3.7552043176561294e-05,
      "loss": 0.0,
      "step": 3730
    },
    {
      "epoch": 0.8329621380846325,
      "grad_norm": 0.00010042425856227055,
      "learning_rate": 3.7513492675404784e-05,
      "loss": 0.0,
      "step": 3740
    },
    {
      "epoch": 0.8351893095768375,
      "grad_norm": 9.790241165319458e-05,
      "learning_rate": 3.747494217424827e-05,
      "loss": 0.0,
      "step": 3750
    },
    {
      "epoch": 0.8374164810690423,
      "grad_norm": 0.000659428013022989,
      "learning_rate": 3.743639167309175e-05,
      "loss": 0.0,
      "step": 3760
    },
    {
      "epoch": 0.8396436525612472,
      "grad_norm": 0.0004528968711383641,
      "learning_rate": 3.7397841171935235e-05,
      "loss": 0.0,
      "step": 3770
    },
    {
      "epoch": 0.8418708240534521,
      "grad_norm": 0.00035268947249278426,
      "learning_rate": 3.7359290670778726e-05,
      "loss": 0.0,
      "step": 3780
    },
    {
      "epoch": 0.844097995545657,
      "grad_norm": 0.0004908341798000038,
      "learning_rate": 3.732074016962221e-05,
      "loss": 0.0,
      "step": 3790
    },
    {
      "epoch": 0.8463251670378619,
      "grad_norm": 0.00011890262976521626,
      "learning_rate": 3.728218966846569e-05,
      "loss": 0.0,
      "step": 3800
    },
    {
      "epoch": 0.8485523385300668,
      "grad_norm": 0.00010729680070653558,
      "learning_rate": 3.724363916730918e-05,
      "loss": 0.0,
      "step": 3810
    },
    {
      "epoch": 0.8507795100222717,
      "grad_norm": 7.062515214784071e-05,
      "learning_rate": 3.720508866615266e-05,
      "loss": 0.0,
      "step": 3820
    },
    {
      "epoch": 0.8530066815144766,
      "grad_norm": 0.000324057909892872,
      "learning_rate": 3.7166538164996144e-05,
      "loss": 0.0,
      "step": 3830
    },
    {
      "epoch": 0.8552338530066815,
      "grad_norm": 0.0005267088999971747,
      "learning_rate": 3.712798766383963e-05,
      "loss": 0.0,
      "step": 3840
    },
    {
      "epoch": 0.8574610244988864,
      "grad_norm": 0.00027139505255036056,
      "learning_rate": 3.708943716268312e-05,
      "loss": 0.0,
      "step": 3850
    },
    {
      "epoch": 0.8596881959910914,
      "grad_norm": 0.00016888155369088054,
      "learning_rate": 3.70508866615266e-05,
      "loss": 0.0954,
      "step": 3860
    },
    {
      "epoch": 0.8619153674832962,
      "grad_norm": 0.00032672949600964785,
      "learning_rate": 3.7012336160370086e-05,
      "loss": 0.0033,
      "step": 3870
    },
    {
      "epoch": 0.8641425389755011,
      "grad_norm": 0.0001724554313113913,
      "learning_rate": 3.697378565921357e-05,
      "loss": 0.0,
      "step": 3880
    },
    {
      "epoch": 0.8663697104677061,
      "grad_norm": 0.0002712109126150608,
      "learning_rate": 3.693523515805706e-05,
      "loss": 0.0,
      "step": 3890
    },
    {
      "epoch": 0.8685968819599109,
      "grad_norm": 0.010603676550090313,
      "learning_rate": 3.6896684656900544e-05,
      "loss": 0.1446,
      "step": 3900
    },
    {
      "epoch": 0.8708240534521158,
      "grad_norm": 0.0027881055139005184,
      "learning_rate": 3.685813415574403e-05,
      "loss": 0.0001,
      "step": 3910
    },
    {
      "epoch": 0.8730512249443207,
      "grad_norm": 4.310096740722656,
      "learning_rate": 3.681958365458751e-05,
      "loss": 0.0004,
      "step": 3920
    },
    {
      "epoch": 0.8752783964365256,
      "grad_norm": 0.000794135092291981,
      "learning_rate": 3.6781033153430995e-05,
      "loss": 0.0001,
      "step": 3930
    },
    {
      "epoch": 0.8775055679287305,
      "grad_norm": 0.0007558314828202128,
      "learning_rate": 3.674248265227448e-05,
      "loss": 0.0,
      "step": 3940
    },
    {
      "epoch": 0.8797327394209354,
      "grad_norm": 0.0009667762788012624,
      "learning_rate": 3.670393215111796e-05,
      "loss": 0.1451,
      "step": 3950
    },
    {
      "epoch": 0.8819599109131403,
      "grad_norm": 0.008304057642817497,
      "learning_rate": 3.666538164996145e-05,
      "loss": 0.0002,
      "step": 3960
    },
    {
      "epoch": 0.8841870824053452,
      "grad_norm": 0.009379779919981956,
      "learning_rate": 3.662683114880494e-05,
      "loss": 0.0005,
      "step": 3970
    },
    {
      "epoch": 0.8864142538975501,
      "grad_norm": 0.0044534350745379925,
      "learning_rate": 3.658828064764842e-05,
      "loss": 0.0002,
      "step": 3980
    },
    {
      "epoch": 0.888641425389755,
      "grad_norm": 0.0013316356344148517,
      "learning_rate": 3.6549730146491904e-05,
      "loss": 0.0001,
      "step": 3990
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.0021342418622225523,
      "learning_rate": 3.6511179645335395e-05,
      "loss": 0.0001,
      "step": 4000
    },
    {
      "epoch": 0.8930957683741648,
      "grad_norm": 0.0008715993026271462,
      "learning_rate": 3.647262914417888e-05,
      "loss": 0.0001,
      "step": 4010
    },
    {
      "epoch": 0.8953229398663697,
      "grad_norm": 0.0018045090837404132,
      "learning_rate": 3.643407864302236e-05,
      "loss": 0.0001,
      "step": 4020
    },
    {
      "epoch": 0.8975501113585747,
      "grad_norm": 0.001939128153026104,
      "learning_rate": 3.6395528141865846e-05,
      "loss": 0.0001,
      "step": 4030
    },
    {
      "epoch": 0.8997772828507795,
      "grad_norm": 0.001111730351112783,
      "learning_rate": 3.6356977640709336e-05,
      "loss": 0.0,
      "step": 4040
    },
    {
      "epoch": 0.9020044543429844,
      "grad_norm": 0.0006659928476437926,
      "learning_rate": 3.631842713955282e-05,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 0.9042316258351893,
      "grad_norm": 0.001416914165019989,
      "learning_rate": 3.62798766383963e-05,
      "loss": 0.0,
      "step": 4060
    },
    {
      "epoch": 0.9064587973273942,
      "grad_norm": 0.0009254838805645704,
      "learning_rate": 3.624132613723978e-05,
      "loss": 0.0,
      "step": 4070
    },
    {
      "epoch": 0.9086859688195991,
      "grad_norm": 0.001662185532040894,
      "learning_rate": 3.620277563608327e-05,
      "loss": 0.0,
      "step": 4080
    },
    {
      "epoch": 0.910913140311804,
      "grad_norm": 0.001154219382442534,
      "learning_rate": 3.6164225134926755e-05,
      "loss": 0.0,
      "step": 4090
    },
    {
      "epoch": 0.9131403118040089,
      "grad_norm": 0.0007746240007691085,
      "learning_rate": 3.612567463377024e-05,
      "loss": 0.0,
      "step": 4100
    },
    {
      "epoch": 0.9153674832962138,
      "grad_norm": 0.0004333450924605131,
      "learning_rate": 3.608712413261372e-05,
      "loss": 0.0,
      "step": 4110
    },
    {
      "epoch": 0.9175946547884187,
      "grad_norm": 0.000549674965441227,
      "learning_rate": 3.604857363145721e-05,
      "loss": 0.1343,
      "step": 4120
    },
    {
      "epoch": 0.9198218262806236,
      "grad_norm": 0.010792474262416363,
      "learning_rate": 3.6010023130300697e-05,
      "loss": 0.0002,
      "step": 4130
    },
    {
      "epoch": 0.9220489977728286,
      "grad_norm": 0.012424382381141186,
      "learning_rate": 3.597147262914418e-05,
      "loss": 0.0004,
      "step": 4140
    },
    {
      "epoch": 0.9242761692650334,
      "grad_norm": 0.0032044334802776575,
      "learning_rate": 3.5932922127987664e-05,
      "loss": 0.0002,
      "step": 4150
    },
    {
      "epoch": 0.9265033407572383,
      "grad_norm": 0.004874192178249359,
      "learning_rate": 3.5894371626831154e-05,
      "loss": 0.0002,
      "step": 4160
    },
    {
      "epoch": 0.9287305122494433,
      "grad_norm": 0.007116436492651701,
      "learning_rate": 3.585582112567464e-05,
      "loss": 0.0003,
      "step": 4170
    },
    {
      "epoch": 0.9309576837416481,
      "grad_norm": 0.0016408837400376797,
      "learning_rate": 3.5817270624518115e-05,
      "loss": 0.0001,
      "step": 4180
    },
    {
      "epoch": 0.933184855233853,
      "grad_norm": 0.0037043443880975246,
      "learning_rate": 3.5778720123361606e-05,
      "loss": 0.0001,
      "step": 4190
    },
    {
      "epoch": 0.9354120267260579,
      "grad_norm": 0.0040302881971001625,
      "learning_rate": 3.574016962220509e-05,
      "loss": 0.0001,
      "step": 4200
    },
    {
      "epoch": 0.9376391982182628,
      "grad_norm": 0.0012655564351007342,
      "learning_rate": 3.570161912104857e-05,
      "loss": 0.0001,
      "step": 4210
    },
    {
      "epoch": 0.9398663697104677,
      "grad_norm": 0.001611659419722855,
      "learning_rate": 3.566306861989206e-05,
      "loss": 0.0001,
      "step": 4220
    },
    {
      "epoch": 0.9420935412026726,
      "grad_norm": 0.0014023970579728484,
      "learning_rate": 3.562451811873555e-05,
      "loss": 0.0001,
      "step": 4230
    },
    {
      "epoch": 0.9443207126948775,
      "grad_norm": 0.0005503900465555489,
      "learning_rate": 3.558596761757903e-05,
      "loss": 0.0,
      "step": 4240
    },
    {
      "epoch": 0.9465478841870824,
      "grad_norm": 0.003033057786524296,
      "learning_rate": 3.5547417116422515e-05,
      "loss": 0.1242,
      "step": 4250
    },
    {
      "epoch": 0.9487750556792873,
      "grad_norm": 0.006673567462712526,
      "learning_rate": 3.5508866615266e-05,
      "loss": 0.0006,
      "step": 4260
    },
    {
      "epoch": 0.9510022271714922,
      "grad_norm": 0.06423783302307129,
      "learning_rate": 3.547031611410949e-05,
      "loss": 0.1464,
      "step": 4270
    },
    {
      "epoch": 0.9532293986636972,
      "grad_norm": 0.01694420352578163,
      "learning_rate": 3.543176561295297e-05,
      "loss": 0.0908,
      "step": 4280
    },
    {
      "epoch": 0.955456570155902,
      "grad_norm": 0.03369475528597832,
      "learning_rate": 3.5393215111796456e-05,
      "loss": 0.0029,
      "step": 4290
    },
    {
      "epoch": 0.9576837416481069,
      "grad_norm": 0.005296897143125534,
      "learning_rate": 3.535466461063994e-05,
      "loss": 0.0012,
      "step": 4300
    },
    {
      "epoch": 0.9599109131403119,
      "grad_norm": 0.023484662175178528,
      "learning_rate": 3.5316114109483424e-05,
      "loss": 0.1825,
      "step": 4310
    },
    {
      "epoch": 0.9621380846325167,
      "grad_norm": 0.053176578134298325,
      "learning_rate": 3.527756360832691e-05,
      "loss": 0.0031,
      "step": 4320
    },
    {
      "epoch": 0.9643652561247216,
      "grad_norm": 0.0070845577865839005,
      "learning_rate": 3.523901310717039e-05,
      "loss": 0.0011,
      "step": 4330
    },
    {
      "epoch": 0.9665924276169265,
      "grad_norm": 0.003767673159018159,
      "learning_rate": 3.520046260601388e-05,
      "loss": 0.0003,
      "step": 4340
    },
    {
      "epoch": 0.9688195991091314,
      "grad_norm": 0.004564973060041666,
      "learning_rate": 3.5161912104857365e-05,
      "loss": 0.0002,
      "step": 4350
    },
    {
      "epoch": 0.9710467706013363,
      "grad_norm": 0.004497037269175053,
      "learning_rate": 3.512336160370085e-05,
      "loss": 0.0005,
      "step": 4360
    },
    {
      "epoch": 0.9732739420935412,
      "grad_norm": 0.0018037912668660283,
      "learning_rate": 3.508481110254433e-05,
      "loss": 0.0001,
      "step": 4370
    },
    {
      "epoch": 0.9755011135857461,
      "grad_norm": 0.002286855597048998,
      "learning_rate": 3.504626060138782e-05,
      "loss": 0.0837,
      "step": 4380
    },
    {
      "epoch": 0.977728285077951,
      "grad_norm": 0.009217270649969578,
      "learning_rate": 3.500771010023131e-05,
      "loss": 0.0398,
      "step": 4390
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.014495945535600185,
      "learning_rate": 3.496915959907479e-05,
      "loss": 0.0051,
      "step": 4400
    },
    {
      "epoch": 0.9821826280623608,
      "grad_norm": 0.00898067932575941,
      "learning_rate": 3.4930609097918274e-05,
      "loss": 0.0003,
      "step": 4410
    },
    {
      "epoch": 0.9844097995545658,
      "grad_norm": 0.002457557013258338,
      "learning_rate": 3.4892058596761765e-05,
      "loss": 0.0002,
      "step": 4420
    },
    {
      "epoch": 0.9866369710467706,
      "grad_norm": 0.002041054656729102,
      "learning_rate": 3.485350809560524e-05,
      "loss": 0.0001,
      "step": 4430
    },
    {
      "epoch": 0.9888641425389755,
      "grad_norm": 0.0026192411314696074,
      "learning_rate": 3.4814957594448726e-05,
      "loss": 0.0059,
      "step": 4440
    },
    {
      "epoch": 0.9910913140311804,
      "grad_norm": 0.08590298146009445,
      "learning_rate": 3.477640709329221e-05,
      "loss": 0.1082,
      "step": 4450
    },
    {
      "epoch": 0.9933184855233853,
      "grad_norm": 0.01861380971968174,
      "learning_rate": 3.47378565921357e-05,
      "loss": 0.0007,
      "step": 4460
    },
    {
      "epoch": 0.9955456570155902,
      "grad_norm": 0.005441186483949423,
      "learning_rate": 3.4699306090979183e-05,
      "loss": 0.0002,
      "step": 4470
    },
    {
      "epoch": 0.9977728285077951,
      "grad_norm": 0.005446340423077345,
      "learning_rate": 3.466075558982267e-05,
      "loss": 0.0002,
      "step": 4480
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.005642300471663475,
      "learning_rate": 3.462220508866615e-05,
      "loss": 0.1098,
      "step": 4490
    },
    {
      "epoch": 1.0022271714922049,
      "grad_norm": 0.011106941848993301,
      "learning_rate": 3.458365458750964e-05,
      "loss": 0.0002,
      "step": 4500
    },
    {
      "epoch": 1.0044543429844097,
      "grad_norm": 0.008065471425652504,
      "learning_rate": 3.4545104086353125e-05,
      "loss": 0.0003,
      "step": 4510
    },
    {
      "epoch": 1.0066815144766148,
      "grad_norm": 0.003855164395645261,
      "learning_rate": 3.450655358519661e-05,
      "loss": 0.0003,
      "step": 4520
    },
    {
      "epoch": 1.0089086859688197,
      "grad_norm": 0.005031227599829435,
      "learning_rate": 3.446800308404009e-05,
      "loss": 0.0002,
      "step": 4530
    },
    {
      "epoch": 1.0111358574610245,
      "grad_norm": 0.003035234287381172,
      "learning_rate": 3.442945258288358e-05,
      "loss": 0.0002,
      "step": 4540
    },
    {
      "epoch": 1.0133630289532294,
      "grad_norm": 0.005446114111691713,
      "learning_rate": 3.439090208172707e-05,
      "loss": 0.0002,
      "step": 4550
    },
    {
      "epoch": 1.0155902004454342,
      "grad_norm": 0.0019662983249872923,
      "learning_rate": 3.4352351580570544e-05,
      "loss": 0.0002,
      "step": 4560
    },
    {
      "epoch": 1.017817371937639,
      "grad_norm": 0.0020467478316277266,
      "learning_rate": 3.4313801079414034e-05,
      "loss": 0.0002,
      "step": 4570
    },
    {
      "epoch": 1.0200445434298442,
      "grad_norm": 0.0020371011923998594,
      "learning_rate": 3.427525057825752e-05,
      "loss": 0.0001,
      "step": 4580
    },
    {
      "epoch": 1.022271714922049,
      "grad_norm": 0.0036228131502866745,
      "learning_rate": 3.4236700077101e-05,
      "loss": 0.0001,
      "step": 4590
    },
    {
      "epoch": 1.024498886414254,
      "grad_norm": 0.0034036727156490088,
      "learning_rate": 3.4198149575944485e-05,
      "loss": 0.0001,
      "step": 4600
    },
    {
      "epoch": 1.0267260579064588,
      "grad_norm": 0.0021988688968122005,
      "learning_rate": 3.4159599074787976e-05,
      "loss": 0.0001,
      "step": 4610
    },
    {
      "epoch": 1.0289532293986636,
      "grad_norm": 0.0016607851721346378,
      "learning_rate": 3.412104857363146e-05,
      "loss": 0.0001,
      "step": 4620
    },
    {
      "epoch": 1.0311804008908685,
      "grad_norm": 0.003347533755004406,
      "learning_rate": 3.408249807247494e-05,
      "loss": 0.0001,
      "step": 4630
    },
    {
      "epoch": 1.0334075723830736,
      "grad_norm": 0.001296843052841723,
      "learning_rate": 3.404394757131843e-05,
      "loss": 0.0001,
      "step": 4640
    },
    {
      "epoch": 1.0356347438752784,
      "grad_norm": 0.003074715146794915,
      "learning_rate": 3.400539707016192e-05,
      "loss": 0.0001,
      "step": 4650
    },
    {
      "epoch": 1.0378619153674833,
      "grad_norm": 0.001008590217679739,
      "learning_rate": 3.39668465690054e-05,
      "loss": 0.0001,
      "step": 4660
    },
    {
      "epoch": 1.0400890868596881,
      "grad_norm": 0.0010433803545311093,
      "learning_rate": 3.3928296067848885e-05,
      "loss": 0.0001,
      "step": 4670
    },
    {
      "epoch": 1.042316258351893,
      "grad_norm": 0.0015513584949076176,
      "learning_rate": 3.388974556669237e-05,
      "loss": 0.0001,
      "step": 4680
    },
    {
      "epoch": 1.044543429844098,
      "grad_norm": 0.001631392166018486,
      "learning_rate": 3.385119506553585e-05,
      "loss": 0.0001,
      "step": 4690
    },
    {
      "epoch": 1.046770601336303,
      "grad_norm": 0.0015330935129895806,
      "learning_rate": 3.3812644564379336e-05,
      "loss": 0.0001,
      "step": 4700
    },
    {
      "epoch": 1.0489977728285078,
      "grad_norm": 0.0012752895709127188,
      "learning_rate": 3.377409406322282e-05,
      "loss": 0.0001,
      "step": 4710
    },
    {
      "epoch": 1.0512249443207127,
      "grad_norm": 0.0009389714105054736,
      "learning_rate": 3.373554356206631e-05,
      "loss": 0.0001,
      "step": 4720
    },
    {
      "epoch": 1.0534521158129175,
      "grad_norm": 0.0008629551157355309,
      "learning_rate": 3.3696993060909794e-05,
      "loss": 0.0001,
      "step": 4730
    },
    {
      "epoch": 1.0556792873051224,
      "grad_norm": 0.0009982050396502018,
      "learning_rate": 3.365844255975328e-05,
      "loss": 0.0001,
      "step": 4740
    },
    {
      "epoch": 1.0579064587973275,
      "grad_norm": 0.0014613802777603269,
      "learning_rate": 3.361989205859676e-05,
      "loss": 0.0,
      "step": 4750
    },
    {
      "epoch": 1.0601336302895323,
      "grad_norm": 0.0022279205732047558,
      "learning_rate": 3.358134155744025e-05,
      "loss": 0.1274,
      "step": 4760
    },
    {
      "epoch": 1.0623608017817372,
      "grad_norm": 0.001650593476369977,
      "learning_rate": 3.3542791056283736e-05,
      "loss": 0.0345,
      "step": 4770
    },
    {
      "epoch": 1.064587973273942,
      "grad_norm": 0.0018556411378085613,
      "learning_rate": 3.350424055512722e-05,
      "loss": 0.0001,
      "step": 4780
    },
    {
      "epoch": 1.066815144766147,
      "grad_norm": 8.49226188659668,
      "learning_rate": 3.34656900539707e-05,
      "loss": 0.0837,
      "step": 4790
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 0.011482222005724907,
      "learning_rate": 3.3427139552814193e-05,
      "loss": 0.0003,
      "step": 4800
    },
    {
      "epoch": 1.0712694877505569,
      "grad_norm": 0.014159686863422394,
      "learning_rate": 3.338858905165767e-05,
      "loss": 0.0007,
      "step": 4810
    },
    {
      "epoch": 1.0734966592427617,
      "grad_norm": 0.006592317949980497,
      "learning_rate": 3.3350038550501154e-05,
      "loss": 0.0003,
      "step": 4820
    },
    {
      "epoch": 1.0757238307349666,
      "grad_norm": 0.006075285375118256,
      "learning_rate": 3.3311488049344645e-05,
      "loss": 0.0002,
      "step": 4830
    },
    {
      "epoch": 1.0779510022271714,
      "grad_norm": 0.008220065385103226,
      "learning_rate": 3.327293754818813e-05,
      "loss": 0.1507,
      "step": 4840
    },
    {
      "epoch": 1.0801781737193763,
      "grad_norm": 0.005131538957357407,
      "learning_rate": 3.323438704703161e-05,
      "loss": 0.0003,
      "step": 4850
    },
    {
      "epoch": 1.0824053452115814,
      "grad_norm": 0.006947116926312447,
      "learning_rate": 3.3195836545875096e-05,
      "loss": 0.0357,
      "step": 4860
    },
    {
      "epoch": 1.0846325167037862,
      "grad_norm": 0.007902241311967373,
      "learning_rate": 3.3157286044718586e-05,
      "loss": 0.0002,
      "step": 4870
    },
    {
      "epoch": 1.086859688195991,
      "grad_norm": 0.0036578578874468803,
      "learning_rate": 3.311873554356207e-05,
      "loss": 0.0001,
      "step": 4880
    },
    {
      "epoch": 1.089086859688196,
      "grad_norm": 0.0022869252134114504,
      "learning_rate": 3.3080185042405554e-05,
      "loss": 0.0001,
      "step": 4890
    },
    {
      "epoch": 1.0913140311804008,
      "grad_norm": 0.0036631945986300707,
      "learning_rate": 3.304163454124904e-05,
      "loss": 0.0001,
      "step": 4900
    },
    {
      "epoch": 1.093541202672606,
      "grad_norm": 0.005049917381256819,
      "learning_rate": 3.300308404009253e-05,
      "loss": 0.0001,
      "step": 4910
    },
    {
      "epoch": 1.0957683741648108,
      "grad_norm": 0.0018736602505668998,
      "learning_rate": 3.296453353893601e-05,
      "loss": 0.0001,
      "step": 4920
    },
    {
      "epoch": 1.0979955456570156,
      "grad_norm": 0.001670879079028964,
      "learning_rate": 3.2925983037779495e-05,
      "loss": 0.0001,
      "step": 4930
    },
    {
      "epoch": 1.1002227171492205,
      "grad_norm": 0.002236241940408945,
      "learning_rate": 3.288743253662297e-05,
      "loss": 0.0001,
      "step": 4940
    },
    {
      "epoch": 1.1024498886414253,
      "grad_norm": 0.0014213103568181396,
      "learning_rate": 3.284888203546646e-05,
      "loss": 0.0001,
      "step": 4950
    },
    {
      "epoch": 1.1046770601336302,
      "grad_norm": 0.0022291853092610836,
      "learning_rate": 3.2810331534309946e-05,
      "loss": 0.0001,
      "step": 4960
    },
    {
      "epoch": 1.1069042316258353,
      "grad_norm": 0.0015065936604514718,
      "learning_rate": 3.277178103315343e-05,
      "loss": 0.0001,
      "step": 4970
    },
    {
      "epoch": 1.1091314031180401,
      "grad_norm": 0.0025117392651736736,
      "learning_rate": 3.2733230531996914e-05,
      "loss": 0.0806,
      "step": 4980
    },
    {
      "epoch": 1.111358574610245,
      "grad_norm": 0.019429584965109825,
      "learning_rate": 3.2694680030840404e-05,
      "loss": 0.0002,
      "step": 4990
    },
    {
      "epoch": 1.1135857461024499,
      "grad_norm": 0.0044836984016001225,
      "learning_rate": 3.265612952968389e-05,
      "loss": 0.0001,
      "step": 5000
    },
    {
      "epoch": 1.1158129175946547,
      "grad_norm": 0.005627152975648642,
      "learning_rate": 3.261757902852737e-05,
      "loss": 0.0001,
      "step": 5010
    },
    {
      "epoch": 1.1180400890868596,
      "grad_norm": 0.0017041133251041174,
      "learning_rate": 3.2579028527370856e-05,
      "loss": 0.0001,
      "step": 5020
    },
    {
      "epoch": 1.1202672605790647,
      "grad_norm": 0.004246249329298735,
      "learning_rate": 3.2540478026214346e-05,
      "loss": 0.0001,
      "step": 5030
    },
    {
      "epoch": 1.1224944320712695,
      "grad_norm": 0.003832840360701084,
      "learning_rate": 3.250192752505783e-05,
      "loss": 0.0001,
      "step": 5040
    },
    {
      "epoch": 1.1247216035634744,
      "grad_norm": 0.0008860721718519926,
      "learning_rate": 3.2463377023901313e-05,
      "loss": 0.0001,
      "step": 5050
    },
    {
      "epoch": 1.1269487750556793,
      "grad_norm": 0.0009854534873738885,
      "learning_rate": 3.24248265227448e-05,
      "loss": 0.0637,
      "step": 5060
    },
    {
      "epoch": 1.1291759465478841,
      "grad_norm": 0.0008990425849333405,
      "learning_rate": 3.238627602158828e-05,
      "loss": 0.0001,
      "step": 5070
    },
    {
      "epoch": 1.131403118040089,
      "grad_norm": 0.000836206367239356,
      "learning_rate": 3.2347725520431765e-05,
      "loss": 0.0001,
      "step": 5080
    },
    {
      "epoch": 1.133630289532294,
      "grad_norm": 0.0028109350241720676,
      "learning_rate": 3.230917501927525e-05,
      "loss": 0.0001,
      "step": 5090
    },
    {
      "epoch": 1.135857461024499,
      "grad_norm": 0.0020337903406471014,
      "learning_rate": 3.227062451811874e-05,
      "loss": 0.0001,
      "step": 5100
    },
    {
      "epoch": 1.1380846325167038,
      "grad_norm": 0.003053826279938221,
      "learning_rate": 3.223207401696222e-05,
      "loss": 0.0,
      "step": 5110
    },
    {
      "epoch": 1.1403118040089086,
      "grad_norm": 0.0010885795345529914,
      "learning_rate": 3.2193523515805706e-05,
      "loss": 0.0,
      "step": 5120
    },
    {
      "epoch": 1.1425389755011135,
      "grad_norm": 0.0007791733369231224,
      "learning_rate": 3.215497301464919e-05,
      "loss": 0.0,
      "step": 5130
    },
    {
      "epoch": 1.1447661469933186,
      "grad_norm": 0.0014236945426091552,
      "learning_rate": 3.211642251349268e-05,
      "loss": 0.0,
      "step": 5140
    },
    {
      "epoch": 1.1469933184855234,
      "grad_norm": 0.0020575381349772215,
      "learning_rate": 3.2077872012336164e-05,
      "loss": 0.0001,
      "step": 5150
    },
    {
      "epoch": 1.1492204899777283,
      "grad_norm": 0.001591063686646521,
      "learning_rate": 3.203932151117965e-05,
      "loss": 0.0,
      "step": 5160
    },
    {
      "epoch": 1.1514476614699332,
      "grad_norm": 0.0006940145394764841,
      "learning_rate": 3.200077101002313e-05,
      "loss": 0.0,
      "step": 5170
    },
    {
      "epoch": 1.153674832962138,
      "grad_norm": 0.001027130987495184,
      "learning_rate": 3.196222050886662e-05,
      "loss": 0.0,
      "step": 5180
    },
    {
      "epoch": 1.1559020044543429,
      "grad_norm": 0.0008381050429306924,
      "learning_rate": 3.19236700077101e-05,
      "loss": 0.0,
      "step": 5190
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 0.0013028769753873348,
      "learning_rate": 3.188511950655358e-05,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 1.1603563474387528,
      "grad_norm": 0.0012028402416035533,
      "learning_rate": 3.184656900539707e-05,
      "loss": 0.0457,
      "step": 5210
    },
    {
      "epoch": 1.1625835189309577,
      "grad_norm": 1.5365265607833862,
      "learning_rate": 3.180801850424056e-05,
      "loss": 0.1317,
      "step": 5220
    },
    {
      "epoch": 1.1648106904231625,
      "grad_norm": 0.0008418929646722972,
      "learning_rate": 3.176946800308404e-05,
      "loss": 0.0369,
      "step": 5230
    },
    {
      "epoch": 1.1670378619153674,
      "grad_norm": 0.000904734421055764,
      "learning_rate": 3.1730917501927524e-05,
      "loss": 0.0,
      "step": 5240
    },
    {
      "epoch": 1.1692650334075725,
      "grad_norm": 0.0012151561677455902,
      "learning_rate": 3.1692367000771015e-05,
      "loss": 0.0,
      "step": 5250
    },
    {
      "epoch": 1.1714922048997773,
      "grad_norm": 0.0008024175767786801,
      "learning_rate": 3.16538164996145e-05,
      "loss": 0.0,
      "step": 5260
    },
    {
      "epoch": 1.1737193763919822,
      "grad_norm": 0.0006243258831091225,
      "learning_rate": 3.161526599845798e-05,
      "loss": 0.0,
      "step": 5270
    },
    {
      "epoch": 1.175946547884187,
      "grad_norm": 0.008797843009233475,
      "learning_rate": 3.1576715497301466e-05,
      "loss": 0.0001,
      "step": 5280
    },
    {
      "epoch": 1.178173719376392,
      "grad_norm": 0.0013678994728252292,
      "learning_rate": 3.1538164996144956e-05,
      "loss": 0.0001,
      "step": 5290
    },
    {
      "epoch": 1.1804008908685968,
      "grad_norm": 0.0015582303749397397,
      "learning_rate": 3.149961449498844e-05,
      "loss": 0.0001,
      "step": 5300
    },
    {
      "epoch": 1.1826280623608019,
      "grad_norm": 0.0006623835652135313,
      "learning_rate": 3.1461063993831924e-05,
      "loss": 0.0,
      "step": 5310
    },
    {
      "epoch": 1.1848552338530067,
      "grad_norm": 0.0010605413699522614,
      "learning_rate": 3.14225134926754e-05,
      "loss": 0.0,
      "step": 5320
    },
    {
      "epoch": 1.1870824053452116,
      "grad_norm": 0.002074113581329584,
      "learning_rate": 3.138396299151889e-05,
      "loss": 0.0,
      "step": 5330
    },
    {
      "epoch": 1.1893095768374164,
      "grad_norm": 0.0004945037071593106,
      "learning_rate": 3.1345412490362375e-05,
      "loss": 0.0,
      "step": 5340
    },
    {
      "epoch": 1.1915367483296213,
      "grad_norm": 0.0017316138837486506,
      "learning_rate": 3.130686198920586e-05,
      "loss": 0.0,
      "step": 5350
    },
    {
      "epoch": 1.1937639198218264,
      "grad_norm": 0.0007202624110504985,
      "learning_rate": 3.126831148804934e-05,
      "loss": 0.0,
      "step": 5360
    },
    {
      "epoch": 1.1959910913140313,
      "grad_norm": 0.0009675301844254136,
      "learning_rate": 3.122976098689283e-05,
      "loss": 0.0,
      "step": 5370
    },
    {
      "epoch": 1.1982182628062361,
      "grad_norm": 0.0007570991292595863,
      "learning_rate": 3.119121048573632e-05,
      "loss": 0.0,
      "step": 5380
    },
    {
      "epoch": 1.200445434298441,
      "grad_norm": 0.0006302893743850291,
      "learning_rate": 3.11526599845798e-05,
      "loss": 0.0,
      "step": 5390
    },
    {
      "epoch": 1.2026726057906458,
      "grad_norm": 0.0004587925795931369,
      "learning_rate": 3.1114109483423284e-05,
      "loss": 0.0,
      "step": 5400
    },
    {
      "epoch": 1.2048997772828507,
      "grad_norm": 0.0016935375751927495,
      "learning_rate": 3.1075558982266775e-05,
      "loss": 0.0,
      "step": 5410
    },
    {
      "epoch": 1.2071269487750558,
      "grad_norm": 0.0005877453368157148,
      "learning_rate": 3.103700848111026e-05,
      "loss": 0.0,
      "step": 5420
    },
    {
      "epoch": 1.2093541202672606,
      "grad_norm": 0.003680687863379717,
      "learning_rate": 3.099845797995374e-05,
      "loss": 0.0399,
      "step": 5430
    },
    {
      "epoch": 1.2115812917594655,
      "grad_norm": 0.0008010804303921759,
      "learning_rate": 3.0959907478797226e-05,
      "loss": 0.0003,
      "step": 5440
    },
    {
      "epoch": 1.2138084632516704,
      "grad_norm": 0.0009090443491004407,
      "learning_rate": 3.092135697764071e-05,
      "loss": 0.0,
      "step": 5450
    },
    {
      "epoch": 1.2160356347438752,
      "grad_norm": 0.0009170587291009724,
      "learning_rate": 3.088280647648419e-05,
      "loss": 0.0,
      "step": 5460
    },
    {
      "epoch": 1.2182628062360803,
      "grad_norm": 5.189276695251465,
      "learning_rate": 3.084425597532768e-05,
      "loss": 0.1413,
      "step": 5470
    },
    {
      "epoch": 1.2204899777282852,
      "grad_norm": 0.005780596751719713,
      "learning_rate": 3.080570547417117e-05,
      "loss": 0.0002,
      "step": 5480
    },
    {
      "epoch": 1.22271714922049,
      "grad_norm": 0.01006004773080349,
      "learning_rate": 3.076715497301465e-05,
      "loss": 0.0007,
      "step": 5490
    },
    {
      "epoch": 1.2249443207126949,
      "grad_norm": 0.0074781449511647224,
      "learning_rate": 3.0728604471858135e-05,
      "loss": 0.0003,
      "step": 5500
    },
    {
      "epoch": 1.2271714922048997,
      "grad_norm": 0.010784213431179523,
      "learning_rate": 3.069005397070162e-05,
      "loss": 0.0001,
      "step": 5510
    },
    {
      "epoch": 1.2293986636971046,
      "grad_norm": 0.002753941109403968,
      "learning_rate": 3.065150346954511e-05,
      "loss": 0.0001,
      "step": 5520
    },
    {
      "epoch": 1.2316258351893095,
      "grad_norm": 0.0039026248268783092,
      "learning_rate": 3.061295296838859e-05,
      "loss": 0.0001,
      "step": 5530
    },
    {
      "epoch": 1.2338530066815145,
      "grad_norm": 0.0011363894445821643,
      "learning_rate": 3.0574402467232076e-05,
      "loss": 0.0001,
      "step": 5540
    },
    {
      "epoch": 1.2360801781737194,
      "grad_norm": 0.0008700927719473839,
      "learning_rate": 3.053585196607556e-05,
      "loss": 0.0001,
      "step": 5550
    },
    {
      "epoch": 1.2383073496659243,
      "grad_norm": 0.0010124619584530592,
      "learning_rate": 3.0497301464919047e-05,
      "loss": 0.0001,
      "step": 5560
    },
    {
      "epoch": 1.2405345211581291,
      "grad_norm": 0.004025884438306093,
      "learning_rate": 3.0458750963762528e-05,
      "loss": 0.0001,
      "step": 5570
    },
    {
      "epoch": 1.242761692650334,
      "grad_norm": 0.0011501286644488573,
      "learning_rate": 3.0420200462606015e-05,
      "loss": 0.0001,
      "step": 5580
    },
    {
      "epoch": 1.244988864142539,
      "grad_norm": 0.00328311906196177,
      "learning_rate": 3.03816499614495e-05,
      "loss": 0.0001,
      "step": 5590
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 0.002304644789546728,
      "learning_rate": 3.0343099460292986e-05,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 1.2494432071269488,
      "grad_norm": 0.0008951505296863616,
      "learning_rate": 3.030454895913647e-05,
      "loss": 0.0,
      "step": 5610
    },
    {
      "epoch": 1.2516703786191536,
      "grad_norm": 0.0014322589850053191,
      "learning_rate": 3.0265998457979956e-05,
      "loss": 0.0001,
      "step": 5620
    },
    {
      "epoch": 1.2538975501113585,
      "grad_norm": 0.0013697169488295913,
      "learning_rate": 3.022744795682344e-05,
      "loss": 0.0,
      "step": 5630
    },
    {
      "epoch": 1.2561247216035634,
      "grad_norm": 0.001387872500345111,
      "learning_rate": 3.0188897455666927e-05,
      "loss": 0.0001,
      "step": 5640
    },
    {
      "epoch": 1.2583518930957684,
      "grad_norm": 0.0010183562990278006,
      "learning_rate": 3.015034695451041e-05,
      "loss": 0.0,
      "step": 5650
    },
    {
      "epoch": 1.2605790645879733,
      "grad_norm": 0.0013937574112787843,
      "learning_rate": 3.0111796453353898e-05,
      "loss": 0.0,
      "step": 5660
    },
    {
      "epoch": 1.2628062360801782,
      "grad_norm": 0.000413422443671152,
      "learning_rate": 3.0073245952197382e-05,
      "loss": 0.0,
      "step": 5670
    },
    {
      "epoch": 1.265033407572383,
      "grad_norm": 0.0011191831436008215,
      "learning_rate": 3.003469545104087e-05,
      "loss": 0.0,
      "step": 5680
    },
    {
      "epoch": 1.267260579064588,
      "grad_norm": 0.0008007407886907458,
      "learning_rate": 2.9996144949884346e-05,
      "loss": 0.0,
      "step": 5690
    },
    {
      "epoch": 1.269487750556793,
      "grad_norm": 0.0008943395223468542,
      "learning_rate": 2.9957594448727833e-05,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 1.2717149220489978,
      "grad_norm": 0.0005292086279951036,
      "learning_rate": 2.9919043947571317e-05,
      "loss": 0.0,
      "step": 5710
    },
    {
      "epoch": 1.2739420935412027,
      "grad_norm": 0.0021183977369219065,
      "learning_rate": 2.9880493446414804e-05,
      "loss": 0.0,
      "step": 5720
    },
    {
      "epoch": 1.2761692650334076,
      "grad_norm": 0.002759388415142894,
      "learning_rate": 2.9841942945258287e-05,
      "loss": 0.0,
      "step": 5730
    },
    {
      "epoch": 1.2783964365256124,
      "grad_norm": 0.0007083702948875725,
      "learning_rate": 2.9803392444101774e-05,
      "loss": 0.0,
      "step": 5740
    },
    {
      "epoch": 1.2806236080178173,
      "grad_norm": 0.0005059570539742708,
      "learning_rate": 2.9764841942945258e-05,
      "loss": 0.0,
      "step": 5750
    },
    {
      "epoch": 1.2828507795100224,
      "grad_norm": 0.0022701029665768147,
      "learning_rate": 2.9726291441788745e-05,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 1.2850779510022272,
      "grad_norm": 0.0015040922444313765,
      "learning_rate": 2.968774094063223e-05,
      "loss": 0.0,
      "step": 5770
    },
    {
      "epoch": 1.287305122494432,
      "grad_norm": 0.0007673162617720664,
      "learning_rate": 2.9649190439475716e-05,
      "loss": 0.0,
      "step": 5780
    },
    {
      "epoch": 1.289532293986637,
      "grad_norm": 0.0016098967753350735,
      "learning_rate": 2.96106399383192e-05,
      "loss": 0.0,
      "step": 5790
    },
    {
      "epoch": 1.2917594654788418,
      "grad_norm": 0.0009788809111341834,
      "learning_rate": 2.9572089437162687e-05,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 1.2939866369710469,
      "grad_norm": 0.0013865643413737416,
      "learning_rate": 2.953353893600617e-05,
      "loss": 0.0,
      "step": 5810
    },
    {
      "epoch": 1.2962138084632517,
      "grad_norm": 0.0019490007543936372,
      "learning_rate": 2.949498843484965e-05,
      "loss": 0.1162,
      "step": 5820
    },
    {
      "epoch": 1.2984409799554566,
      "grad_norm": 0.004460920579731464,
      "learning_rate": 2.9456437933693138e-05,
      "loss": 0.0004,
      "step": 5830
    },
    {
      "epoch": 1.3006681514476615,
      "grad_norm": 0.003187498776242137,
      "learning_rate": 2.9417887432536622e-05,
      "loss": 0.0001,
      "step": 5840
    },
    {
      "epoch": 1.3028953229398663,
      "grad_norm": 0.0018679111963137984,
      "learning_rate": 2.937933693138011e-05,
      "loss": 0.0001,
      "step": 5850
    },
    {
      "epoch": 1.3051224944320712,
      "grad_norm": 0.0016402002656832337,
      "learning_rate": 2.9340786430223593e-05,
      "loss": 0.0001,
      "step": 5860
    },
    {
      "epoch": 1.307349665924276,
      "grad_norm": 0.0016862229676917195,
      "learning_rate": 2.930223592906708e-05,
      "loss": 0.0001,
      "step": 5870
    },
    {
      "epoch": 1.3095768374164811,
      "grad_norm": 0.008272766135632992,
      "learning_rate": 2.9263685427910563e-05,
      "loss": 0.1179,
      "step": 5880
    },
    {
      "epoch": 1.311804008908686,
      "grad_norm": 0.016305891796946526,
      "learning_rate": 2.922513492675405e-05,
      "loss": 0.0016,
      "step": 5890
    },
    {
      "epoch": 1.3140311804008908,
      "grad_norm": 0.013389138504862785,
      "learning_rate": 2.9186584425597534e-05,
      "loss": 0.0005,
      "step": 5900
    },
    {
      "epoch": 1.3162583518930957,
      "grad_norm": 0.004036020953208208,
      "learning_rate": 2.914803392444102e-05,
      "loss": 0.0002,
      "step": 5910
    },
    {
      "epoch": 1.3184855233853008,
      "grad_norm": 0.0018805762520059943,
      "learning_rate": 2.9109483423284505e-05,
      "loss": 0.0001,
      "step": 5920
    },
    {
      "epoch": 1.3207126948775056,
      "grad_norm": 0.0016349803190678358,
      "learning_rate": 2.9070932922127992e-05,
      "loss": 0.0001,
      "step": 5930
    },
    {
      "epoch": 1.3229398663697105,
      "grad_norm": 0.0014406576519832015,
      "learning_rate": 2.9032382420971476e-05,
      "loss": 0.0001,
      "step": 5940
    },
    {
      "epoch": 1.3251670378619154,
      "grad_norm": 0.0034317574463784695,
      "learning_rate": 2.8993831919814956e-05,
      "loss": 0.0001,
      "step": 5950
    },
    {
      "epoch": 1.3273942093541202,
      "grad_norm": 0.0021904667373746634,
      "learning_rate": 2.8955281418658443e-05,
      "loss": 0.0001,
      "step": 5960
    },
    {
      "epoch": 1.329621380846325,
      "grad_norm": 0.0018436844693496823,
      "learning_rate": 2.8916730917501927e-05,
      "loss": 0.0001,
      "step": 5970
    },
    {
      "epoch": 1.33184855233853,
      "grad_norm": 0.0006677725468762219,
      "learning_rate": 2.8878180416345414e-05,
      "loss": 0.0001,
      "step": 5980
    },
    {
      "epoch": 1.334075723830735,
      "grad_norm": 0.0010744460159912705,
      "learning_rate": 2.8839629915188898e-05,
      "loss": 0.0001,
      "step": 5990
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 0.002190809929743409,
      "learning_rate": 2.8801079414032385e-05,
      "loss": 0.0001,
      "step": 6000
    },
    {
      "epoch": 1.3385300668151447,
      "grad_norm": 0.001202732790261507,
      "learning_rate": 2.876252891287587e-05,
      "loss": 0.0,
      "step": 6010
    },
    {
      "epoch": 1.3407572383073496,
      "grad_norm": 0.0009515125420875847,
      "learning_rate": 2.8723978411719356e-05,
      "loss": 0.0001,
      "step": 6020
    },
    {
      "epoch": 1.3429844097995547,
      "grad_norm": 0.0010124974651262164,
      "learning_rate": 2.868542791056284e-05,
      "loss": 0.0,
      "step": 6030
    },
    {
      "epoch": 1.3452115812917596,
      "grad_norm": 0.0007879985496401787,
      "learning_rate": 2.8646877409406327e-05,
      "loss": 0.0,
      "step": 6040
    },
    {
      "epoch": 1.3474387527839644,
      "grad_norm": 0.0013290154747664928,
      "learning_rate": 2.860832690824981e-05,
      "loss": 0.0,
      "step": 6050
    },
    {
      "epoch": 1.3496659242761693,
      "grad_norm": 0.0019963758531957865,
      "learning_rate": 2.8569776407093297e-05,
      "loss": 0.0,
      "step": 6060
    },
    {
      "epoch": 1.3518930957683741,
      "grad_norm": 0.0007348745712079108,
      "learning_rate": 2.8531225905936774e-05,
      "loss": 0.0,
      "step": 6070
    },
    {
      "epoch": 1.354120267260579,
      "grad_norm": 0.0008901248802430928,
      "learning_rate": 2.849267540478026e-05,
      "loss": 0.0,
      "step": 6080
    },
    {
      "epoch": 1.3563474387527839,
      "grad_norm": 0.001462399959564209,
      "learning_rate": 2.8454124903623745e-05,
      "loss": 0.0,
      "step": 6090
    },
    {
      "epoch": 1.358574610244989,
      "grad_norm": 0.0010686405003070831,
      "learning_rate": 2.8415574402467232e-05,
      "loss": 0.0,
      "step": 6100
    },
    {
      "epoch": 1.3608017817371938,
      "grad_norm": 0.0010669669136404991,
      "learning_rate": 2.8377023901310716e-05,
      "loss": 0.0,
      "step": 6110
    },
    {
      "epoch": 1.3630289532293987,
      "grad_norm": 0.0006517975707538426,
      "learning_rate": 2.8338473400154203e-05,
      "loss": 0.0,
      "step": 6120
    },
    {
      "epoch": 1.3652561247216035,
      "grad_norm": 0.0011815542820841074,
      "learning_rate": 2.8299922898997687e-05,
      "loss": 0.0001,
      "step": 6130
    },
    {
      "epoch": 1.3674832962138086,
      "grad_norm": 0.001589005347341299,
      "learning_rate": 2.8261372397841174e-05,
      "loss": 0.0,
      "step": 6140
    },
    {
      "epoch": 1.3697104677060135,
      "grad_norm": 0.0003907177597284317,
      "learning_rate": 2.8222821896684658e-05,
      "loss": 0.0,
      "step": 6150
    },
    {
      "epoch": 1.3719376391982183,
      "grad_norm": 0.0005675466964021325,
      "learning_rate": 2.8184271395528145e-05,
      "loss": 0.0,
      "step": 6160
    },
    {
      "epoch": 1.3741648106904232,
      "grad_norm": 0.0008658167789690197,
      "learning_rate": 2.814572089437163e-05,
      "loss": 0.0,
      "step": 6170
    },
    {
      "epoch": 1.376391982182628,
      "grad_norm": 0.0008586731273680925,
      "learning_rate": 2.8107170393215116e-05,
      "loss": 0.0,
      "step": 6180
    },
    {
      "epoch": 1.378619153674833,
      "grad_norm": 0.001109569682739675,
      "learning_rate": 2.80686198920586e-05,
      "loss": 0.0,
      "step": 6190
    },
    {
      "epoch": 1.3808463251670378,
      "grad_norm": 0.000993455178104341,
      "learning_rate": 2.803006939090208e-05,
      "loss": 0.0,
      "step": 6200
    },
    {
      "epoch": 1.3830734966592428,
      "grad_norm": 0.0007990585290826857,
      "learning_rate": 2.7991518889745567e-05,
      "loss": 0.0,
      "step": 6210
    },
    {
      "epoch": 1.3853006681514477,
      "grad_norm": 0.0010492479195818305,
      "learning_rate": 2.795296838858905e-05,
      "loss": 0.0007,
      "step": 6220
    },
    {
      "epoch": 1.3875278396436526,
      "grad_norm": 0.0006239758804440498,
      "learning_rate": 2.7914417887432537e-05,
      "loss": 0.0,
      "step": 6230
    },
    {
      "epoch": 1.3897550111358574,
      "grad_norm": 0.00084241374861449,
      "learning_rate": 2.787586738627602e-05,
      "loss": 0.0361,
      "step": 6240
    },
    {
      "epoch": 1.3919821826280623,
      "grad_norm": 0.0004398444725666195,
      "learning_rate": 2.783731688511951e-05,
      "loss": 0.0,
      "step": 6250
    },
    {
      "epoch": 1.3942093541202674,
      "grad_norm": 0.0009273941977880895,
      "learning_rate": 2.7798766383962992e-05,
      "loss": 0.0,
      "step": 6260
    },
    {
      "epoch": 1.3964365256124722,
      "grad_norm": 0.0005654773558489978,
      "learning_rate": 2.776021588280648e-05,
      "loss": 0.0,
      "step": 6270
    },
    {
      "epoch": 1.398663697104677,
      "grad_norm": 0.0009012295049615204,
      "learning_rate": 2.7721665381649963e-05,
      "loss": 0.0,
      "step": 6280
    },
    {
      "epoch": 1.400890868596882,
      "grad_norm": 0.0007113759056665003,
      "learning_rate": 2.768311488049345e-05,
      "loss": 0.0,
      "step": 6290
    },
    {
      "epoch": 1.4031180400890868,
      "grad_norm": 0.0006231694133020937,
      "learning_rate": 2.7644564379336934e-05,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 1.4053452115812917,
      "grad_norm": 0.0006430759676732123,
      "learning_rate": 2.760601387818042e-05,
      "loss": 0.0,
      "step": 6310
    },
    {
      "epoch": 1.4075723830734965,
      "grad_norm": 0.0005243508494459093,
      "learning_rate": 2.75674633770239e-05,
      "loss": 0.0,
      "step": 6320
    },
    {
      "epoch": 1.4097995545657016,
      "grad_norm": 0.000320407998515293,
      "learning_rate": 2.7528912875867385e-05,
      "loss": 0.0,
      "step": 6330
    },
    {
      "epoch": 1.4120267260579065,
      "grad_norm": 0.00037247780710458755,
      "learning_rate": 2.7490362374710872e-05,
      "loss": 0.0,
      "step": 6340
    },
    {
      "epoch": 1.4142538975501113,
      "grad_norm": 0.0008446499705314636,
      "learning_rate": 2.7451811873554356e-05,
      "loss": 0.0,
      "step": 6350
    },
    {
      "epoch": 1.4164810690423162,
      "grad_norm": 0.00042812476749531925,
      "learning_rate": 2.7413261372397843e-05,
      "loss": 0.0,
      "step": 6360
    },
    {
      "epoch": 1.4187082405345213,
      "grad_norm": 0.0005336503963917494,
      "learning_rate": 2.7374710871241326e-05,
      "loss": 0.0,
      "step": 6370
    },
    {
      "epoch": 1.4209354120267261,
      "grad_norm": 0.0008986687171272933,
      "learning_rate": 2.7336160370084814e-05,
      "loss": 0.0,
      "step": 6380
    },
    {
      "epoch": 1.423162583518931,
      "grad_norm": 0.0005739284097217023,
      "learning_rate": 2.7297609868928297e-05,
      "loss": 0.0,
      "step": 6390
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": 0.00042841731919907033,
      "learning_rate": 2.7259059367771784e-05,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 1.4276169265033407,
      "grad_norm": 0.00036023478605784476,
      "learning_rate": 2.7220508866615268e-05,
      "loss": 0.0,
      "step": 6410
    },
    {
      "epoch": 1.4298440979955456,
      "grad_norm": 0.0005672274855896831,
      "learning_rate": 2.7181958365458755e-05,
      "loss": 0.0677,
      "step": 6420
    },
    {
      "epoch": 1.4320712694877504,
      "grad_norm": 0.0004089979629497975,
      "learning_rate": 2.714340786430224e-05,
      "loss": 0.0,
      "step": 6430
    },
    {
      "epoch": 1.4342984409799555,
      "grad_norm": 0.000576140359044075,
      "learning_rate": 2.7104857363145726e-05,
      "loss": 0.0,
      "step": 6440
    },
    {
      "epoch": 1.4365256124721604,
      "grad_norm": 0.0002545116876717657,
      "learning_rate": 2.7066306861989203e-05,
      "loss": 0.0,
      "step": 6450
    },
    {
      "epoch": 1.4387527839643652,
      "grad_norm": 0.0008622147142887115,
      "learning_rate": 2.702775636083269e-05,
      "loss": 0.0,
      "step": 6460
    },
    {
      "epoch": 1.44097995545657,
      "grad_norm": 0.0005532540963031352,
      "learning_rate": 2.6989205859676174e-05,
      "loss": 0.0,
      "step": 6470
    },
    {
      "epoch": 1.4432071269487752,
      "grad_norm": 0.0004623107088264078,
      "learning_rate": 2.695065535851966e-05,
      "loss": 0.0,
      "step": 6480
    },
    {
      "epoch": 1.44543429844098,
      "grad_norm": 0.00030390103347599506,
      "learning_rate": 2.6912104857363145e-05,
      "loss": 0.0,
      "step": 6490
    },
    {
      "epoch": 1.447661469933185,
      "grad_norm": 0.0004347209178376943,
      "learning_rate": 2.687355435620663e-05,
      "loss": 0.0055,
      "step": 6500
    },
    {
      "epoch": 1.4498886414253898,
      "grad_norm": 0.00041875854367390275,
      "learning_rate": 2.6835003855050115e-05,
      "loss": 0.0,
      "step": 6510
    },
    {
      "epoch": 1.4521158129175946,
      "grad_norm": 0.0005203001783229411,
      "learning_rate": 2.6796453353893602e-05,
      "loss": 0.0,
      "step": 6520
    },
    {
      "epoch": 1.4543429844097995,
      "grad_norm": 0.00032970914617180824,
      "learning_rate": 2.6757902852737086e-05,
      "loss": 0.0,
      "step": 6530
    },
    {
      "epoch": 1.4565701559020043,
      "grad_norm": 0.0003795723314397037,
      "learning_rate": 2.6719352351580573e-05,
      "loss": 0.0,
      "step": 6540
    },
    {
      "epoch": 1.4587973273942094,
      "grad_norm": 0.0005550830974243581,
      "learning_rate": 2.6680801850424057e-05,
      "loss": 0.0,
      "step": 6550
    },
    {
      "epoch": 1.4610244988864143,
      "grad_norm": 0.0004780368763022125,
      "learning_rate": 2.6642251349267544e-05,
      "loss": 0.0,
      "step": 6560
    },
    {
      "epoch": 1.4632516703786191,
      "grad_norm": 0.0003926035133190453,
      "learning_rate": 2.6603700848111028e-05,
      "loss": 0.0001,
      "step": 6570
    },
    {
      "epoch": 1.465478841870824,
      "grad_norm": 0.0004077192861586809,
      "learning_rate": 2.6565150346954508e-05,
      "loss": 0.0,
      "step": 6580
    },
    {
      "epoch": 1.467706013363029,
      "grad_norm": 0.00036988905048929155,
      "learning_rate": 2.6526599845797995e-05,
      "loss": 0.0,
      "step": 6590
    },
    {
      "epoch": 1.469933184855234,
      "grad_norm": 0.0002877804508898407,
      "learning_rate": 2.648804934464148e-05,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 1.4721603563474388,
      "grad_norm": 0.0004862249188590795,
      "learning_rate": 2.6449498843484966e-05,
      "loss": 0.0,
      "step": 6610
    },
    {
      "epoch": 1.4743875278396437,
      "grad_norm": 0.00037282088305801153,
      "learning_rate": 2.641094834232845e-05,
      "loss": 0.0,
      "step": 6620
    },
    {
      "epoch": 1.4766146993318485,
      "grad_norm": 0.0003468336653895676,
      "learning_rate": 2.6372397841171937e-05,
      "loss": 0.0,
      "step": 6630
    },
    {
      "epoch": 1.4788418708240534,
      "grad_norm": 0.00041394407162442803,
      "learning_rate": 2.633384734001542e-05,
      "loss": 0.0,
      "step": 6640
    },
    {
      "epoch": 1.4810690423162582,
      "grad_norm": 0.0005185309564694762,
      "learning_rate": 2.6295296838858908e-05,
      "loss": 0.0,
      "step": 6650
    },
    {
      "epoch": 1.4832962138084633,
      "grad_norm": 0.0002986897306982428,
      "learning_rate": 2.625674633770239e-05,
      "loss": 0.0,
      "step": 6660
    },
    {
      "epoch": 1.4855233853006682,
      "grad_norm": 0.00038207467878237367,
      "learning_rate": 2.621819583654588e-05,
      "loss": 0.0,
      "step": 6670
    },
    {
      "epoch": 1.487750556792873,
      "grad_norm": 0.00035274168476462364,
      "learning_rate": 2.6179645335389362e-05,
      "loss": 0.0,
      "step": 6680
    },
    {
      "epoch": 1.489977728285078,
      "grad_norm": 0.0004930036375299096,
      "learning_rate": 2.614109483423285e-05,
      "loss": 0.1313,
      "step": 6690
    },
    {
      "epoch": 1.492204899777283,
      "grad_norm": 0.0021518138237297535,
      "learning_rate": 2.610254433307633e-05,
      "loss": 0.0001,
      "step": 6700
    },
    {
      "epoch": 1.4944320712694878,
      "grad_norm": 0.0008139967103488743,
      "learning_rate": 2.6063993831919813e-05,
      "loss": 0.0018,
      "step": 6710
    },
    {
      "epoch": 1.4966592427616927,
      "grad_norm": 0.0016216669464483857,
      "learning_rate": 2.60254433307633e-05,
      "loss": 0.0001,
      "step": 6720
    },
    {
      "epoch": 1.4988864142538976,
      "grad_norm": 0.000403306883526966,
      "learning_rate": 2.5986892829606784e-05,
      "loss": 0.0,
      "step": 6730
    },
    {
      "epoch": 1.5011135857461024,
      "grad_norm": 0.0009526092326268554,
      "learning_rate": 2.594834232845027e-05,
      "loss": 0.0001,
      "step": 6740
    },
    {
      "epoch": 1.5033407572383073,
      "grad_norm": 0.0011932143243029714,
      "learning_rate": 2.5909791827293755e-05,
      "loss": 0.0,
      "step": 6750
    },
    {
      "epoch": 1.5055679287305122,
      "grad_norm": 0.0012008952908217907,
      "learning_rate": 2.5871241326137242e-05,
      "loss": 0.0,
      "step": 6760
    },
    {
      "epoch": 1.507795100222717,
      "grad_norm": 0.004962856415659189,
      "learning_rate": 2.5832690824980726e-05,
      "loss": 0.1365,
      "step": 6770
    },
    {
      "epoch": 1.510022271714922,
      "grad_norm": 0.008846395649015903,
      "learning_rate": 2.5794140323824213e-05,
      "loss": 0.0003,
      "step": 6780
    },
    {
      "epoch": 1.512249443207127,
      "grad_norm": 0.0064992355182766914,
      "learning_rate": 2.5755589822667697e-05,
      "loss": 0.0003,
      "step": 6790
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 0.0034252109471708536,
      "learning_rate": 2.5717039321511184e-05,
      "loss": 0.0001,
      "step": 6800
    },
    {
      "epoch": 1.516703786191537,
      "grad_norm": 0.0008383146487176418,
      "learning_rate": 2.5678488820354667e-05,
      "loss": 0.0001,
      "step": 6810
    },
    {
      "epoch": 1.5189309576837418,
      "grad_norm": 0.0010578091023489833,
      "learning_rate": 2.5639938319198155e-05,
      "loss": 0.0001,
      "step": 6820
    },
    {
      "epoch": 1.5211581291759466,
      "grad_norm": 0.0009533079573884606,
      "learning_rate": 2.5601387818041635e-05,
      "loss": 0.0,
      "step": 6830
    },
    {
      "epoch": 1.5233853006681515,
      "grad_norm": 0.0025690256152302027,
      "learning_rate": 2.556283731688512e-05,
      "loss": 0.0,
      "step": 6840
    },
    {
      "epoch": 1.5256124721603563,
      "grad_norm": 0.0020194349344819784,
      "learning_rate": 2.5524286815728606e-05,
      "loss": 0.0,
      "step": 6850
    },
    {
      "epoch": 1.5278396436525612,
      "grad_norm": 0.0017170123755931854,
      "learning_rate": 2.548573631457209e-05,
      "loss": 0.0,
      "step": 6860
    },
    {
      "epoch": 1.530066815144766,
      "grad_norm": 0.0010309310164302588,
      "learning_rate": 2.5447185813415577e-05,
      "loss": 0.0,
      "step": 6870
    },
    {
      "epoch": 1.532293986636971,
      "grad_norm": 0.0006167608662508428,
      "learning_rate": 2.540863531225906e-05,
      "loss": 0.0,
      "step": 6880
    },
    {
      "epoch": 1.534521158129176,
      "grad_norm": 0.0020047251600772142,
      "learning_rate": 2.5370084811102547e-05,
      "loss": 0.0,
      "step": 6890
    },
    {
      "epoch": 1.5367483296213809,
      "grad_norm": 0.000899630889762193,
      "learning_rate": 2.533153430994603e-05,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 1.5389755011135857,
      "grad_norm": 0.0007288437918759882,
      "learning_rate": 2.5292983808789518e-05,
      "loss": 0.0,
      "step": 6910
    },
    {
      "epoch": 1.5412026726057908,
      "grad_norm": 0.000762737006880343,
      "learning_rate": 2.5254433307633002e-05,
      "loss": 0.0,
      "step": 6920
    },
    {
      "epoch": 1.5434298440979957,
      "grad_norm": 0.001272005494683981,
      "learning_rate": 2.521588280647649e-05,
      "loss": 0.1367,
      "step": 6930
    },
    {
      "epoch": 1.5456570155902005,
      "grad_norm": 0.015572422184050083,
      "learning_rate": 2.5177332305319973e-05,
      "loss": 0.0003,
      "step": 6940
    },
    {
      "epoch": 1.5478841870824054,
      "grad_norm": 0.0030967809725552797,
      "learning_rate": 2.5138781804163453e-05,
      "loss": 0.0003,
      "step": 6950
    },
    {
      "epoch": 1.5501113585746102,
      "grad_norm": 0.005576889496296644,
      "learning_rate": 2.5100231303006937e-05,
      "loss": 0.0003,
      "step": 6960
    },
    {
      "epoch": 1.552338530066815,
      "grad_norm": 0.0015532460529357195,
      "learning_rate": 2.5061680801850424e-05,
      "loss": 0.0002,
      "step": 6970
    },
    {
      "epoch": 1.55456570155902,
      "grad_norm": 0.003326854668557644,
      "learning_rate": 2.5023130300693908e-05,
      "loss": 0.0001,
      "step": 6980
    },
    {
      "epoch": 1.5567928730512248,
      "grad_norm": 0.0015586254885420203,
      "learning_rate": 2.4984579799537395e-05,
      "loss": 0.0001,
      "step": 6990
    },
    {
      "epoch": 1.5590200445434297,
      "grad_norm": 0.0009606105741113424,
      "learning_rate": 2.494602929838088e-05,
      "loss": 0.0001,
      "step": 7000
    }
  ],
  "logging_steps": 10,
  "max_steps": 13470,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7417909389938688.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
