{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.779510022271715,
  "eval_steps": 500,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0022271714922048997,
      "grad_norm": 3.431209087371826,
      "learning_rate": 9e-07,
      "loss": 0.6988,
      "step": 10
    },
    {
      "epoch": 0.004454342984409799,
      "grad_norm": 1.5945241451263428,
      "learning_rate": 1.9e-06,
      "loss": 0.6943,
      "step": 20
    },
    {
      "epoch": 0.0066815144766146995,
      "grad_norm": 1.3031045198440552,
      "learning_rate": 2.9e-06,
      "loss": 0.6927,
      "step": 30
    },
    {
      "epoch": 0.008908685968819599,
      "grad_norm": 2.643918514251709,
      "learning_rate": 3.9e-06,
      "loss": 0.6881,
      "step": 40
    },
    {
      "epoch": 0.011135857461024499,
      "grad_norm": 1.3544669151306152,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.6639,
      "step": 50
    },
    {
      "epoch": 0.013363028953229399,
      "grad_norm": 2.9651875495910645,
      "learning_rate": 5.9e-06,
      "loss": 0.651,
      "step": 60
    },
    {
      "epoch": 0.015590200445434299,
      "grad_norm": 3.1865758895874023,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.5755,
      "step": 70
    },
    {
      "epoch": 0.017817371937639197,
      "grad_norm": 3.4834768772125244,
      "learning_rate": 7.9e-06,
      "loss": 0.4199,
      "step": 80
    },
    {
      "epoch": 0.0200445434298441,
      "grad_norm": 1.7848082780838013,
      "learning_rate": 8.9e-06,
      "loss": 0.2412,
      "step": 90
    },
    {
      "epoch": 0.022271714922048998,
      "grad_norm": 0.9703733325004578,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.1429,
      "step": 100
    },
    {
      "epoch": 0.024498886414253896,
      "grad_norm": 0.5473387241363525,
      "learning_rate": 1.09e-05,
      "loss": 0.0967,
      "step": 110
    },
    {
      "epoch": 0.026726057906458798,
      "grad_norm": 0.40797603130340576,
      "learning_rate": 1.19e-05,
      "loss": 0.0464,
      "step": 120
    },
    {
      "epoch": 0.028953229398663696,
      "grad_norm": 0.29466378688812256,
      "learning_rate": 1.29e-05,
      "loss": 0.0263,
      "step": 130
    },
    {
      "epoch": 0.031180400890868598,
      "grad_norm": 0.7490040063858032,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0188,
      "step": 140
    },
    {
      "epoch": 0.0334075723830735,
      "grad_norm": 0.1550196409225464,
      "learning_rate": 1.49e-05,
      "loss": 0.0102,
      "step": 150
    },
    {
      "epoch": 0.035634743875278395,
      "grad_norm": 8.649392127990723,
      "learning_rate": 1.59e-05,
      "loss": 0.0133,
      "step": 160
    },
    {
      "epoch": 0.0378619153674833,
      "grad_norm": 0.08959051966667175,
      "learning_rate": 1.69e-05,
      "loss": 0.0069,
      "step": 170
    },
    {
      "epoch": 0.0400890868596882,
      "grad_norm": 0.08933669328689575,
      "learning_rate": 1.79e-05,
      "loss": 0.0079,
      "step": 180
    },
    {
      "epoch": 0.042316258351893093,
      "grad_norm": 0.07168997079133987,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0057,
      "step": 190
    },
    {
      "epoch": 0.044543429844097995,
      "grad_norm": 0.06148263067007065,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0434,
      "step": 200
    },
    {
      "epoch": 0.0467706013363029,
      "grad_norm": 0.05540284141898155,
      "learning_rate": 2.09e-05,
      "loss": 0.0702,
      "step": 210
    },
    {
      "epoch": 0.04899777282850779,
      "grad_norm": 0.0727599635720253,
      "learning_rate": 2.19e-05,
      "loss": 0.0036,
      "step": 220
    },
    {
      "epoch": 0.051224944320712694,
      "grad_norm": 0.051876556128263474,
      "learning_rate": 2.29e-05,
      "loss": 0.003,
      "step": 230
    },
    {
      "epoch": 0.053452115812917596,
      "grad_norm": 0.0467323362827301,
      "learning_rate": 2.39e-05,
      "loss": 0.0028,
      "step": 240
    },
    {
      "epoch": 0.0556792873051225,
      "grad_norm": 0.036060597747564316,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.0025,
      "step": 250
    },
    {
      "epoch": 0.05790645879732739,
      "grad_norm": 0.04070688411593437,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.002,
      "step": 260
    },
    {
      "epoch": 0.060133630289532294,
      "grad_norm": 0.02991284243762493,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0019,
      "step": 270
    },
    {
      "epoch": 0.062360801781737196,
      "grad_norm": 0.02594655565917492,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0018,
      "step": 280
    },
    {
      "epoch": 0.0645879732739421,
      "grad_norm": 0.03034917078912258,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0015,
      "step": 290
    },
    {
      "epoch": 0.066815144766147,
      "grad_norm": 0.040472112596035004,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0013,
      "step": 300
    },
    {
      "epoch": 0.06904231625835189,
      "grad_norm": 0.036792658269405365,
      "learning_rate": 3.09e-05,
      "loss": 0.0013,
      "step": 310
    },
    {
      "epoch": 0.07126948775055679,
      "grad_norm": 0.01685582846403122,
      "learning_rate": 3.19e-05,
      "loss": 0.001,
      "step": 320
    },
    {
      "epoch": 0.07349665924276169,
      "grad_norm": 0.014991199597716331,
      "learning_rate": 3.29e-05,
      "loss": 0.001,
      "step": 330
    },
    {
      "epoch": 0.0757238307349666,
      "grad_norm": 0.015452426858246326,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0009,
      "step": 340
    },
    {
      "epoch": 0.0779510022271715,
      "grad_norm": 0.015531397424638271,
      "learning_rate": 3.49e-05,
      "loss": 0.0007,
      "step": 350
    },
    {
      "epoch": 0.0801781737193764,
      "grad_norm": 0.06109783425927162,
      "learning_rate": 3.59e-05,
      "loss": 0.0009,
      "step": 360
    },
    {
      "epoch": 0.08240534521158129,
      "grad_norm": 0.01355788018554449,
      "learning_rate": 3.69e-05,
      "loss": 0.0558,
      "step": 370
    },
    {
      "epoch": 0.08463251670378619,
      "grad_norm": 0.009466464631259441,
      "learning_rate": 3.79e-05,
      "loss": 0.0006,
      "step": 380
    },
    {
      "epoch": 0.08685968819599109,
      "grad_norm": 0.010187627747654915,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0007,
      "step": 390
    },
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 0.012195323593914509,
      "learning_rate": 3.99e-05,
      "loss": 0.0007,
      "step": 400
    },
    {
      "epoch": 0.09131403118040089,
      "grad_norm": 0.02273370325565338,
      "learning_rate": 4.09e-05,
      "loss": 0.0027,
      "step": 410
    },
    {
      "epoch": 0.0935412026726058,
      "grad_norm": 0.010213186033070087,
      "learning_rate": 4.19e-05,
      "loss": 0.0004,
      "step": 420
    },
    {
      "epoch": 0.0957683741648107,
      "grad_norm": 0.008116074837744236,
      "learning_rate": 4.29e-05,
      "loss": 0.0206,
      "step": 430
    },
    {
      "epoch": 0.09799554565701558,
      "grad_norm": 0.009267566725611687,
      "learning_rate": 4.39e-05,
      "loss": 0.001,
      "step": 440
    },
    {
      "epoch": 0.10022271714922049,
      "grad_norm": 0.007021318655461073,
      "learning_rate": 4.49e-05,
      "loss": 0.0005,
      "step": 450
    },
    {
      "epoch": 0.10244988864142539,
      "grad_norm": 35.92754364013672,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.0291,
      "step": 460
    },
    {
      "epoch": 0.10467706013363029,
      "grad_norm": 0.007265315391123295,
      "learning_rate": 4.69e-05,
      "loss": 0.0128,
      "step": 470
    },
    {
      "epoch": 0.10690423162583519,
      "grad_norm": 0.012291595339775085,
      "learning_rate": 4.79e-05,
      "loss": 0.0013,
      "step": 480
    },
    {
      "epoch": 0.1091314031180401,
      "grad_norm": 0.005603676196187735,
      "learning_rate": 4.89e-05,
      "loss": 0.0003,
      "step": 490
    },
    {
      "epoch": 0.111358574610245,
      "grad_norm": 0.009176917374134064,
      "learning_rate": 4.99e-05,
      "loss": 0.0729,
      "step": 500
    },
    {
      "epoch": 0.11358574610244988,
      "grad_norm": 0.01008897926658392,
      "learning_rate": 4.996530454895914e-05,
      "loss": 0.0005,
      "step": 510
    },
    {
      "epoch": 0.11581291759465479,
      "grad_norm": 0.008612244389951229,
      "learning_rate": 4.992675404780263e-05,
      "loss": 0.0004,
      "step": 520
    },
    {
      "epoch": 0.11804008908685969,
      "grad_norm": 0.03885987773537636,
      "learning_rate": 4.9888203546646105e-05,
      "loss": 0.1178,
      "step": 530
    },
    {
      "epoch": 0.12026726057906459,
      "grad_norm": 0.025776294991374016,
      "learning_rate": 4.984965304548959e-05,
      "loss": 0.0006,
      "step": 540
    },
    {
      "epoch": 0.12249443207126949,
      "grad_norm": 0.08023320883512497,
      "learning_rate": 4.981110254433308e-05,
      "loss": 0.0006,
      "step": 550
    },
    {
      "epoch": 0.12472160356347439,
      "grad_norm": 0.004364595282822847,
      "learning_rate": 4.977255204317656e-05,
      "loss": 0.0004,
      "step": 560
    },
    {
      "epoch": 0.12694877505567928,
      "grad_norm": 0.005635369103401899,
      "learning_rate": 4.973400154202005e-05,
      "loss": 0.0002,
      "step": 570
    },
    {
      "epoch": 0.1291759465478842,
      "grad_norm": 0.004209843464195728,
      "learning_rate": 4.969545104086353e-05,
      "loss": 0.0002,
      "step": 580
    },
    {
      "epoch": 0.13140311804008908,
      "grad_norm": 0.0034029444213956594,
      "learning_rate": 4.965690053970702e-05,
      "loss": 0.0002,
      "step": 590
    },
    {
      "epoch": 0.133630289532294,
      "grad_norm": 0.00575220724567771,
      "learning_rate": 4.9618350038550505e-05,
      "loss": 0.0002,
      "step": 600
    },
    {
      "epoch": 0.1358574610244989,
      "grad_norm": 0.004919408820569515,
      "learning_rate": 4.957979953739399e-05,
      "loss": 0.0002,
      "step": 610
    },
    {
      "epoch": 0.13808463251670378,
      "grad_norm": 0.0033537691924721003,
      "learning_rate": 4.954124903623747e-05,
      "loss": 0.0002,
      "step": 620
    },
    {
      "epoch": 0.1403118040089087,
      "grad_norm": 0.0032662146259099245,
      "learning_rate": 4.950269853508096e-05,
      "loss": 0.0001,
      "step": 630
    },
    {
      "epoch": 0.14253897550111358,
      "grad_norm": 0.0025406882632523775,
      "learning_rate": 4.9464148033924446e-05,
      "loss": 0.0001,
      "step": 640
    },
    {
      "epoch": 0.1447661469933185,
      "grad_norm": 0.02041727863252163,
      "learning_rate": 4.942559753276793e-05,
      "loss": 0.1093,
      "step": 650
    },
    {
      "epoch": 0.14699331848552338,
      "grad_norm": 0.03743819519877434,
      "learning_rate": 4.9387047031611414e-05,
      "loss": 0.0059,
      "step": 660
    },
    {
      "epoch": 0.1492204899777283,
      "grad_norm": 0.007928205654025078,
      "learning_rate": 4.93484965304549e-05,
      "loss": 0.0009,
      "step": 670
    },
    {
      "epoch": 0.1514476614699332,
      "grad_norm": 0.004348834045231342,
      "learning_rate": 4.930994602929838e-05,
      "loss": 0.0011,
      "step": 680
    },
    {
      "epoch": 0.15367483296213807,
      "grad_norm": 0.006778515409678221,
      "learning_rate": 4.9271395528141865e-05,
      "loss": 0.0002,
      "step": 690
    },
    {
      "epoch": 0.155902004454343,
      "grad_norm": 0.00542496656998992,
      "learning_rate": 4.9232845026985355e-05,
      "loss": 0.0002,
      "step": 700
    },
    {
      "epoch": 0.15812917594654788,
      "grad_norm": 0.004850401543080807,
      "learning_rate": 4.919429452582884e-05,
      "loss": 0.0002,
      "step": 710
    },
    {
      "epoch": 0.1603563474387528,
      "grad_norm": 0.004906316753476858,
      "learning_rate": 4.915574402467232e-05,
      "loss": 0.0002,
      "step": 720
    },
    {
      "epoch": 0.16258351893095768,
      "grad_norm": 0.0031026357319206,
      "learning_rate": 4.9117193523515807e-05,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 0.16481069042316257,
      "grad_norm": 0.0030167296063154936,
      "learning_rate": 4.90786430223593e-05,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 0.16703786191536749,
      "grad_norm": 0.003254351206123829,
      "learning_rate": 4.904009252120278e-05,
      "loss": 0.0001,
      "step": 750
    },
    {
      "epoch": 0.16926503340757237,
      "grad_norm": 0.0023794753942638636,
      "learning_rate": 4.9001542020046264e-05,
      "loss": 0.0001,
      "step": 760
    },
    {
      "epoch": 0.1714922048997773,
      "grad_norm": 0.0018970713717862964,
      "learning_rate": 4.896299151888975e-05,
      "loss": 0.0001,
      "step": 770
    },
    {
      "epoch": 0.17371937639198218,
      "grad_norm": 0.0077140796929597855,
      "learning_rate": 4.892444101773323e-05,
      "loss": 0.0494,
      "step": 780
    },
    {
      "epoch": 0.1759465478841871,
      "grad_norm": 0.005012082867324352,
      "learning_rate": 4.8885890516576716e-05,
      "loss": 0.0004,
      "step": 790
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.0030972680542618036,
      "learning_rate": 4.88473400154202e-05,
      "loss": 0.0002,
      "step": 800
    },
    {
      "epoch": 0.18040089086859687,
      "grad_norm": 0.008881570771336555,
      "learning_rate": 4.880878951426368e-05,
      "loss": 0.072,
      "step": 810
    },
    {
      "epoch": 0.18262806236080179,
      "grad_norm": 0.004121475387364626,
      "learning_rate": 4.8770239013107174e-05,
      "loss": 0.0006,
      "step": 820
    },
    {
      "epoch": 0.18485523385300667,
      "grad_norm": 0.003665172727778554,
      "learning_rate": 4.873168851195066e-05,
      "loss": 0.0002,
      "step": 830
    },
    {
      "epoch": 0.1870824053452116,
      "grad_norm": 0.0022593180183321238,
      "learning_rate": 4.869313801079414e-05,
      "loss": 0.0002,
      "step": 840
    },
    {
      "epoch": 0.18930957683741648,
      "grad_norm": 0.0030925734899938107,
      "learning_rate": 4.8654587509637625e-05,
      "loss": 0.0001,
      "step": 850
    },
    {
      "epoch": 0.1915367483296214,
      "grad_norm": 0.005627123173326254,
      "learning_rate": 4.8616037008481115e-05,
      "loss": 0.0866,
      "step": 860
    },
    {
      "epoch": 0.19376391982182628,
      "grad_norm": 0.017698820680379868,
      "learning_rate": 4.85774865073246e-05,
      "loss": 0.0003,
      "step": 870
    },
    {
      "epoch": 0.19599109131403117,
      "grad_norm": 0.0037356670945882797,
      "learning_rate": 4.853893600616808e-05,
      "loss": 0.0008,
      "step": 880
    },
    {
      "epoch": 0.19821826280623608,
      "grad_norm": 0.0017527706222608685,
      "learning_rate": 4.8500385505011566e-05,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 0.20044543429844097,
      "grad_norm": 0.00198148051276803,
      "learning_rate": 4.846183500385506e-05,
      "loss": 0.0001,
      "step": 900
    },
    {
      "epoch": 0.2026726057906459,
      "grad_norm": 0.0033013392239809036,
      "learning_rate": 4.8423284502698534e-05,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 0.20489977728285078,
      "grad_norm": 0.0024627968668937683,
      "learning_rate": 4.838473400154202e-05,
      "loss": 0.0001,
      "step": 920
    },
    {
      "epoch": 0.2071269487750557,
      "grad_norm": 0.002736808033660054,
      "learning_rate": 4.834618350038551e-05,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 0.20935412026726058,
      "grad_norm": 0.0016122461529448628,
      "learning_rate": 4.830763299922899e-05,
      "loss": 0.0001,
      "step": 940
    },
    {
      "epoch": 0.21158129175946547,
      "grad_norm": 0.00158878939691931,
      "learning_rate": 4.8269082498072475e-05,
      "loss": 0.0001,
      "step": 950
    },
    {
      "epoch": 0.21380846325167038,
      "grad_norm": 0.0011894447961822152,
      "learning_rate": 4.823053199691596e-05,
      "loss": 0.0001,
      "step": 960
    },
    {
      "epoch": 0.21603563474387527,
      "grad_norm": 0.0020984618458896875,
      "learning_rate": 4.819198149575945e-05,
      "loss": 0.0001,
      "step": 970
    },
    {
      "epoch": 0.2182628062360802,
      "grad_norm": 0.0013036364689469337,
      "learning_rate": 4.815343099460293e-05,
      "loss": 0.0001,
      "step": 980
    },
    {
      "epoch": 0.22048997772828507,
      "grad_norm": 0.0015882375882938504,
      "learning_rate": 4.811488049344642e-05,
      "loss": 0.0001,
      "step": 990
    },
    {
      "epoch": 0.22271714922049,
      "grad_norm": 0.0015365431318059564,
      "learning_rate": 4.80763299922899e-05,
      "loss": 0.0001,
      "step": 1000
    },
    {
      "epoch": 0.22494432071269488,
      "grad_norm": 0.0016050381818786263,
      "learning_rate": 4.803777949113339e-05,
      "loss": 0.0001,
      "step": 1010
    },
    {
      "epoch": 0.22717149220489977,
      "grad_norm": 0.001162832835689187,
      "learning_rate": 4.7999228989976875e-05,
      "loss": 0.0001,
      "step": 1020
    },
    {
      "epoch": 0.22939866369710468,
      "grad_norm": 0.0017633364768698812,
      "learning_rate": 4.796067848882035e-05,
      "loss": 0.0001,
      "step": 1030
    },
    {
      "epoch": 0.23162583518930957,
      "grad_norm": 0.0014406056143343449,
      "learning_rate": 4.792212798766384e-05,
      "loss": 0.0001,
      "step": 1040
    },
    {
      "epoch": 0.23385300668151449,
      "grad_norm": 0.0009505327907390893,
      "learning_rate": 4.7883577486507326e-05,
      "loss": 0.0,
      "step": 1050
    },
    {
      "epoch": 0.23608017817371937,
      "grad_norm": 0.0009892246453091502,
      "learning_rate": 4.784502698535081e-05,
      "loss": 0.0001,
      "step": 1060
    },
    {
      "epoch": 0.2383073496659243,
      "grad_norm": 0.001066096592694521,
      "learning_rate": 4.7806476484194294e-05,
      "loss": 0.0,
      "step": 1070
    },
    {
      "epoch": 0.24053452115812918,
      "grad_norm": 0.001613892731256783,
      "learning_rate": 4.7767925983037784e-05,
      "loss": 0.0,
      "step": 1080
    },
    {
      "epoch": 0.24276169265033407,
      "grad_norm": 0.0017776720924302936,
      "learning_rate": 4.772937548188127e-05,
      "loss": 0.0001,
      "step": 1090
    },
    {
      "epoch": 0.24498886414253898,
      "grad_norm": 0.002030929084867239,
      "learning_rate": 4.769082498072475e-05,
      "loss": 0.0001,
      "step": 1100
    },
    {
      "epoch": 0.24721603563474387,
      "grad_norm": 0.0009249323047697544,
      "learning_rate": 4.7652274479568235e-05,
      "loss": 0.0,
      "step": 1110
    },
    {
      "epoch": 0.24944320712694878,
      "grad_norm": 0.0008249652455560863,
      "learning_rate": 4.7613723978411726e-05,
      "loss": 0.0,
      "step": 1120
    },
    {
      "epoch": 0.2516703786191537,
      "grad_norm": 0.0012628004187718034,
      "learning_rate": 4.757517347725521e-05,
      "loss": 0.0,
      "step": 1130
    },
    {
      "epoch": 0.25389755011135856,
      "grad_norm": 0.0010191318579018116,
      "learning_rate": 4.753662297609869e-05,
      "loss": 0.0,
      "step": 1140
    },
    {
      "epoch": 0.2561247216035635,
      "grad_norm": 0.0010273990919813514,
      "learning_rate": 4.749807247494218e-05,
      "loss": 0.0,
      "step": 1150
    },
    {
      "epoch": 0.2583518930957684,
      "grad_norm": 0.0009914592374116182,
      "learning_rate": 4.745952197378566e-05,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 0.26057906458797325,
      "grad_norm": 0.0009320122771896422,
      "learning_rate": 4.7420971472629144e-05,
      "loss": 0.0,
      "step": 1170
    },
    {
      "epoch": 0.26280623608017817,
      "grad_norm": 0.0010169537272304296,
      "learning_rate": 4.738242097147263e-05,
      "loss": 0.0,
      "step": 1180
    },
    {
      "epoch": 0.2650334075723831,
      "grad_norm": 0.0006987357628531754,
      "learning_rate": 4.734387047031612e-05,
      "loss": 0.0,
      "step": 1190
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.000799989269580692,
      "learning_rate": 4.73053199691596e-05,
      "loss": 0.0001,
      "step": 1200
    },
    {
      "epoch": 0.26948775055679286,
      "grad_norm": 0.0006347693270072341,
      "learning_rate": 4.7266769468003086e-05,
      "loss": 0.0,
      "step": 1210
    },
    {
      "epoch": 0.2717149220489978,
      "grad_norm": 0.0010448938701301813,
      "learning_rate": 4.722821896684657e-05,
      "loss": 0.0,
      "step": 1220
    },
    {
      "epoch": 0.2739420935412027,
      "grad_norm": 0.0006951876566745341,
      "learning_rate": 4.718966846569006e-05,
      "loss": 0.0,
      "step": 1230
    },
    {
      "epoch": 0.27616926503340755,
      "grad_norm": 0.0009757720399647951,
      "learning_rate": 4.7151117964533544e-05,
      "loss": 0.0,
      "step": 1240
    },
    {
      "epoch": 0.27839643652561247,
      "grad_norm": 0.0008078649989329278,
      "learning_rate": 4.711256746337703e-05,
      "loss": 0.0,
      "step": 1250
    },
    {
      "epoch": 0.2806236080178174,
      "grad_norm": 0.0008198667201213539,
      "learning_rate": 4.707401696222051e-05,
      "loss": 0.0,
      "step": 1260
    },
    {
      "epoch": 0.2828507795100223,
      "grad_norm": 0.0012516301358118653,
      "learning_rate": 4.7035466461064e-05,
      "loss": 0.0,
      "step": 1270
    },
    {
      "epoch": 0.28507795100222716,
      "grad_norm": 0.0006594061851501465,
      "learning_rate": 4.6996915959907485e-05,
      "loss": 0.0024,
      "step": 1280
    },
    {
      "epoch": 0.2873051224944321,
      "grad_norm": 0.0013818058650940657,
      "learning_rate": 4.695836545875096e-05,
      "loss": 0.0,
      "step": 1290
    },
    {
      "epoch": 0.289532293986637,
      "grad_norm": 0.0010867497185245156,
      "learning_rate": 4.6919814957594446e-05,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 0.29175946547884185,
      "grad_norm": 0.0008936910890042782,
      "learning_rate": 4.6881264456437937e-05,
      "loss": 0.0,
      "step": 1310
    },
    {
      "epoch": 0.29398663697104677,
      "grad_norm": 0.0027311043813824654,
      "learning_rate": 4.684271395528142e-05,
      "loss": 0.0,
      "step": 1320
    },
    {
      "epoch": 0.2962138084632517,
      "grad_norm": 0.0008754460723139346,
      "learning_rate": 4.6804163454124904e-05,
      "loss": 0.0,
      "step": 1330
    },
    {
      "epoch": 0.2984409799554566,
      "grad_norm": 0.0005403757095336914,
      "learning_rate": 4.676561295296839e-05,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 0.30066815144766146,
      "grad_norm": 0.0006410368368960917,
      "learning_rate": 4.672706245181188e-05,
      "loss": 0.0,
      "step": 1350
    },
    {
      "epoch": 0.3028953229398664,
      "grad_norm": 0.0010693053482100368,
      "learning_rate": 4.668851195065536e-05,
      "loss": 0.0,
      "step": 1360
    },
    {
      "epoch": 0.3051224944320713,
      "grad_norm": 0.0007671352941542864,
      "learning_rate": 4.6649961449498846e-05,
      "loss": 0.0,
      "step": 1370
    },
    {
      "epoch": 0.30734966592427615,
      "grad_norm": 0.0010526691330596805,
      "learning_rate": 4.661141094834233e-05,
      "loss": 0.0003,
      "step": 1380
    },
    {
      "epoch": 0.30957683741648107,
      "grad_norm": 0.0008738858159631491,
      "learning_rate": 4.657286044718582e-05,
      "loss": 0.0,
      "step": 1390
    },
    {
      "epoch": 0.311804008908686,
      "grad_norm": 0.000733574153855443,
      "learning_rate": 4.6534309946029304e-05,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 0.31403118040089084,
      "grad_norm": 0.0015889606438577175,
      "learning_rate": 4.649575944487278e-05,
      "loss": 0.0,
      "step": 1410
    },
    {
      "epoch": 0.31625835189309576,
      "grad_norm": 0.0008665199275128543,
      "learning_rate": 4.645720894371627e-05,
      "loss": 0.0,
      "step": 1420
    },
    {
      "epoch": 0.3184855233853007,
      "grad_norm": 0.0010845508659258485,
      "learning_rate": 4.6418658442559755e-05,
      "loss": 0.0,
      "step": 1430
    },
    {
      "epoch": 0.3207126948775056,
      "grad_norm": 0.0009218277409672737,
      "learning_rate": 4.638010794140324e-05,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 0.32293986636971045,
      "grad_norm": 0.0013361776946112514,
      "learning_rate": 4.634155744024672e-05,
      "loss": 0.0,
      "step": 1450
    },
    {
      "epoch": 0.32516703786191536,
      "grad_norm": 0.0021335347555577755,
      "learning_rate": 4.630300693909021e-05,
      "loss": 0.1099,
      "step": 1460
    },
    {
      "epoch": 0.3273942093541203,
      "grad_norm": 0.0021354560740292072,
      "learning_rate": 4.6264456437933696e-05,
      "loss": 0.0027,
      "step": 1470
    },
    {
      "epoch": 0.32962138084632514,
      "grad_norm": 0.001235857722349465,
      "learning_rate": 4.622590593677718e-05,
      "loss": 0.0001,
      "step": 1480
    },
    {
      "epoch": 0.33184855233853006,
      "grad_norm": 0.0018102267058566213,
      "learning_rate": 4.6187355435620664e-05,
      "loss": 0.0114,
      "step": 1490
    },
    {
      "epoch": 0.33407572383073497,
      "grad_norm": 0.03878825530409813,
      "learning_rate": 4.6148804934464154e-05,
      "loss": 0.1055,
      "step": 1500
    },
    {
      "epoch": 0.3363028953229399,
      "grad_norm": 0.0012812159257009625,
      "learning_rate": 4.611025443330764e-05,
      "loss": 0.0001,
      "step": 1510
    },
    {
      "epoch": 0.33853006681514475,
      "grad_norm": 0.0018881550058722496,
      "learning_rate": 4.607170393215112e-05,
      "loss": 0.0,
      "step": 1520
    },
    {
      "epoch": 0.34075723830734966,
      "grad_norm": 0.0009954406414180994,
      "learning_rate": 4.6033153430994605e-05,
      "loss": 0.0,
      "step": 1530
    },
    {
      "epoch": 0.3429844097995546,
      "grad_norm": 0.0010783427860587835,
      "learning_rate": 4.599460292983809e-05,
      "loss": 0.0,
      "step": 1540
    },
    {
      "epoch": 0.34521158129175944,
      "grad_norm": 0.000995759037323296,
      "learning_rate": 4.595605242868157e-05,
      "loss": 0.0,
      "step": 1550
    },
    {
      "epoch": 0.34743875278396436,
      "grad_norm": 0.0009018325945362449,
      "learning_rate": 4.5917501927525057e-05,
      "loss": 0.0,
      "step": 1560
    },
    {
      "epoch": 0.34966592427616927,
      "grad_norm": 0.004622419364750385,
      "learning_rate": 4.587895142636855e-05,
      "loss": 0.111,
      "step": 1570
    },
    {
      "epoch": 0.3518930957683742,
      "grad_norm": 0.005895143840461969,
      "learning_rate": 4.584040092521203e-05,
      "loss": 0.0003,
      "step": 1580
    },
    {
      "epoch": 0.35412026726057905,
      "grad_norm": 0.002627168083563447,
      "learning_rate": 4.5801850424055514e-05,
      "loss": 0.0001,
      "step": 1590
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.0021668588742613792,
      "learning_rate": 4.5763299922899e-05,
      "loss": 0.0001,
      "step": 1600
    },
    {
      "epoch": 0.3585746102449889,
      "grad_norm": 0.0018249565036967397,
      "learning_rate": 4.572474942174249e-05,
      "loss": 0.0,
      "step": 1610
    },
    {
      "epoch": 0.36080178173719374,
      "grad_norm": 0.000831479555927217,
      "learning_rate": 4.568619892058597e-05,
      "loss": 0.0001,
      "step": 1620
    },
    {
      "epoch": 0.36302895322939865,
      "grad_norm": 0.0013563591055572033,
      "learning_rate": 4.5647648419429456e-05,
      "loss": 0.0,
      "step": 1630
    },
    {
      "epoch": 0.36525612472160357,
      "grad_norm": 0.0012283700052648783,
      "learning_rate": 4.560909791827294e-05,
      "loss": 0.0,
      "step": 1640
    },
    {
      "epoch": 0.3674832962138085,
      "grad_norm": 0.0006783531862311065,
      "learning_rate": 4.557054741711643e-05,
      "loss": 0.0,
      "step": 1650
    },
    {
      "epoch": 0.36971046770601335,
      "grad_norm": 0.0012505725026130676,
      "learning_rate": 4.553199691595991e-05,
      "loss": 0.0,
      "step": 1660
    },
    {
      "epoch": 0.37193763919821826,
      "grad_norm": 0.0005117461550980806,
      "learning_rate": 4.549344641480339e-05,
      "loss": 0.0,
      "step": 1670
    },
    {
      "epoch": 0.3741648106904232,
      "grad_norm": 0.0013493510195985436,
      "learning_rate": 4.5454895913646875e-05,
      "loss": 0.0,
      "step": 1680
    },
    {
      "epoch": 0.37639198218262804,
      "grad_norm": 0.0008173023234121501,
      "learning_rate": 4.5416345412490365e-05,
      "loss": 0.0,
      "step": 1690
    },
    {
      "epoch": 0.37861915367483295,
      "grad_norm": 0.0003803448344115168,
      "learning_rate": 4.537779491133385e-05,
      "loss": 0.0,
      "step": 1700
    },
    {
      "epoch": 0.38084632516703787,
      "grad_norm": 0.0007326370687223971,
      "learning_rate": 4.533924441017733e-05,
      "loss": 0.0,
      "step": 1710
    },
    {
      "epoch": 0.3830734966592428,
      "grad_norm": 0.000820969115011394,
      "learning_rate": 4.5300693909020816e-05,
      "loss": 0.0,
      "step": 1720
    },
    {
      "epoch": 0.38530066815144765,
      "grad_norm": 0.0007523024687543511,
      "learning_rate": 4.526214340786431e-05,
      "loss": 0.0,
      "step": 1730
    },
    {
      "epoch": 0.38752783964365256,
      "grad_norm": 0.0006807052413932979,
      "learning_rate": 4.522359290670779e-05,
      "loss": 0.0001,
      "step": 1740
    },
    {
      "epoch": 0.3897550111358575,
      "grad_norm": 0.0008182713645510375,
      "learning_rate": 4.5185042405551274e-05,
      "loss": 0.0,
      "step": 1750
    },
    {
      "epoch": 0.39198218262806234,
      "grad_norm": 6.073887825012207,
      "learning_rate": 4.514649190439476e-05,
      "loss": 0.0154,
      "step": 1760
    },
    {
      "epoch": 0.39420935412026725,
      "grad_norm": 0.0010553799802437425,
      "learning_rate": 4.510794140323825e-05,
      "loss": 0.0,
      "step": 1770
    },
    {
      "epoch": 0.39643652561247217,
      "grad_norm": 0.0011755876475945115,
      "learning_rate": 4.506939090208173e-05,
      "loss": 0.0652,
      "step": 1780
    },
    {
      "epoch": 0.3986636971046771,
      "grad_norm": 0.0011125204619020224,
      "learning_rate": 4.503084040092521e-05,
      "loss": 0.0699,
      "step": 1790
    },
    {
      "epoch": 0.40089086859688194,
      "grad_norm": 0.0008977939723990858,
      "learning_rate": 4.49922898997687e-05,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 0.40311804008908686,
      "grad_norm": 0.0008301349589601159,
      "learning_rate": 4.495373939861218e-05,
      "loss": 0.0,
      "step": 1810
    },
    {
      "epoch": 0.4053452115812918,
      "grad_norm": 0.001015080721117556,
      "learning_rate": 4.491518889745567e-05,
      "loss": 0.0,
      "step": 1820
    },
    {
      "epoch": 0.40757238307349664,
      "grad_norm": 0.0006330236210487783,
      "learning_rate": 4.487663839629915e-05,
      "loss": 0.0,
      "step": 1830
    },
    {
      "epoch": 0.40979955456570155,
      "grad_norm": 0.0006975868600420654,
      "learning_rate": 4.483808789514264e-05,
      "loss": 0.0,
      "step": 1840
    },
    {
      "epoch": 0.41202672605790647,
      "grad_norm": 0.0004977515200152993,
      "learning_rate": 4.4799537393986125e-05,
      "loss": 0.0,
      "step": 1850
    },
    {
      "epoch": 0.4142538975501114,
      "grad_norm": 0.0007092118612490594,
      "learning_rate": 4.476098689282961e-05,
      "loss": 0.0,
      "step": 1860
    },
    {
      "epoch": 0.41648106904231624,
      "grad_norm": 0.0006570556433871388,
      "learning_rate": 4.472243639167309e-05,
      "loss": 0.0,
      "step": 1870
    },
    {
      "epoch": 0.41870824053452116,
      "grad_norm": 0.0005447635776363313,
      "learning_rate": 4.468388589051658e-05,
      "loss": 0.0,
      "step": 1880
    },
    {
      "epoch": 0.4209354120267261,
      "grad_norm": 0.0005734127480536699,
      "learning_rate": 4.4645335389360067e-05,
      "loss": 0.0,
      "step": 1890
    },
    {
      "epoch": 0.42316258351893093,
      "grad_norm": 0.00027139150188304484,
      "learning_rate": 4.460678488820355e-05,
      "loss": 0.0,
      "step": 1900
    },
    {
      "epoch": 0.42538975501113585,
      "grad_norm": 0.0003526418295223266,
      "learning_rate": 4.4568234387047034e-05,
      "loss": 0.0,
      "step": 1910
    },
    {
      "epoch": 0.42761692650334077,
      "grad_norm": 0.0004612547636497766,
      "learning_rate": 4.452968388589052e-05,
      "loss": 0.0,
      "step": 1920
    },
    {
      "epoch": 0.4298440979955457,
      "grad_norm": 0.00020060790120624006,
      "learning_rate": 4.4491133384734e-05,
      "loss": 0.0,
      "step": 1930
    },
    {
      "epoch": 0.43207126948775054,
      "grad_norm": 0.00025065711815841496,
      "learning_rate": 4.4452582883577485e-05,
      "loss": 0.0,
      "step": 1940
    },
    {
      "epoch": 0.43429844097995546,
      "grad_norm": 0.000687809195369482,
      "learning_rate": 4.4414032382420976e-05,
      "loss": 0.0,
      "step": 1950
    },
    {
      "epoch": 0.4365256124721604,
      "grad_norm": 0.0002696731826290488,
      "learning_rate": 4.437548188126446e-05,
      "loss": 0.0,
      "step": 1960
    },
    {
      "epoch": 0.43875278396436523,
      "grad_norm": 0.00027800185489468277,
      "learning_rate": 4.433693138010794e-05,
      "loss": 0.0,
      "step": 1970
    },
    {
      "epoch": 0.44097995545657015,
      "grad_norm": 0.0003358863468747586,
      "learning_rate": 4.429838087895143e-05,
      "loss": 0.0,
      "step": 1980
    },
    {
      "epoch": 0.44320712694877507,
      "grad_norm": 0.00025063971406780183,
      "learning_rate": 4.425983037779492e-05,
      "loss": 0.0,
      "step": 1990
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.0002283905923832208,
      "learning_rate": 4.42212798766384e-05,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 0.44766146993318484,
      "grad_norm": 0.00028414212283678353,
      "learning_rate": 4.4182729375481885e-05,
      "loss": 0.0,
      "step": 2010
    },
    {
      "epoch": 0.44988864142538976,
      "grad_norm": 0.0002541285357438028,
      "learning_rate": 4.414417887432537e-05,
      "loss": 0.0,
      "step": 2020
    },
    {
      "epoch": 0.4521158129175947,
      "grad_norm": 0.0003097271837759763,
      "learning_rate": 4.410562837316886e-05,
      "loss": 0.0,
      "step": 2030
    },
    {
      "epoch": 0.45434298440979953,
      "grad_norm": 0.00019927140965592116,
      "learning_rate": 4.4067077872012336e-05,
      "loss": 0.0,
      "step": 2040
    },
    {
      "epoch": 0.45657015590200445,
      "grad_norm": 0.0003926644567400217,
      "learning_rate": 4.402852737085582e-05,
      "loss": 0.0,
      "step": 2050
    },
    {
      "epoch": 0.45879732739420936,
      "grad_norm": 0.00026364834047853947,
      "learning_rate": 4.39899768696993e-05,
      "loss": 0.0,
      "step": 2060
    },
    {
      "epoch": 0.4610244988864143,
      "grad_norm": 0.0003544599749147892,
      "learning_rate": 4.3951426368542794e-05,
      "loss": 0.0,
      "step": 2070
    },
    {
      "epoch": 0.46325167037861914,
      "grad_norm": 0.00031236401991918683,
      "learning_rate": 4.391287586738628e-05,
      "loss": 0.0,
      "step": 2080
    },
    {
      "epoch": 0.46547884187082406,
      "grad_norm": 0.00881137978285551,
      "learning_rate": 4.387432536622976e-05,
      "loss": 0.0,
      "step": 2090
    },
    {
      "epoch": 0.46770601336302897,
      "grad_norm": 0.0001897539768833667,
      "learning_rate": 4.3835774865073245e-05,
      "loss": 0.0,
      "step": 2100
    },
    {
      "epoch": 0.46993318485523383,
      "grad_norm": 0.00021031378128100187,
      "learning_rate": 4.3797224363916735e-05,
      "loss": 0.0,
      "step": 2110
    },
    {
      "epoch": 0.47216035634743875,
      "grad_norm": 0.00033220002660527825,
      "learning_rate": 4.375867386276022e-05,
      "loss": 0.0,
      "step": 2120
    },
    {
      "epoch": 0.47438752783964366,
      "grad_norm": 0.00026820923085324466,
      "learning_rate": 4.37201233616037e-05,
      "loss": 0.0,
      "step": 2130
    },
    {
      "epoch": 0.4766146993318486,
      "grad_norm": 0.0003019977011717856,
      "learning_rate": 4.3681572860447187e-05,
      "loss": 0.0,
      "step": 2140
    },
    {
      "epoch": 0.47884187082405344,
      "grad_norm": 0.00016682011482771486,
      "learning_rate": 4.364302235929068e-05,
      "loss": 0.0,
      "step": 2150
    },
    {
      "epoch": 0.48106904231625836,
      "grad_norm": 0.0001762968604452908,
      "learning_rate": 4.360447185813416e-05,
      "loss": 0.0,
      "step": 2160
    },
    {
      "epoch": 0.48329621380846327,
      "grad_norm": 0.0002879390958696604,
      "learning_rate": 4.356592135697764e-05,
      "loss": 0.0,
      "step": 2170
    },
    {
      "epoch": 0.48552338530066813,
      "grad_norm": 0.00030516277183778584,
      "learning_rate": 4.352737085582113e-05,
      "loss": 0.0,
      "step": 2180
    },
    {
      "epoch": 0.48775055679287305,
      "grad_norm": 0.0002903284039348364,
      "learning_rate": 4.348882035466461e-05,
      "loss": 0.0,
      "step": 2190
    },
    {
      "epoch": 0.48997772828507796,
      "grad_norm": 0.00015976096619851887,
      "learning_rate": 4.3450269853508096e-05,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 0.4922048997772829,
      "grad_norm": 0.0001243038714164868,
      "learning_rate": 4.341171935235158e-05,
      "loss": 0.0,
      "step": 2210
    },
    {
      "epoch": 0.49443207126948774,
      "grad_norm": 0.00015202203940134495,
      "learning_rate": 4.337316885119507e-05,
      "loss": 0.0,
      "step": 2220
    },
    {
      "epoch": 0.49665924276169265,
      "grad_norm": 0.00021134661801625043,
      "learning_rate": 4.3334618350038554e-05,
      "loss": 0.0,
      "step": 2230
    },
    {
      "epoch": 0.49888641425389757,
      "grad_norm": 0.0002100022102240473,
      "learning_rate": 4.329606784888204e-05,
      "loss": 0.0,
      "step": 2240
    },
    {
      "epoch": 0.5011135857461024,
      "grad_norm": 0.00020145188318565488,
      "learning_rate": 4.325751734772552e-05,
      "loss": 0.0048,
      "step": 2250
    },
    {
      "epoch": 0.5033407572383074,
      "grad_norm": 0.00019276955572422594,
      "learning_rate": 4.321896684656901e-05,
      "loss": 0.1059,
      "step": 2260
    },
    {
      "epoch": 0.5055679287305123,
      "grad_norm": 0.0002645141794346273,
      "learning_rate": 4.3180416345412495e-05,
      "loss": 0.0,
      "step": 2270
    },
    {
      "epoch": 0.5077951002227171,
      "grad_norm": 0.00018088033539243042,
      "learning_rate": 4.314186584425598e-05,
      "loss": 0.0707,
      "step": 2280
    },
    {
      "epoch": 0.5100222717149221,
      "grad_norm": 0.0005815575714223087,
      "learning_rate": 4.310331534309946e-05,
      "loss": 0.0,
      "step": 2290
    },
    {
      "epoch": 0.512249443207127,
      "grad_norm": 0.0002722882782109082,
      "learning_rate": 4.3064764841942946e-05,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 0.5144766146993318,
      "grad_norm": 0.0003896223206538707,
      "learning_rate": 4.302621434078643e-05,
      "loss": 0.0,
      "step": 2310
    },
    {
      "epoch": 0.5167037861915368,
      "grad_norm": 0.0002769269049167633,
      "learning_rate": 4.2987663839629914e-05,
      "loss": 0.0,
      "step": 2320
    },
    {
      "epoch": 0.5189309576837416,
      "grad_norm": 0.0003637747431639582,
      "learning_rate": 4.2949113338473404e-05,
      "loss": 0.0,
      "step": 2330
    },
    {
      "epoch": 0.5211581291759465,
      "grad_norm": 0.000259217107668519,
      "learning_rate": 4.291056283731689e-05,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 0.5233853006681515,
      "grad_norm": 0.00026838446501642466,
      "learning_rate": 4.287201233616037e-05,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 0.5256124721603563,
      "grad_norm": 0.00020945107098668814,
      "learning_rate": 4.2833461835003855e-05,
      "loss": 0.0,
      "step": 2360
    },
    {
      "epoch": 0.5278396436525612,
      "grad_norm": 0.00010726645268732682,
      "learning_rate": 4.2794911333847346e-05,
      "loss": 0.0,
      "step": 2370
    },
    {
      "epoch": 0.5300668151447662,
      "grad_norm": 0.00023083029373083264,
      "learning_rate": 4.275636083269083e-05,
      "loss": 0.0,
      "step": 2380
    },
    {
      "epoch": 0.532293986636971,
      "grad_norm": 0.0002932041243184358,
      "learning_rate": 4.271781033153431e-05,
      "loss": 0.0,
      "step": 2390
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.00024158954329323024,
      "learning_rate": 4.26792598303778e-05,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 0.5367483296213809,
      "grad_norm": 0.00017432335880585015,
      "learning_rate": 4.264070932922129e-05,
      "loss": 0.0,
      "step": 2410
    },
    {
      "epoch": 0.5389755011135857,
      "grad_norm": 0.00025588905555196106,
      "learning_rate": 4.2602158828064764e-05,
      "loss": 0.0,
      "step": 2420
    },
    {
      "epoch": 0.5412026726057907,
      "grad_norm": 0.00020005925034638494,
      "learning_rate": 4.256360832690825e-05,
      "loss": 0.0,
      "step": 2430
    },
    {
      "epoch": 0.5434298440979956,
      "grad_norm": 1.326442837715149,
      "learning_rate": 4.252505782575173e-05,
      "loss": 0.0002,
      "step": 2440
    },
    {
      "epoch": 0.5456570155902004,
      "grad_norm": 0.000160490395501256,
      "learning_rate": 4.248650732459522e-05,
      "loss": 0.0,
      "step": 2450
    },
    {
      "epoch": 0.5478841870824054,
      "grad_norm": 0.00026525784051045775,
      "learning_rate": 4.2447956823438706e-05,
      "loss": 0.0,
      "step": 2460
    },
    {
      "epoch": 0.5501113585746102,
      "grad_norm": 0.00028466308140195906,
      "learning_rate": 4.240940632228219e-05,
      "loss": 0.0,
      "step": 2470
    },
    {
      "epoch": 0.5523385300668151,
      "grad_norm": 0.0003406311443541199,
      "learning_rate": 4.2370855821125673e-05,
      "loss": 0.0,
      "step": 2480
    },
    {
      "epoch": 0.5545657015590201,
      "grad_norm": 0.0014456204371526837,
      "learning_rate": 4.2332305319969164e-05,
      "loss": 0.1394,
      "step": 2490
    },
    {
      "epoch": 0.5567928730512249,
      "grad_norm": 0.018602000549435616,
      "learning_rate": 4.229375481881265e-05,
      "loss": 0.0006,
      "step": 2500
    },
    {
      "epoch": 0.5590200445434298,
      "grad_norm": 0.004737880080938339,
      "learning_rate": 4.225520431765613e-05,
      "loss": 0.0002,
      "step": 2510
    },
    {
      "epoch": 0.5612472160356348,
      "grad_norm": 0.0007649053004570305,
      "learning_rate": 4.2216653816499615e-05,
      "loss": 0.0001,
      "step": 2520
    },
    {
      "epoch": 0.5634743875278396,
      "grad_norm": 0.00045079676783643663,
      "learning_rate": 4.2178103315343106e-05,
      "loss": 0.0,
      "step": 2530
    },
    {
      "epoch": 0.5657015590200446,
      "grad_norm": 0.002734321402385831,
      "learning_rate": 4.213955281418659e-05,
      "loss": 0.0001,
      "step": 2540
    },
    {
      "epoch": 0.5679287305122495,
      "grad_norm": 0.0004303815949242562,
      "learning_rate": 4.2101002313030066e-05,
      "loss": 0.0001,
      "step": 2550
    },
    {
      "epoch": 0.5701559020044543,
      "grad_norm": 0.0009247238049283624,
      "learning_rate": 4.206245181187356e-05,
      "loss": 0.0001,
      "step": 2560
    },
    {
      "epoch": 0.5723830734966593,
      "grad_norm": 0.0008175800903700292,
      "learning_rate": 4.202390131071704e-05,
      "loss": 0.0,
      "step": 2570
    },
    {
      "epoch": 0.5746102449888641,
      "grad_norm": 0.0006684832042083144,
      "learning_rate": 4.1985350809560524e-05,
      "loss": 0.0,
      "step": 2580
    },
    {
      "epoch": 0.576837416481069,
      "grad_norm": 0.0016378102591261268,
      "learning_rate": 4.194680030840401e-05,
      "loss": 0.0,
      "step": 2590
    },
    {
      "epoch": 0.579064587973274,
      "grad_norm": 0.001343109761364758,
      "learning_rate": 4.19082498072475e-05,
      "loss": 0.0007,
      "step": 2600
    },
    {
      "epoch": 0.5812917594654788,
      "grad_norm": 0.0011126409517601132,
      "learning_rate": 4.186969930609098e-05,
      "loss": 0.0,
      "step": 2610
    },
    {
      "epoch": 0.5835189309576837,
      "grad_norm": 0.0002313750155735761,
      "learning_rate": 4.1831148804934466e-05,
      "loss": 0.0001,
      "step": 2620
    },
    {
      "epoch": 0.5857461024498887,
      "grad_norm": 0.0008886293508112431,
      "learning_rate": 4.179259830377795e-05,
      "loss": 0.0,
      "step": 2630
    },
    {
      "epoch": 0.5879732739420935,
      "grad_norm": 0.00032957884832285345,
      "learning_rate": 4.175404780262144e-05,
      "loss": 0.0869,
      "step": 2640
    },
    {
      "epoch": 0.5902004454342984,
      "grad_norm": 0.0008201717282645404,
      "learning_rate": 4.1715497301464924e-05,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 0.5924276169265034,
      "grad_norm": 0.00025711231864988804,
      "learning_rate": 4.167694680030841e-05,
      "loss": 0.0,
      "step": 2660
    },
    {
      "epoch": 0.5946547884187082,
      "grad_norm": 0.0008011129684746265,
      "learning_rate": 4.163839629915189e-05,
      "loss": 0.0,
      "step": 2670
    },
    {
      "epoch": 0.5968819599109132,
      "grad_norm": 0.0010779767762869596,
      "learning_rate": 4.1599845797995375e-05,
      "loss": 0.0,
      "step": 2680
    },
    {
      "epoch": 0.5991091314031181,
      "grad_norm": 0.0010311354417353868,
      "learning_rate": 4.156129529683886e-05,
      "loss": 0.0,
      "step": 2690
    },
    {
      "epoch": 0.6013363028953229,
      "grad_norm": 0.00023698681616224349,
      "learning_rate": 4.152274479568234e-05,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 0.6035634743875279,
      "grad_norm": 0.00045445479918271303,
      "learning_rate": 4.148419429452583e-05,
      "loss": 0.0,
      "step": 2710
    },
    {
      "epoch": 0.6057906458797327,
      "grad_norm": 0.00023948757734615356,
      "learning_rate": 4.1445643793369317e-05,
      "loss": 0.0,
      "step": 2720
    },
    {
      "epoch": 0.6080178173719376,
      "grad_norm": 0.0005660987226292491,
      "learning_rate": 4.14070932922128e-05,
      "loss": 0.0,
      "step": 2730
    },
    {
      "epoch": 0.6102449888641426,
      "grad_norm": 0.00026418882771395147,
      "learning_rate": 4.1368542791056284e-05,
      "loss": 0.0,
      "step": 2740
    },
    {
      "epoch": 0.6124721603563474,
      "grad_norm": 0.0010307327611371875,
      "learning_rate": 4.1329992289899774e-05,
      "loss": 0.0,
      "step": 2750
    },
    {
      "epoch": 0.6146993318485523,
      "grad_norm": 0.0007111537852324545,
      "learning_rate": 4.129144178874326e-05,
      "loss": 0.0,
      "step": 2760
    },
    {
      "epoch": 0.6169265033407573,
      "grad_norm": 0.00017744976503308862,
      "learning_rate": 4.125289128758674e-05,
      "loss": 0.0,
      "step": 2770
    },
    {
      "epoch": 0.6191536748329621,
      "grad_norm": 0.00018538543372415006,
      "learning_rate": 4.1214340786430226e-05,
      "loss": 0.0,
      "step": 2780
    },
    {
      "epoch": 0.621380846325167,
      "grad_norm": 0.00015498687571380287,
      "learning_rate": 4.1175790285273716e-05,
      "loss": 0.0,
      "step": 2790
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.00032607323373667896,
      "learning_rate": 4.113723978411719e-05,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 0.6258351893095768,
      "grad_norm": 0.00030000731931068003,
      "learning_rate": 4.109868928296068e-05,
      "loss": 0.0,
      "step": 2810
    },
    {
      "epoch": 0.6280623608017817,
      "grad_norm": 0.000638816796708852,
      "learning_rate": 4.106013878180416e-05,
      "loss": 0.0,
      "step": 2820
    },
    {
      "epoch": 0.6302895322939867,
      "grad_norm": 0.0001565155980642885,
      "learning_rate": 4.102158828064765e-05,
      "loss": 0.0,
      "step": 2830
    },
    {
      "epoch": 0.6325167037861915,
      "grad_norm": 0.0030806143768131733,
      "learning_rate": 4.0983037779491135e-05,
      "loss": 0.1463,
      "step": 2840
    },
    {
      "epoch": 0.6347438752783965,
      "grad_norm": 0.007997855544090271,
      "learning_rate": 4.094448727833462e-05,
      "loss": 0.0002,
      "step": 2850
    },
    {
      "epoch": 0.6369710467706013,
      "grad_norm": 0.004887103568762541,
      "learning_rate": 4.09059367771781e-05,
      "loss": 0.0002,
      "step": 2860
    },
    {
      "epoch": 0.6391982182628062,
      "grad_norm": 0.006579360458999872,
      "learning_rate": 4.086738627602159e-05,
      "loss": 0.0002,
      "step": 2870
    },
    {
      "epoch": 0.6414253897550112,
      "grad_norm": 0.0008752902504056692,
      "learning_rate": 4.0828835774865076e-05,
      "loss": 0.0001,
      "step": 2880
    },
    {
      "epoch": 0.643652561247216,
      "grad_norm": 0.005229898728430271,
      "learning_rate": 4.079028527370856e-05,
      "loss": 0.0001,
      "step": 2890
    },
    {
      "epoch": 0.6458797327394209,
      "grad_norm": 0.0022277552634477615,
      "learning_rate": 4.0751734772552044e-05,
      "loss": 0.0001,
      "step": 2900
    },
    {
      "epoch": 0.6481069042316259,
      "grad_norm": 0.0018573213601484895,
      "learning_rate": 4.0713184271395534e-05,
      "loss": 0.0001,
      "step": 2910
    },
    {
      "epoch": 0.6503340757238307,
      "grad_norm": 0.0020243863109499216,
      "learning_rate": 4.067463377023901e-05,
      "loss": 0.0001,
      "step": 2920
    },
    {
      "epoch": 0.6525612472160356,
      "grad_norm": 0.0007021389901638031,
      "learning_rate": 4.0636083269082495e-05,
      "loss": 0.0,
      "step": 2930
    },
    {
      "epoch": 0.6547884187082406,
      "grad_norm": 0.0017332455608993769,
      "learning_rate": 4.0597532767925985e-05,
      "loss": 0.0001,
      "step": 2940
    },
    {
      "epoch": 0.6570155902004454,
      "grad_norm": 0.0018174854340031743,
      "learning_rate": 4.055898226676947e-05,
      "loss": 0.0001,
      "step": 2950
    },
    {
      "epoch": 0.6592427616926503,
      "grad_norm": 0.0015441302675753832,
      "learning_rate": 4.052043176561295e-05,
      "loss": 0.0,
      "step": 2960
    },
    {
      "epoch": 0.6614699331848553,
      "grad_norm": 0.001032699947245419,
      "learning_rate": 4.0481881264456437e-05,
      "loss": 0.0,
      "step": 2970
    },
    {
      "epoch": 0.6636971046770601,
      "grad_norm": 0.00044125542626716197,
      "learning_rate": 4.044333076329993e-05,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 0.6659242761692651,
      "grad_norm": 0.0009667433332651854,
      "learning_rate": 4.040478026214341e-05,
      "loss": 0.0,
      "step": 2990
    },
    {
      "epoch": 0.6681514476614699,
      "grad_norm": 0.0003516009310260415,
      "learning_rate": 4.0366229760986894e-05,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 0.6703786191536748,
      "grad_norm": 0.0015322661492973566,
      "learning_rate": 4.032767925983038e-05,
      "loss": 0.0,
      "step": 3010
    },
    {
      "epoch": 0.6726057906458798,
      "grad_norm": 0.000876994919963181,
      "learning_rate": 4.028912875867387e-05,
      "loss": 0.0,
      "step": 3020
    },
    {
      "epoch": 0.6748329621380846,
      "grad_norm": 0.00034614064497873187,
      "learning_rate": 4.025057825751735e-05,
      "loss": 0.0,
      "step": 3030
    },
    {
      "epoch": 0.6770601336302895,
      "grad_norm": 0.000813994905911386,
      "learning_rate": 4.0212027756360836e-05,
      "loss": 0.0,
      "step": 3040
    },
    {
      "epoch": 0.6792873051224945,
      "grad_norm": 0.00023068086011335254,
      "learning_rate": 4.017347725520432e-05,
      "loss": 0.0,
      "step": 3050
    },
    {
      "epoch": 0.6815144766146993,
      "grad_norm": 0.001094404375180602,
      "learning_rate": 4.0134926754047803e-05,
      "loss": 0.0,
      "step": 3060
    },
    {
      "epoch": 0.6837416481069042,
      "grad_norm": 0.000730548519641161,
      "learning_rate": 4.009637625289129e-05,
      "loss": 0.0,
      "step": 3070
    },
    {
      "epoch": 0.6859688195991092,
      "grad_norm": 0.00039700401248410344,
      "learning_rate": 4.005782575173477e-05,
      "loss": 0.0,
      "step": 3080
    },
    {
      "epoch": 0.688195991091314,
      "grad_norm": 0.0009495611884631217,
      "learning_rate": 4.001927525057826e-05,
      "loss": 0.0,
      "step": 3090
    },
    {
      "epoch": 0.6904231625835189,
      "grad_norm": 0.0005000840174034238,
      "learning_rate": 3.9980724749421745e-05,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 0.6926503340757239,
      "grad_norm": 0.000807891832664609,
      "learning_rate": 3.994217424826523e-05,
      "loss": 0.0,
      "step": 3110
    },
    {
      "epoch": 0.6948775055679287,
      "grad_norm": 0.0007179659442044795,
      "learning_rate": 3.990362374710871e-05,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 0.6971046770601337,
      "grad_norm": 0.00021862825087737292,
      "learning_rate": 3.98650732459522e-05,
      "loss": 0.0,
      "step": 3130
    },
    {
      "epoch": 0.6993318485523385,
      "grad_norm": 0.0007914184825494885,
      "learning_rate": 3.982652274479569e-05,
      "loss": 0.0,
      "step": 3140
    },
    {
      "epoch": 0.7015590200445434,
      "grad_norm": 0.0004448989639058709,
      "learning_rate": 3.978797224363917e-05,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 0.7037861915367484,
      "grad_norm": 0.0005098663386888802,
      "learning_rate": 3.9749421742482654e-05,
      "loss": 0.0,
      "step": 3160
    },
    {
      "epoch": 0.7060133630289532,
      "grad_norm": 0.0004451029235497117,
      "learning_rate": 3.9710871241326145e-05,
      "loss": 0.0,
      "step": 3170
    },
    {
      "epoch": 0.7082405345211581,
      "grad_norm": 0.0002661039470694959,
      "learning_rate": 3.967232074016962e-05,
      "loss": 0.0,
      "step": 3180
    },
    {
      "epoch": 0.7104677060133631,
      "grad_norm": 0.000525188515894115,
      "learning_rate": 3.9633770239013105e-05,
      "loss": 0.0,
      "step": 3190
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.000537294487003237,
      "learning_rate": 3.9595219737856596e-05,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 0.7149220489977728,
      "grad_norm": 0.00024381428374908864,
      "learning_rate": 3.955666923670008e-05,
      "loss": 0.0,
      "step": 3210
    },
    {
      "epoch": 0.7171492204899778,
      "grad_norm": 0.00045926414895802736,
      "learning_rate": 3.951811873554356e-05,
      "loss": 0.0,
      "step": 3220
    },
    {
      "epoch": 0.7193763919821826,
      "grad_norm": 0.00015859499399084598,
      "learning_rate": 3.947956823438705e-05,
      "loss": 0.0,
      "step": 3230
    },
    {
      "epoch": 0.7216035634743875,
      "grad_norm": 0.0007333502871915698,
      "learning_rate": 3.944101773323054e-05,
      "loss": 0.0,
      "step": 3240
    },
    {
      "epoch": 0.7238307349665924,
      "grad_norm": 0.00042863021371886134,
      "learning_rate": 3.940246723207402e-05,
      "loss": 0.0,
      "step": 3250
    },
    {
      "epoch": 0.7260579064587973,
      "grad_norm": 0.00032288357033394277,
      "learning_rate": 3.9363916730917505e-05,
      "loss": 0.0,
      "step": 3260
    },
    {
      "epoch": 0.7282850779510023,
      "grad_norm": 0.0015761787071824074,
      "learning_rate": 3.932536622976099e-05,
      "loss": 0.0,
      "step": 3270
    },
    {
      "epoch": 0.7305122494432071,
      "grad_norm": 0.0004929349524900317,
      "learning_rate": 3.928681572860448e-05,
      "loss": 0.0,
      "step": 3280
    },
    {
      "epoch": 0.732739420935412,
      "grad_norm": 0.0007659941329620779,
      "learning_rate": 3.924826522744796e-05,
      "loss": 0.0,
      "step": 3290
    },
    {
      "epoch": 0.734966592427617,
      "grad_norm": 0.0001819997123675421,
      "learning_rate": 3.920971472629144e-05,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 0.7371937639198218,
      "grad_norm": 0.0018726077396422625,
      "learning_rate": 3.9171164225134923e-05,
      "loss": 0.0,
      "step": 3310
    },
    {
      "epoch": 0.7394209354120267,
      "grad_norm": 0.0013080404605716467,
      "learning_rate": 3.9132613723978414e-05,
      "loss": 0.0,
      "step": 3320
    },
    {
      "epoch": 0.7416481069042317,
      "grad_norm": 0.000130145184812136,
      "learning_rate": 3.90940632228219e-05,
      "loss": 0.0,
      "step": 3330
    },
    {
      "epoch": 0.7438752783964365,
      "grad_norm": 0.00016184076957870275,
      "learning_rate": 3.905551272166538e-05,
      "loss": 0.0,
      "step": 3340
    },
    {
      "epoch": 0.7461024498886414,
      "grad_norm": 0.0008521195850335062,
      "learning_rate": 3.9016962220508865e-05,
      "loss": 0.0,
      "step": 3350
    },
    {
      "epoch": 0.7483296213808464,
      "grad_norm": 0.0007329609361477196,
      "learning_rate": 3.8978411719352356e-05,
      "loss": 0.0,
      "step": 3360
    },
    {
      "epoch": 0.7505567928730512,
      "grad_norm": 0.0005094830994494259,
      "learning_rate": 3.893986121819584e-05,
      "loss": 0.0,
      "step": 3370
    },
    {
      "epoch": 0.7527839643652561,
      "grad_norm": 0.00043443645699881017,
      "learning_rate": 3.890131071703932e-05,
      "loss": 0.0,
      "step": 3380
    },
    {
      "epoch": 0.755011135857461,
      "grad_norm": 0.0002736199530772865,
      "learning_rate": 3.886276021588281e-05,
      "loss": 0.0,
      "step": 3390
    },
    {
      "epoch": 0.7572383073496659,
      "grad_norm": 0.0006232046289369464,
      "learning_rate": 3.88242097147263e-05,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 0.7594654788418709,
      "grad_norm": 0.0004833474522456527,
      "learning_rate": 3.878565921356978e-05,
      "loss": 0.0,
      "step": 3410
    },
    {
      "epoch": 0.7616926503340757,
      "grad_norm": 0.0003467232745606452,
      "learning_rate": 3.8747108712413265e-05,
      "loss": 0.0,
      "step": 3420
    },
    {
      "epoch": 0.7639198218262806,
      "grad_norm": 0.00019307642651256174,
      "learning_rate": 3.870855821125675e-05,
      "loss": 0.0,
      "step": 3430
    },
    {
      "epoch": 0.7661469933184856,
      "grad_norm": 0.00024653508444316685,
      "learning_rate": 3.867000771010023e-05,
      "loss": 0.0,
      "step": 3440
    },
    {
      "epoch": 0.7683741648106904,
      "grad_norm": 0.0002766924735624343,
      "learning_rate": 3.8631457208943716e-05,
      "loss": 0.0,
      "step": 3450
    },
    {
      "epoch": 0.7706013363028953,
      "grad_norm": 0.00018661456124391407,
      "learning_rate": 3.85929067077872e-05,
      "loss": 0.0,
      "step": 3460
    },
    {
      "epoch": 0.7728285077951003,
      "grad_norm": 0.0002908989554271102,
      "learning_rate": 3.855435620663069e-05,
      "loss": 0.0,
      "step": 3470
    },
    {
      "epoch": 0.7750556792873051,
      "grad_norm": 0.00019832549151033163,
      "learning_rate": 3.8515805705474174e-05,
      "loss": 0.0,
      "step": 3480
    },
    {
      "epoch": 0.77728285077951,
      "grad_norm": 7.54355060053058e-05,
      "learning_rate": 3.847725520431766e-05,
      "loss": 0.0,
      "step": 3490
    },
    {
      "epoch": 0.779510022271715,
      "grad_norm": 0.0001069350546458736,
      "learning_rate": 3.843870470316114e-05,
      "loss": 0.0,
      "step": 3500
    }
  ],
  "logging_steps": 10,
  "max_steps": 13470,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3709087162368000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
