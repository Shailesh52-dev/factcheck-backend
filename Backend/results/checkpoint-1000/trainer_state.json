{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.22271714922049,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0022271714922048997,
      "grad_norm": 3.431209087371826,
      "learning_rate": 9e-07,
      "loss": 0.6988,
      "step": 10
    },
    {
      "epoch": 0.004454342984409799,
      "grad_norm": 1.5945241451263428,
      "learning_rate": 1.9e-06,
      "loss": 0.6943,
      "step": 20
    },
    {
      "epoch": 0.0066815144766146995,
      "grad_norm": 1.3031045198440552,
      "learning_rate": 2.9e-06,
      "loss": 0.6927,
      "step": 30
    },
    {
      "epoch": 0.008908685968819599,
      "grad_norm": 2.643918514251709,
      "learning_rate": 3.9e-06,
      "loss": 0.6881,
      "step": 40
    },
    {
      "epoch": 0.011135857461024499,
      "grad_norm": 1.3544669151306152,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.6639,
      "step": 50
    },
    {
      "epoch": 0.013363028953229399,
      "grad_norm": 2.9651875495910645,
      "learning_rate": 5.9e-06,
      "loss": 0.651,
      "step": 60
    },
    {
      "epoch": 0.015590200445434299,
      "grad_norm": 3.1865758895874023,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.5755,
      "step": 70
    },
    {
      "epoch": 0.017817371937639197,
      "grad_norm": 3.4834768772125244,
      "learning_rate": 7.9e-06,
      "loss": 0.4199,
      "step": 80
    },
    {
      "epoch": 0.0200445434298441,
      "grad_norm": 1.7848082780838013,
      "learning_rate": 8.9e-06,
      "loss": 0.2412,
      "step": 90
    },
    {
      "epoch": 0.022271714922048998,
      "grad_norm": 0.9703733325004578,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.1429,
      "step": 100
    },
    {
      "epoch": 0.024498886414253896,
      "grad_norm": 0.5473387241363525,
      "learning_rate": 1.09e-05,
      "loss": 0.0967,
      "step": 110
    },
    {
      "epoch": 0.026726057906458798,
      "grad_norm": 0.40797603130340576,
      "learning_rate": 1.19e-05,
      "loss": 0.0464,
      "step": 120
    },
    {
      "epoch": 0.028953229398663696,
      "grad_norm": 0.29466378688812256,
      "learning_rate": 1.29e-05,
      "loss": 0.0263,
      "step": 130
    },
    {
      "epoch": 0.031180400890868598,
      "grad_norm": 0.7490040063858032,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0188,
      "step": 140
    },
    {
      "epoch": 0.0334075723830735,
      "grad_norm": 0.1550196409225464,
      "learning_rate": 1.49e-05,
      "loss": 0.0102,
      "step": 150
    },
    {
      "epoch": 0.035634743875278395,
      "grad_norm": 8.649392127990723,
      "learning_rate": 1.59e-05,
      "loss": 0.0133,
      "step": 160
    },
    {
      "epoch": 0.0378619153674833,
      "grad_norm": 0.08959051966667175,
      "learning_rate": 1.69e-05,
      "loss": 0.0069,
      "step": 170
    },
    {
      "epoch": 0.0400890868596882,
      "grad_norm": 0.08933669328689575,
      "learning_rate": 1.79e-05,
      "loss": 0.0079,
      "step": 180
    },
    {
      "epoch": 0.042316258351893093,
      "grad_norm": 0.07168997079133987,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0057,
      "step": 190
    },
    {
      "epoch": 0.044543429844097995,
      "grad_norm": 0.06148263067007065,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0434,
      "step": 200
    },
    {
      "epoch": 0.0467706013363029,
      "grad_norm": 0.05540284141898155,
      "learning_rate": 2.09e-05,
      "loss": 0.0702,
      "step": 210
    },
    {
      "epoch": 0.04899777282850779,
      "grad_norm": 0.0727599635720253,
      "learning_rate": 2.19e-05,
      "loss": 0.0036,
      "step": 220
    },
    {
      "epoch": 0.051224944320712694,
      "grad_norm": 0.051876556128263474,
      "learning_rate": 2.29e-05,
      "loss": 0.003,
      "step": 230
    },
    {
      "epoch": 0.053452115812917596,
      "grad_norm": 0.0467323362827301,
      "learning_rate": 2.39e-05,
      "loss": 0.0028,
      "step": 240
    },
    {
      "epoch": 0.0556792873051225,
      "grad_norm": 0.036060597747564316,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.0025,
      "step": 250
    },
    {
      "epoch": 0.05790645879732739,
      "grad_norm": 0.04070688411593437,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.002,
      "step": 260
    },
    {
      "epoch": 0.060133630289532294,
      "grad_norm": 0.02991284243762493,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0019,
      "step": 270
    },
    {
      "epoch": 0.062360801781737196,
      "grad_norm": 0.02594655565917492,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0018,
      "step": 280
    },
    {
      "epoch": 0.0645879732739421,
      "grad_norm": 0.03034917078912258,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0015,
      "step": 290
    },
    {
      "epoch": 0.066815144766147,
      "grad_norm": 0.040472112596035004,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0013,
      "step": 300
    },
    {
      "epoch": 0.06904231625835189,
      "grad_norm": 0.036792658269405365,
      "learning_rate": 3.09e-05,
      "loss": 0.0013,
      "step": 310
    },
    {
      "epoch": 0.07126948775055679,
      "grad_norm": 0.01685582846403122,
      "learning_rate": 3.19e-05,
      "loss": 0.001,
      "step": 320
    },
    {
      "epoch": 0.07349665924276169,
      "grad_norm": 0.014991199597716331,
      "learning_rate": 3.29e-05,
      "loss": 0.001,
      "step": 330
    },
    {
      "epoch": 0.0757238307349666,
      "grad_norm": 0.015452426858246326,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0009,
      "step": 340
    },
    {
      "epoch": 0.0779510022271715,
      "grad_norm": 0.015531397424638271,
      "learning_rate": 3.49e-05,
      "loss": 0.0007,
      "step": 350
    },
    {
      "epoch": 0.0801781737193764,
      "grad_norm": 0.06109783425927162,
      "learning_rate": 3.59e-05,
      "loss": 0.0009,
      "step": 360
    },
    {
      "epoch": 0.08240534521158129,
      "grad_norm": 0.01355788018554449,
      "learning_rate": 3.69e-05,
      "loss": 0.0558,
      "step": 370
    },
    {
      "epoch": 0.08463251670378619,
      "grad_norm": 0.009466464631259441,
      "learning_rate": 3.79e-05,
      "loss": 0.0006,
      "step": 380
    },
    {
      "epoch": 0.08685968819599109,
      "grad_norm": 0.010187627747654915,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0007,
      "step": 390
    },
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 0.012195323593914509,
      "learning_rate": 3.99e-05,
      "loss": 0.0007,
      "step": 400
    },
    {
      "epoch": 0.09131403118040089,
      "grad_norm": 0.02273370325565338,
      "learning_rate": 4.09e-05,
      "loss": 0.0027,
      "step": 410
    },
    {
      "epoch": 0.0935412026726058,
      "grad_norm": 0.010213186033070087,
      "learning_rate": 4.19e-05,
      "loss": 0.0004,
      "step": 420
    },
    {
      "epoch": 0.0957683741648107,
      "grad_norm": 0.008116074837744236,
      "learning_rate": 4.29e-05,
      "loss": 0.0206,
      "step": 430
    },
    {
      "epoch": 0.09799554565701558,
      "grad_norm": 0.009267566725611687,
      "learning_rate": 4.39e-05,
      "loss": 0.001,
      "step": 440
    },
    {
      "epoch": 0.10022271714922049,
      "grad_norm": 0.007021318655461073,
      "learning_rate": 4.49e-05,
      "loss": 0.0005,
      "step": 450
    },
    {
      "epoch": 0.10244988864142539,
      "grad_norm": 35.92754364013672,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.0291,
      "step": 460
    },
    {
      "epoch": 0.10467706013363029,
      "grad_norm": 0.007265315391123295,
      "learning_rate": 4.69e-05,
      "loss": 0.0128,
      "step": 470
    },
    {
      "epoch": 0.10690423162583519,
      "grad_norm": 0.012291595339775085,
      "learning_rate": 4.79e-05,
      "loss": 0.0013,
      "step": 480
    },
    {
      "epoch": 0.1091314031180401,
      "grad_norm": 0.005603676196187735,
      "learning_rate": 4.89e-05,
      "loss": 0.0003,
      "step": 490
    },
    {
      "epoch": 0.111358574610245,
      "grad_norm": 0.009176917374134064,
      "learning_rate": 4.99e-05,
      "loss": 0.0729,
      "step": 500
    },
    {
      "epoch": 0.11358574610244988,
      "grad_norm": 0.01008897926658392,
      "learning_rate": 4.996530454895914e-05,
      "loss": 0.0005,
      "step": 510
    },
    {
      "epoch": 0.11581291759465479,
      "grad_norm": 0.008612244389951229,
      "learning_rate": 4.992675404780263e-05,
      "loss": 0.0004,
      "step": 520
    },
    {
      "epoch": 0.11804008908685969,
      "grad_norm": 0.03885987773537636,
      "learning_rate": 4.9888203546646105e-05,
      "loss": 0.1178,
      "step": 530
    },
    {
      "epoch": 0.12026726057906459,
      "grad_norm": 0.025776294991374016,
      "learning_rate": 4.984965304548959e-05,
      "loss": 0.0006,
      "step": 540
    },
    {
      "epoch": 0.12249443207126949,
      "grad_norm": 0.08023320883512497,
      "learning_rate": 4.981110254433308e-05,
      "loss": 0.0006,
      "step": 550
    },
    {
      "epoch": 0.12472160356347439,
      "grad_norm": 0.004364595282822847,
      "learning_rate": 4.977255204317656e-05,
      "loss": 0.0004,
      "step": 560
    },
    {
      "epoch": 0.12694877505567928,
      "grad_norm": 0.005635369103401899,
      "learning_rate": 4.973400154202005e-05,
      "loss": 0.0002,
      "step": 570
    },
    {
      "epoch": 0.1291759465478842,
      "grad_norm": 0.004209843464195728,
      "learning_rate": 4.969545104086353e-05,
      "loss": 0.0002,
      "step": 580
    },
    {
      "epoch": 0.13140311804008908,
      "grad_norm": 0.0034029444213956594,
      "learning_rate": 4.965690053970702e-05,
      "loss": 0.0002,
      "step": 590
    },
    {
      "epoch": 0.133630289532294,
      "grad_norm": 0.00575220724567771,
      "learning_rate": 4.9618350038550505e-05,
      "loss": 0.0002,
      "step": 600
    },
    {
      "epoch": 0.1358574610244989,
      "grad_norm": 0.004919408820569515,
      "learning_rate": 4.957979953739399e-05,
      "loss": 0.0002,
      "step": 610
    },
    {
      "epoch": 0.13808463251670378,
      "grad_norm": 0.0033537691924721003,
      "learning_rate": 4.954124903623747e-05,
      "loss": 0.0002,
      "step": 620
    },
    {
      "epoch": 0.1403118040089087,
      "grad_norm": 0.0032662146259099245,
      "learning_rate": 4.950269853508096e-05,
      "loss": 0.0001,
      "step": 630
    },
    {
      "epoch": 0.14253897550111358,
      "grad_norm": 0.0025406882632523775,
      "learning_rate": 4.9464148033924446e-05,
      "loss": 0.0001,
      "step": 640
    },
    {
      "epoch": 0.1447661469933185,
      "grad_norm": 0.02041727863252163,
      "learning_rate": 4.942559753276793e-05,
      "loss": 0.1093,
      "step": 650
    },
    {
      "epoch": 0.14699331848552338,
      "grad_norm": 0.03743819519877434,
      "learning_rate": 4.9387047031611414e-05,
      "loss": 0.0059,
      "step": 660
    },
    {
      "epoch": 0.1492204899777283,
      "grad_norm": 0.007928205654025078,
      "learning_rate": 4.93484965304549e-05,
      "loss": 0.0009,
      "step": 670
    },
    {
      "epoch": 0.1514476614699332,
      "grad_norm": 0.004348834045231342,
      "learning_rate": 4.930994602929838e-05,
      "loss": 0.0011,
      "step": 680
    },
    {
      "epoch": 0.15367483296213807,
      "grad_norm": 0.006778515409678221,
      "learning_rate": 4.9271395528141865e-05,
      "loss": 0.0002,
      "step": 690
    },
    {
      "epoch": 0.155902004454343,
      "grad_norm": 0.00542496656998992,
      "learning_rate": 4.9232845026985355e-05,
      "loss": 0.0002,
      "step": 700
    },
    {
      "epoch": 0.15812917594654788,
      "grad_norm": 0.004850401543080807,
      "learning_rate": 4.919429452582884e-05,
      "loss": 0.0002,
      "step": 710
    },
    {
      "epoch": 0.1603563474387528,
      "grad_norm": 0.004906316753476858,
      "learning_rate": 4.915574402467232e-05,
      "loss": 0.0002,
      "step": 720
    },
    {
      "epoch": 0.16258351893095768,
      "grad_norm": 0.0031026357319206,
      "learning_rate": 4.9117193523515807e-05,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 0.16481069042316257,
      "grad_norm": 0.0030167296063154936,
      "learning_rate": 4.90786430223593e-05,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 0.16703786191536749,
      "grad_norm": 0.003254351206123829,
      "learning_rate": 4.904009252120278e-05,
      "loss": 0.0001,
      "step": 750
    },
    {
      "epoch": 0.16926503340757237,
      "grad_norm": 0.0023794753942638636,
      "learning_rate": 4.9001542020046264e-05,
      "loss": 0.0001,
      "step": 760
    },
    {
      "epoch": 0.1714922048997773,
      "grad_norm": 0.0018970713717862964,
      "learning_rate": 4.896299151888975e-05,
      "loss": 0.0001,
      "step": 770
    },
    {
      "epoch": 0.17371937639198218,
      "grad_norm": 0.0077140796929597855,
      "learning_rate": 4.892444101773323e-05,
      "loss": 0.0494,
      "step": 780
    },
    {
      "epoch": 0.1759465478841871,
      "grad_norm": 0.005012082867324352,
      "learning_rate": 4.8885890516576716e-05,
      "loss": 0.0004,
      "step": 790
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.0030972680542618036,
      "learning_rate": 4.88473400154202e-05,
      "loss": 0.0002,
      "step": 800
    },
    {
      "epoch": 0.18040089086859687,
      "grad_norm": 0.008881570771336555,
      "learning_rate": 4.880878951426368e-05,
      "loss": 0.072,
      "step": 810
    },
    {
      "epoch": 0.18262806236080179,
      "grad_norm": 0.004121475387364626,
      "learning_rate": 4.8770239013107174e-05,
      "loss": 0.0006,
      "step": 820
    },
    {
      "epoch": 0.18485523385300667,
      "grad_norm": 0.003665172727778554,
      "learning_rate": 4.873168851195066e-05,
      "loss": 0.0002,
      "step": 830
    },
    {
      "epoch": 0.1870824053452116,
      "grad_norm": 0.0022593180183321238,
      "learning_rate": 4.869313801079414e-05,
      "loss": 0.0002,
      "step": 840
    },
    {
      "epoch": 0.18930957683741648,
      "grad_norm": 0.0030925734899938107,
      "learning_rate": 4.8654587509637625e-05,
      "loss": 0.0001,
      "step": 850
    },
    {
      "epoch": 0.1915367483296214,
      "grad_norm": 0.005627123173326254,
      "learning_rate": 4.8616037008481115e-05,
      "loss": 0.0866,
      "step": 860
    },
    {
      "epoch": 0.19376391982182628,
      "grad_norm": 0.017698820680379868,
      "learning_rate": 4.85774865073246e-05,
      "loss": 0.0003,
      "step": 870
    },
    {
      "epoch": 0.19599109131403117,
      "grad_norm": 0.0037356670945882797,
      "learning_rate": 4.853893600616808e-05,
      "loss": 0.0008,
      "step": 880
    },
    {
      "epoch": 0.19821826280623608,
      "grad_norm": 0.0017527706222608685,
      "learning_rate": 4.8500385505011566e-05,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 0.20044543429844097,
      "grad_norm": 0.00198148051276803,
      "learning_rate": 4.846183500385506e-05,
      "loss": 0.0001,
      "step": 900
    },
    {
      "epoch": 0.2026726057906459,
      "grad_norm": 0.0033013392239809036,
      "learning_rate": 4.8423284502698534e-05,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 0.20489977728285078,
      "grad_norm": 0.0024627968668937683,
      "learning_rate": 4.838473400154202e-05,
      "loss": 0.0001,
      "step": 920
    },
    {
      "epoch": 0.2071269487750557,
      "grad_norm": 0.002736808033660054,
      "learning_rate": 4.834618350038551e-05,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 0.20935412026726058,
      "grad_norm": 0.0016122461529448628,
      "learning_rate": 4.830763299922899e-05,
      "loss": 0.0001,
      "step": 940
    },
    {
      "epoch": 0.21158129175946547,
      "grad_norm": 0.00158878939691931,
      "learning_rate": 4.8269082498072475e-05,
      "loss": 0.0001,
      "step": 950
    },
    {
      "epoch": 0.21380846325167038,
      "grad_norm": 0.0011894447961822152,
      "learning_rate": 4.823053199691596e-05,
      "loss": 0.0001,
      "step": 960
    },
    {
      "epoch": 0.21603563474387527,
      "grad_norm": 0.0020984618458896875,
      "learning_rate": 4.819198149575945e-05,
      "loss": 0.0001,
      "step": 970
    },
    {
      "epoch": 0.2182628062360802,
      "grad_norm": 0.0013036364689469337,
      "learning_rate": 4.815343099460293e-05,
      "loss": 0.0001,
      "step": 980
    },
    {
      "epoch": 0.22048997772828507,
      "grad_norm": 0.0015882375882938504,
      "learning_rate": 4.811488049344642e-05,
      "loss": 0.0001,
      "step": 990
    },
    {
      "epoch": 0.22271714922049,
      "grad_norm": 0.0015365431318059564,
      "learning_rate": 4.80763299922899e-05,
      "loss": 0.0001,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 13470,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1059739189248000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
