{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.111358574610245,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0022271714922048997,
      "grad_norm": 3.431209087371826,
      "learning_rate": 9e-07,
      "loss": 0.6988,
      "step": 10
    },
    {
      "epoch": 0.004454342984409799,
      "grad_norm": 1.5945241451263428,
      "learning_rate": 1.9e-06,
      "loss": 0.6943,
      "step": 20
    },
    {
      "epoch": 0.0066815144766146995,
      "grad_norm": 1.3031045198440552,
      "learning_rate": 2.9e-06,
      "loss": 0.6927,
      "step": 30
    },
    {
      "epoch": 0.008908685968819599,
      "grad_norm": 2.643918514251709,
      "learning_rate": 3.9e-06,
      "loss": 0.6881,
      "step": 40
    },
    {
      "epoch": 0.011135857461024499,
      "grad_norm": 1.3544669151306152,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.6639,
      "step": 50
    },
    {
      "epoch": 0.013363028953229399,
      "grad_norm": 2.9651875495910645,
      "learning_rate": 5.9e-06,
      "loss": 0.651,
      "step": 60
    },
    {
      "epoch": 0.015590200445434299,
      "grad_norm": 3.1865758895874023,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.5755,
      "step": 70
    },
    {
      "epoch": 0.017817371937639197,
      "grad_norm": 3.4834768772125244,
      "learning_rate": 7.9e-06,
      "loss": 0.4199,
      "step": 80
    },
    {
      "epoch": 0.0200445434298441,
      "grad_norm": 1.7848082780838013,
      "learning_rate": 8.9e-06,
      "loss": 0.2412,
      "step": 90
    },
    {
      "epoch": 0.022271714922048998,
      "grad_norm": 0.9703733325004578,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.1429,
      "step": 100
    },
    {
      "epoch": 0.024498886414253896,
      "grad_norm": 0.5473387241363525,
      "learning_rate": 1.09e-05,
      "loss": 0.0967,
      "step": 110
    },
    {
      "epoch": 0.026726057906458798,
      "grad_norm": 0.40797603130340576,
      "learning_rate": 1.19e-05,
      "loss": 0.0464,
      "step": 120
    },
    {
      "epoch": 0.028953229398663696,
      "grad_norm": 0.29466378688812256,
      "learning_rate": 1.29e-05,
      "loss": 0.0263,
      "step": 130
    },
    {
      "epoch": 0.031180400890868598,
      "grad_norm": 0.7490040063858032,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0188,
      "step": 140
    },
    {
      "epoch": 0.0334075723830735,
      "grad_norm": 0.1550196409225464,
      "learning_rate": 1.49e-05,
      "loss": 0.0102,
      "step": 150
    },
    {
      "epoch": 0.035634743875278395,
      "grad_norm": 8.649392127990723,
      "learning_rate": 1.59e-05,
      "loss": 0.0133,
      "step": 160
    },
    {
      "epoch": 0.0378619153674833,
      "grad_norm": 0.08959051966667175,
      "learning_rate": 1.69e-05,
      "loss": 0.0069,
      "step": 170
    },
    {
      "epoch": 0.0400890868596882,
      "grad_norm": 0.08933669328689575,
      "learning_rate": 1.79e-05,
      "loss": 0.0079,
      "step": 180
    },
    {
      "epoch": 0.042316258351893093,
      "grad_norm": 0.07168997079133987,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0057,
      "step": 190
    },
    {
      "epoch": 0.044543429844097995,
      "grad_norm": 0.06148263067007065,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0434,
      "step": 200
    },
    {
      "epoch": 0.0467706013363029,
      "grad_norm": 0.05540284141898155,
      "learning_rate": 2.09e-05,
      "loss": 0.0702,
      "step": 210
    },
    {
      "epoch": 0.04899777282850779,
      "grad_norm": 0.0727599635720253,
      "learning_rate": 2.19e-05,
      "loss": 0.0036,
      "step": 220
    },
    {
      "epoch": 0.051224944320712694,
      "grad_norm": 0.051876556128263474,
      "learning_rate": 2.29e-05,
      "loss": 0.003,
      "step": 230
    },
    {
      "epoch": 0.053452115812917596,
      "grad_norm": 0.0467323362827301,
      "learning_rate": 2.39e-05,
      "loss": 0.0028,
      "step": 240
    },
    {
      "epoch": 0.0556792873051225,
      "grad_norm": 0.036060597747564316,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.0025,
      "step": 250
    },
    {
      "epoch": 0.05790645879732739,
      "grad_norm": 0.04070688411593437,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.002,
      "step": 260
    },
    {
      "epoch": 0.060133630289532294,
      "grad_norm": 0.02991284243762493,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0019,
      "step": 270
    },
    {
      "epoch": 0.062360801781737196,
      "grad_norm": 0.02594655565917492,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0018,
      "step": 280
    },
    {
      "epoch": 0.0645879732739421,
      "grad_norm": 0.03034917078912258,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0015,
      "step": 290
    },
    {
      "epoch": 0.066815144766147,
      "grad_norm": 0.040472112596035004,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0013,
      "step": 300
    },
    {
      "epoch": 0.06904231625835189,
      "grad_norm": 0.036792658269405365,
      "learning_rate": 3.09e-05,
      "loss": 0.0013,
      "step": 310
    },
    {
      "epoch": 0.07126948775055679,
      "grad_norm": 0.01685582846403122,
      "learning_rate": 3.19e-05,
      "loss": 0.001,
      "step": 320
    },
    {
      "epoch": 0.07349665924276169,
      "grad_norm": 0.014991199597716331,
      "learning_rate": 3.29e-05,
      "loss": 0.001,
      "step": 330
    },
    {
      "epoch": 0.0757238307349666,
      "grad_norm": 0.015452426858246326,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0009,
      "step": 340
    },
    {
      "epoch": 0.0779510022271715,
      "grad_norm": 0.015531397424638271,
      "learning_rate": 3.49e-05,
      "loss": 0.0007,
      "step": 350
    },
    {
      "epoch": 0.0801781737193764,
      "grad_norm": 0.06109783425927162,
      "learning_rate": 3.59e-05,
      "loss": 0.0009,
      "step": 360
    },
    {
      "epoch": 0.08240534521158129,
      "grad_norm": 0.01355788018554449,
      "learning_rate": 3.69e-05,
      "loss": 0.0558,
      "step": 370
    },
    {
      "epoch": 0.08463251670378619,
      "grad_norm": 0.009466464631259441,
      "learning_rate": 3.79e-05,
      "loss": 0.0006,
      "step": 380
    },
    {
      "epoch": 0.08685968819599109,
      "grad_norm": 0.010187627747654915,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0007,
      "step": 390
    },
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 0.012195323593914509,
      "learning_rate": 3.99e-05,
      "loss": 0.0007,
      "step": 400
    },
    {
      "epoch": 0.09131403118040089,
      "grad_norm": 0.02273370325565338,
      "learning_rate": 4.09e-05,
      "loss": 0.0027,
      "step": 410
    },
    {
      "epoch": 0.0935412026726058,
      "grad_norm": 0.010213186033070087,
      "learning_rate": 4.19e-05,
      "loss": 0.0004,
      "step": 420
    },
    {
      "epoch": 0.0957683741648107,
      "grad_norm": 0.008116074837744236,
      "learning_rate": 4.29e-05,
      "loss": 0.0206,
      "step": 430
    },
    {
      "epoch": 0.09799554565701558,
      "grad_norm": 0.009267566725611687,
      "learning_rate": 4.39e-05,
      "loss": 0.001,
      "step": 440
    },
    {
      "epoch": 0.10022271714922049,
      "grad_norm": 0.007021318655461073,
      "learning_rate": 4.49e-05,
      "loss": 0.0005,
      "step": 450
    },
    {
      "epoch": 0.10244988864142539,
      "grad_norm": 35.92754364013672,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.0291,
      "step": 460
    },
    {
      "epoch": 0.10467706013363029,
      "grad_norm": 0.007265315391123295,
      "learning_rate": 4.69e-05,
      "loss": 0.0128,
      "step": 470
    },
    {
      "epoch": 0.10690423162583519,
      "grad_norm": 0.012291595339775085,
      "learning_rate": 4.79e-05,
      "loss": 0.0013,
      "step": 480
    },
    {
      "epoch": 0.1091314031180401,
      "grad_norm": 0.005603676196187735,
      "learning_rate": 4.89e-05,
      "loss": 0.0003,
      "step": 490
    },
    {
      "epoch": 0.111358574610245,
      "grad_norm": 0.009176917374134064,
      "learning_rate": 4.99e-05,
      "loss": 0.0729,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 13470,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 529869594624000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
